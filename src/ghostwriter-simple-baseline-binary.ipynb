{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3c0300d",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "Simple baselines for GhostWriter dataset (e.g. linear regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "2a8cb4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "84320c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages (3.0.5)\n",
      "Requirement already satisfied: lightgbm in /home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy in /home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages (from xgboost) (2.2.6)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages (from xgboost) (2.26.2)\n",
      "Requirement already satisfied: scipy in /home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages (from xgboost) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "50487020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, math, string, numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from datasets import DatasetDict, load_dataset\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "rng = check_random_state(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "dad88cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "_punct_tbl = str.maketrans(\"\", \"\", \"\")\n",
    "punct_set = set(string.punctuation)\n",
    "url_pat = re.compile(r\"(https?://\\S+|www\\.\\S+)\", re.IGNORECASE)\n",
    "sent_pat = re.compile(r\"[.!?]\")\n",
    "nonspace_pat = re.compile(r\"\\S\")\n",
    "alnum_pat = re.compile(r\"[A-Za-z0-9]\")\n",
    "\n",
    "def safe_div(a, b):\n",
    "    return a / b if b else 0.0\n",
    "\n",
    "def tokenize_whitespace_strip_punct(text):\n",
    "    toks = []\n",
    "    for tok in text.split():\n",
    "        # strip leading/trailing punctuation\n",
    "        tok = tok.strip(string.punctuation)\n",
    "        if tok and alnum_pat.search(tok):\n",
    "            toks.append(tok)\n",
    "    return toks\n",
    "\n",
    "def extract_metrics_batch(batch):\n",
    "    texts = batch[\"text\"]\n",
    "    out = {\n",
    "        \"n_chars\": [],\n",
    "        \"n_chars_nospace\": [],\n",
    "        \"n_words\": [],\n",
    "        \"avg_word_len\": [],\n",
    "        \"n_sents\": [],\n",
    "        \"n_punct\": [],\n",
    "        \"punct_ratio\": [],\n",
    "        \"upper_ratio\": [],\n",
    "        \"digit_ratio\": [],\n",
    "        \"url_count\": [],\n",
    "        \"type_token_ratio\": [],\n",
    "        \"hapax_ratio\": [],\n",
    "    }\n",
    "    for t in texts:\n",
    "        t = t if isinstance(t, str) else \"\"\n",
    "        n_chars = len(t)\n",
    "        n_chars_nospace = len(re.findall(r\"\\S\", t))\n",
    "        n_punct = sum(1 for ch in t if (not ch.isalnum()) and (not ch.isspace()))\n",
    "        n_upper = sum(1 for ch in t if ch.isupper())\n",
    "        n_digit = sum(1 for ch in t if ch.isdigit())\n",
    "        url_count = len(url_pat.findall(t))\n",
    "\n",
    "        # sentence count (min 1 for non-empty text)\n",
    "        sent_splits = [s for s in sent_pat.split(t) if s.strip()]\n",
    "        n_sents = max(1, len(sent_splits)) if t.strip() else 0\n",
    "\n",
    "        toks = tokenize_whitespace_strip_punct(t)\n",
    "        n_words = len(toks)\n",
    "        avg_word_len = safe_div(sum(len(w) for w in toks), n_words)\n",
    "\n",
    "        # lexical diversity\n",
    "        toks_lower = [w.lower() for w in toks]\n",
    "        vocab = set(toks_lower)\n",
    "        type_token_ratio = safe_div(len(vocab), n_words)\n",
    "\n",
    "        # hapax legomena ratio\n",
    "        from collections import Counter\n",
    "        cnt = Counter(toks_lower)\n",
    "        hapax_ratio = safe_div(sum(1 for w, c in cnt.items() if c == 1), n_words)\n",
    "\n",
    "        punct_ratio = safe_div(n_punct, n_chars_nospace)\n",
    "        upper_ratio = safe_div(n_upper, n_chars_nospace)\n",
    "        digit_ratio = safe_div(n_digit, n_chars_nospace)\n",
    "\n",
    "        out[\"n_chars\"].append(n_chars)\n",
    "        out[\"n_chars_nospace\"].append(n_chars_nospace)\n",
    "        out[\"n_words\"].append(n_words)\n",
    "        out[\"avg_word_len\"].append(avg_word_len)\n",
    "        out[\"n_sents\"].append(n_sents)\n",
    "        out[\"n_punct\"].append(n_punct)\n",
    "        out[\"punct_ratio\"].append(punct_ratio)\n",
    "        out[\"upper_ratio\"].append(upper_ratio)\n",
    "        out[\"digit_ratio\"].append(digit_ratio)\n",
    "        out[\"url_count\"].append(url_count)\n",
    "        out[\"type_token_ratio\"].append(type_token_ratio)\n",
    "        out[\"hapax_ratio\"].append(hapax_ratio)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "01f81aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "    \"n_chars\",\"n_chars_nospace\",\"n_words\",\"avg_word_len\",\"n_sents\",\"n_punct\",\n",
    "    \"punct_ratio\",\"upper_ratio\",\"digit_ratio\",\"url_count\",\"type_token_ratio\",\"hapax_ratio\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abea4fc0",
   "metadata": {},
   "source": [
    "## Dataset & Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "859a167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"TheItCrOw/GhostWriter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2f2f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a929366e01242a4b09ffcbae94bbf4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/382535 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97f52a54b7740f3acd5c96e6509e377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/54648 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe62639dc164417394236e08470b93f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/109296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693d35f3c70842cbaf0104e542cc8def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/256280 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e95c96cfe764a8187f513dd91cc30e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/36611 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed7b14222a042b1b9968c4b3ea1fa3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/73223 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfcae2b927ef422bb5b3efe45a64ef40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/256266 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3ef256a93a496aa31a5582c71ba6c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/36610 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5657d4265cf54efca8c3a44c97a30218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/73219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Keep only 1 and 0\n",
    "dataset01 = DatasetDict({\n",
    "    split: ds.filter(lambda ex: ex[\"label\"] in (0, 1))\n",
    "    for split, ds in dataset.items()\n",
    "})\n",
    "\n",
    "# 2. Remove empty texts\n",
    "dataset01 = DatasetDict({\n",
    "    split: ds.filter(lambda ex: isinstance(ex[\"text\"], str) and ex[\"text\"].strip() != \"\")\n",
    "    for split, ds in dataset01.items()\n",
    "})\n",
    "\n",
    "def clean_markdown(batch):\n",
    "    cleaned = []\n",
    "    for t in batch[\"text\"]:\n",
    "        # Collapse multiple spaces and trim\n",
    "        t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "        cleaned.append(t)\n",
    "    return {\"text\": cleaned}\n",
    "\n",
    "dataset01 = DatasetDict({\n",
    "    split: ds.map(clean_markdown, batched=True, num_proc=4)\n",
    "    for split, ds in dataset01.items()\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "73ab8d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c9e8ee3197424c973488da6aaaad45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/256266 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597aa2aa917b4aa3a7ebcb7e3ec54157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/36610 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629d8b1dbea94301b9e645a8af02852f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/73219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': '41a1cb62-9edd-4aa2-8083-e26165fcc9c2',\n",
       " 'text': 'In today’s world, technology has woven itself into the very fabric of our daily lives, and its impact on understanding human emotions is both fascinating and concerning. As someone who has grown up with smartphones and social media, I can’t help but wonder how this tech shapes our ability to recognize genuine feelings, especially in educational settings. For instance, tools that analyze facial expressions or tone of voice can be incredibly useful for teachers trying to gauge student engagement. However, I often feel that relying too heavily on these technologies can lead to misunderstandings. Emotions are complex and nuanced; a smile doesn’t always mean happiness, and a frown doesn’t always signify sadness. By placing too much trust in algorithms, we risk oversimplifying the rich tapestry of human emotion. I believe that while technology can aid our understanding, it shouldn’t replace our instinctual ability to connect with others. After all, the most profound insights into feelings often come from genuine human interaction, not just data points on a screen. Balancing tech with empathy is key in nurturing emotional intelligence in our schools.',\n",
       " 'domain': 'student_essays',\n",
       " 'date': '2025',\n",
       " 'source': '9edd7547-57c4-4ef0-b33e-6a0f82d35499',\n",
       " 'lang': 'en-EN',\n",
       " 'label': 1,\n",
       " 'agent': 'gpt-4o-mini',\n",
       " 'type': 'fulltext',\n",
       " 'n_chars': 1161,\n",
       " 'n_chars_nospace': 981,\n",
       " 'n_words': 181,\n",
       " 'avg_word_len': 5.303867403314917,\n",
       " 'n_sents': 9,\n",
       " 'n_punct': 26,\n",
       " 'punct_ratio': 0.026503567787971458,\n",
       " 'upper_ratio': 0.011213047910295617,\n",
       " 'digit_ratio': 0.0,\n",
       " 'url_count': 0,\n",
       " 'type_token_ratio': 0.7348066298342542,\n",
       " 'hapax_ratio': 0.580110497237569}"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==== 2) Feature extraction ====\n",
    "dataset_feats = DatasetDict({\n",
    "    split: ds.map(extract_metrics_batch, batched=True, num_proc=8)\n",
    "    for split, ds in dataset01.items()\n",
    "})\n",
    "dataset_feats['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "915de6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 3) Prepare arrays ====\n",
    "def to_xy(ds):\n",
    "    X = np.column_stack([np.array(ds[f], dtype=np.float32) for f in FEATURES])\n",
    "    y = np.array(ds[\"label\"], dtype=np.int64)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "24eb9c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (256266, 12)  Test size: (73219, 12)\n",
      "Class balance (train): {0: 104303, 1: 151963}\n",
      "Class balance (test): {0: 29801, 1: 43418}\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = to_xy(dataset_feats[\"train\"])\n",
    "X_test,  y_test  = to_xy(dataset_feats[\"test\"])\n",
    "\n",
    "print(\"Train size:\", X_train.shape, \" Test size:\", X_test.shape)\n",
    "print(\"Class balance (train):\", {c:int((y_train==c).sum()) for c in [0,1]})\n",
    "print(\"Class balance (test):\",  {c:int((y_test==c).sum()) for c in [0,1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120e3510",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "024e7484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred, y_proba):\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auroc = roc_auc_score(y_true, y_proba)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    fpr = fp / (fp + tn) if (fp + tn) else 0.0\n",
    "    tpr = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "\n",
    "    return {\"F1\": f1, \"AUROC\": auroc, \"FPR\": fpr, \"TPR\": tpr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "d7d14cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "ba551f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Linear Regression + threshold 0.5\n",
    "linreg = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "    (\"lr\", LinearRegression())\n",
    "])\n",
    "linreg.fit(X_train, y_train)\n",
    "linreg_scores = linreg.predict(X_test)\n",
    "linreg_proba = np.clip(linreg_scores, 0, 1)\n",
    "linreg_pred = (linreg_scores >= 0.5).astype(int)\n",
    "results[\"LinearRegression\"] = compute_metrics(y_test, linreg_pred, linreg_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "2ca5d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) XGBoost\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=1.0,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    eval_metric=\"logloss\",\n",
    "    objective=\"binary:logistic\",\n",
    ")\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_proba = xgb.predict_proba(X_test)[:, 1]\n",
    "xgb_pred = (xgb_proba >= 0.5).astype(int)\n",
    "results[\"XGBoost\"] = compute_metrics(y_test, xgb_pred, xgb_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "e4e57e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 151963, number of negative: 104303\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2854\n",
      "[LightGBM] [Info] Number of data points in the train set: 256266, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.592989 -> initscore=0.376337\n",
      "[LightGBM] [Info] Start training from score 0.376337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 3) LightGBM\n",
    "lgbm = LGBMClassifier(\n",
    "    n_estimators=600,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=63,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=1.0,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    objective=\"binary\",\n",
    ")\n",
    "\n",
    "lgbm.fit(X_train, y_train)\n",
    "lgbm_proba = lgbm.predict_proba(X_test)[:, 1]\n",
    "lgbm_pred = (lgbm_proba >= 0.5).astype(int)\n",
    "results[\"LightGBM\"] = compute_metrics(y_test, lgbm_pred, lgbm_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "c45e061f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LightGBM': {'AUROC': np.float64(0.9788015728741681),\n",
      "              'F1': 0.9354409204192414,\n",
      "              'FPR': np.float64(0.11258011476124963),\n",
      "              'TPR': np.float64(0.9466120042378737)},\n",
      " 'LinearRegression': {'AUROC': np.float64(0.8640460041397114),\n",
      "                      'F1': 0.8517433313394097,\n",
      "                      'FPR': np.float64(0.4432737156471259),\n",
      "                      'TPR': np.float64(0.9674558938689023)},\n",
      " 'XGBoost': {'AUROC': np.float64(0.9761205758976311),\n",
      "             'F1': 0.9313982670709411,\n",
      "             'FPR': np.float64(0.12187510486225295),\n",
      "             'TPR': np.float64(0.9445160993136488)}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
