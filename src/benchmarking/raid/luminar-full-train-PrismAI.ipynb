{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Luminar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, NamedTuple\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    PreTrainedModel,\n",
    "    PreTrainedTokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Luminar Encoder\n",
    "\n",
    "1. Pre-Process Inputs: tokenize and pass through LLM, recording hidden states\n",
    "2. Calculate _Intermediate Likelihoods_: pass each hidden state through the models LM head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuminarEncoder:\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_dim: int = 256,\n",
    "        model_name_or_path: str = \"gpt2\",\n",
    "        device: str = (\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    ):\n",
    "        self.feature_dim = feature_dim\n",
    "        self.device = torch.device(device)\n",
    "\n",
    "        self.tokenizer: PreTrainedTokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_name_or_path\n",
    "        )\n",
    "        if not hasattr(self.tokenizer, \"pad_token\") or self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        self.pad_token_id = self.tokenizer.pad_token_id\n",
    "\n",
    "        self.model: PreTrainedModel = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name_or_path\n",
    "        )\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        if hasattr(self.model, \"lm_head\"):\n",
    "            self.model_lm_head: nn.Linear = self.model.lm_head\n",
    "        elif hasattr(self.model.model, \"lm_head\"):\n",
    "            self.model_lm_head: nn.Linear = self.model.model.lm_head\n",
    "        else:\n",
    "            raise ValueError(\"Could not find lm_head in model\")\n",
    "\n",
    "    def __call__(self, batch: dict[str, list[str]]) -> dict[str, list[torch.Tensor]]:\n",
    "        return {\"features\": self.process(batch[\"text\"])}\n",
    "\n",
    "    def process(self, batch: list[str]) -> list[torch.Tensor]:\n",
    "        encoding = self.tokenizer(\n",
    "            batch,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=self.feature_dim,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        batch_hidden_states = self.forward(encoding.input_ids, encoding.attention_mask)\n",
    "\n",
    "        intermediate_likelihoods = []\n",
    "        for input_ids, hidden_states in zip(encoding.input_ids, batch_hidden_states):\n",
    "            intermediate_likelihoods.append(\n",
    "                self.compute_intermediate_likelihoods(input_ids, hidden_states)\n",
    "            )\n",
    "\n",
    "        return intermediate_likelihoods\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: torch.Tensor,\n",
    "    ) -> Iterable[tuple[torch.Tensor, ...]]:\n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids.to(self.device),\n",
    "            attention_mask=attention_mask.to(self.device),\n",
    "            output_hidden_states=True,\n",
    "        )\n",
    "\n",
    "        # unpack hidden states to get one list of tensors per input sequence,\n",
    "        # instead of one hidden state per layer in the model\n",
    "        return zip(*outputs.hidden_states)  # type: ignore\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def compute_intermediate_likelihoods(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        hidden_states: tuple[torch.Tensor],\n",
    "    ) -> torch.Tensor:\n",
    "        labels = input_ids[1:].view(-1, 1)\n",
    "\n",
    "        seq_length = min(labels.ne(self.pad_token_id).sum(), self.feature_dim)\n",
    "        labels = labels[:seq_length].to(self.device)\n",
    "\n",
    "        intermediate_likelihoods = []\n",
    "        for hs in hidden_states:\n",
    "            hs: torch.Tensor = hs[:seq_length].to(self.device)\n",
    "            il = (\n",
    "                # get layer logits\n",
    "                self.model_lm_head(hs)\n",
    "                # calculate likelihoods\n",
    "                .softmax(-1)\n",
    "                # get likelihoods of input tokens\n",
    "                .gather(-1, labels)\n",
    "                .squeeze(-1)\n",
    "                .cpu()\n",
    "            )\n",
    "            del hs\n",
    "\n",
    "            # pad with zeros if sequence is shorter than required feature_dim\n",
    "            if seq_length < self.feature_dim:\n",
    "                il = torch.cat([il, torch.zeros(self.feature_dim - seq_length)])\n",
    "\n",
    "            intermediate_likelihoods.append(il)\n",
    "\n",
    "        # stack intermediate likelihoods to get tensor of shape (feature_dim, num_layers)\n",
    "        return torch.stack(intermediate_likelihoods, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Luminar Classifier\n",
    "\n",
    "CNN-based classifier using _Intermediate Likelihoods_ as input features.\n",
    "Here, we utilize these inherently 2D values (`seq_len * num_layers`) as 1D inputs where the second dimension is treated as input channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalLayerSpec(NamedTuple):\n",
    "    channels: int\n",
    "    kernel_size: int | tuple[int, int]\n",
    "    stride: int = 1\n",
    "\n",
    "    @property\n",
    "    def kernel_size_1d(self):\n",
    "        if isinstance(self.kernel_size, int):\n",
    "            return self.kernel_size\n",
    "        return self.kernel_size[0]\n",
    "\n",
    "    @property\n",
    "    def kernel_size_2d(self):\n",
    "        if isinstance(self.kernel_size, int):\n",
    "            return (self.kernel_size, self.kernel_size)\n",
    "        return self.kernel_size\n",
    "\n",
    "    @property\n",
    "    def padding(self) -> int:\n",
    "        return (self.kernel_size_1d - 1) // 2\n",
    "\n",
    "    def __repr__(self):\n",
    "        return repr(tuple(self))\n",
    "\n",
    "\n",
    "DEFAULT_CONV_LAYER_SHAPES = ((64, 5), (128, 3), (128, 3), (128, 3), (64, 3))\n",
    "\n",
    "\n",
    "class LuminarClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        conv_layer_shapes: Iterable[ConvolutionalLayerSpec] = DEFAULT_CONV_LAYER_SHAPES,\n",
    "        projection_dim: int | None = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.Sequential()\n",
    "        for conv in conv_layer_shapes:\n",
    "            conv = ConvolutionalLayerSpec(*conv)\n",
    "            self.conv_layers.append(\n",
    "                nn.LazyConv1d(\n",
    "                    conv.channels,\n",
    "                    conv.kernel_size,  # type: ignore\n",
    "                    conv.stride,\n",
    "                    conv.padding,\n",
    "                ),\n",
    "            )\n",
    "            self.conv_layers.append(\n",
    "                nn.LeakyReLU(),\n",
    "            )\n",
    "        self.conv_layers.append(nn.Flatten())\n",
    "\n",
    "        if projection_dim:\n",
    "            self.projection = nn.Sequential(\n",
    "                nn.LazyLinear(projection_dim), nn.LeakyReLU()\n",
    "            )\n",
    "        else:\n",
    "            self.projection = nn.Identity()\n",
    "\n",
    "        self.classifier = nn.LazyLinear(1)\n",
    "\n",
    "    def forward(self, features: torch.Tensor):\n",
    "        # We are using 2D features (so `features` is a 3D tensor)\n",
    "        # but we want to treat the second feature dimension as channels.\n",
    "        # Thus, we need to transpose the tensor here\n",
    "        features = features.transpose(1, 2)\n",
    "\n",
    "        for layer in self.conv_layers:\n",
    "            features = layer(features)\n",
    "\n",
    "        return self.classifier(self.projection(features.flatten(1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import json\n",
    "\n",
    "import os\n",
    "from datasets import concatenate_datasets\n",
    "\n",
    "dataset_list = []\n",
    "data_dir = \"/resources/public/stoeckel/PrismAI/data\"\n",
    "\n",
    "for fname in os.listdir(data_dir):\n",
    "    if fname.endswith(\".jsonl.bz2\"):\n",
    "        path = os.path.join(data_dir, fname)\n",
    "        dataset = Dataset.from_list(\n",
    "            [json.loads(line) for line in bz2.open(path, \"rt\")]\n",
    "        )\n",
    "        dataset_list.append(dataset)\n",
    "\n",
    "raw_dataset = concatenate_datasets(dataset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b0dd130df124d12b784f5b5e70b9487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/74735 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd218149d3d04b879ebd44310b9cbfdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18684 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['agent', 'label', 'label_str', 'text'],\n",
       "        num_rows: 149470\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['agent', 'label', 'label_str', 'text'],\n",
       "        num_rows: 37368\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def flatten_samples(batch: dict):\n",
    "    result = defaultdict(list)\n",
    "    for element in batch[\"samples\"]:\n",
    "        for sample in element:\n",
    "            for key, value in sample.items():\n",
    "                result[key].append(value)\n",
    "    return result\n",
    "\n",
    "\n",
    "dataset = raw_dataset.train_test_split(test_size=0.2).map(\n",
    "    flatten_samples,\n",
    "    batched=True,\n",
    "    remove_columns=raw_dataset.column_names,\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent': 'human',\n",
       " 'label': 0,\n",
       " 'label_str': 'human',\n",
       " 'text': 'I disagree with this decision because not everyone does nor likes to do activitys. Some people like to do activitys like sports and yearbook but to force all students to do an extracurricular activity is unfair to those who dont want to. It should be a choice whether or not you want to have a extracurricular activity or not. I say it should be a choice because alot of people dont like to be active and dont try. If a principal trys to force extracurricular activities on his\\\\her students than most students wont like nor participate in most of the activitys the classes will be doing once they are in the class.\\n\\nIf i where to agree with this decision than i would say that it would be a great idea for the people who do like to play sports, help with yearbook, and be on the student council. I would also say it would be a great opportunity for the students who dont like these activities because it would give them a chance to be active and to give them a chance to have an activity involving the student council or yearbook.\\n\\nBut im not, i fully disagree with this decision due to its idea of making students participate in activitys that they may or may not want to participate in.\\xa0'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LuminarEncoder(128, model_name_or_path=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70f733e8ec584f639c638bc08930660b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/149470 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf902370bb82404e98338daaaf43ab87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/37368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(encoder, batched=True, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LuminarClassifier()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 4671/4671 [02:42<00:00, 28.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "train_dataset = dataset[\"train\"].with_format(\"torch\", [\"features\", \"label\"])\n",
    "for batch in tqdm(\n",
    "    DataLoader(train_dataset, 32)\n",
    "):\n",
    "    optimizer.zero_grad()\n",
    "    features = batch[\"features\"]\n",
    "    labels = batch[\"label\"].float().unsqueeze(-1)\n",
    "\n",
    "    preds = model(features)\n",
    "\n",
    "    loss = criterion(preds, labels)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to luminar_classifier.pt\n"
     ]
    }
   ],
   "source": [
    "save_path = \"luminar_classifier.pt\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "\n",
    "print(f\"Model saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 1168/1168 [00:35<00:00, 33.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=0.14466811366433482\n",
      "f1=0.9396291504959035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "y_pred, y_truth, losses = [], [], []\n",
    "test_dataset = dataset[\"test\"].with_format(\"torch\", [\"features\", \"label\"])\n",
    "for batch in tqdm(DataLoader(test_dataset, 32)):\n",
    "    with torch.no_grad():\n",
    "        features = batch[\"features\"]\n",
    "        labels = batch[\"label\"].float().unsqueeze(-1)\n",
    "        preds = model(features)\n",
    "\n",
    "        y_pred.extend(preds.sigmoid().round().squeeze().tolist())\n",
    "        y_truth.extend(labels.squeeze().tolist())\n",
    "\n",
    "        loss = criterion(preds, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "print(f\"loss={np.mean(losses)}\")\n",
    "print(f\"f1={f1_score(y_truth, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "# Source: Ghostbuster, Verma et al. (2024)\n",
    "def get_scores(labels, probabilities, calibrated=False, precision=6):\n",
    "    assert len(labels) == len(probabilities)\n",
    "\n",
    "    if calibrated:\n",
    "        threshold = sorted(probabilities)[len(labels) - sum(labels) - 1]\n",
    "    else:\n",
    "        threshold = 0.5\n",
    "\n",
    "    acc = round(float(accuracy_score(labels, probabilities > threshold)), precision)\n",
    "    f1 = round(float(f1_score(labels, probabilities > threshold)), precision)\n",
    "\n",
    "    if sum(labels) == 0 or sum(labels) == len(labels):\n",
    "        auroc = -1\n",
    "    else:\n",
    "        auroc = round(float(roc_auc_score(labels, probabilities)), precision)\n",
    "\n",
    "    return acc, f1, auroc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
