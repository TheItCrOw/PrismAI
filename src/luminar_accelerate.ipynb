{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26864b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from torch import Tensor, nn\n",
    "from tqdm import tqdm\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "from luminar.classifier import LuminarCNN\n",
    "from luminar.utils import PaddingDataCollator, get_matched_datasets\n",
    "\n",
    "HF_TOKEN = (Path.home() / \".hf_token\").read_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47d21c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f065414a",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bf68ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from luminar.encoder import LuminarEncoder\n",
    "\n",
    "\n",
    "# encoder = LuminarEncoder()\n",
    "# encoder.device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f7e778",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a429a29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     logits, labels = eval_pred\n",
    "#     scores = torch.tensor(logits).sigmoid().cpu().flatten().numpy()\n",
    "#     labels = np.array(labels).flatten()\n",
    "\n",
    "#     metrics = {}\n",
    "\n",
    "#     metrics[\"acc\"] = float(accuracy_score(labels, scores > 0.5))\n",
    "#     metrics[\"f1\"] = float(f1_score(labels, scores > 0.5))\n",
    "\n",
    "#     threshold = sorted(scores)[len(labels) - sum(labels) - 1]\n",
    "#     metrics[\"acc_calibrated\"] = float(accuracy_score(labels, scores > threshold))\n",
    "#     metrics[\"f1_calibrated\"] = float(f1_score(labels, scores > threshold))\n",
    "#     metrics[\"threshold\"] = threshold\n",
    "\n",
    "#     if sum(labels) == 0 or sum(labels) == len(labels):\n",
    "#         auroc = -1\n",
    "#     else:\n",
    "#         auroc = float(roc_auc_score(labels, scores))\n",
    "#     metrics[\"auroc\"] = auroc\n",
    "\n",
    "#     return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06afa49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "acc = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "roc_auc = evaluate.load(\"roc_auc\")\n",
    "\n",
    "\n",
    "def compute_scores(preds: NDArray, labels: NDArray, suffix=\"\"):\n",
    "    f1_score_each = f1.compute(predictions=preds, references=labels, average=None)\n",
    "    f1_score_weighted = f1.compute(\n",
    "        predictions=preds, references=labels, average=\"weighted\"\n",
    "    )\n",
    "    acc_score = acc.compute(predictions=preds, references=labels)\n",
    "    roc_auc_score = roc_auc.compute(prediction_scores=preds, references=labels)\n",
    "\n",
    "    return {\n",
    "        f\"f1_each_{i}{suffix}\": score\n",
    "        for i, score in enumerate(f1_score_each[\"f1\"])  # type: ignore\n",
    "    } | {\n",
    "        f\"f1_weighted{suffix}\": f1_score_weighted[\"f1\"],  # type: ignore\n",
    "        f\"accuracy{suffix}\": acc_score[\"accuracy\"],  # type: ignore\n",
    "        f\"roc_auc{suffix}\": roc_auc_score[\"roc_auc\"],  # type: ignore\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    logits = 1 / (1 + np.exp(-np.array(logits)))\n",
    "\n",
    "    metrics = compute_scores(logits > 0.5, labels)\n",
    "\n",
    "    threshold = np.median(logits)\n",
    "    metrics |= compute_scores(logits > threshold, labels, \"_median\")\n",
    "    metrics[\"threshold_median\"] = threshold\n",
    "\n",
    "    metrics[\"ground_truth_0\"] = np.sum(labels == 0)\n",
    "    metrics[\"ground_truth_1\"] = np.sum(labels == 1)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c528f341",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = \"gpt_4o_mini\"\n",
    "feature_len = 256\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4c0be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset: Dataset = (\n",
    "    load_dataset(\n",
    "        \"liberi-luminaris/PrismAI-encoded-gpt2\",\n",
    "        \"cnn_news-fulltext\",\n",
    "        split=f\"human+{agent}+gemma2_9b\",\n",
    "        token=HF_TOKEN,\n",
    "    )  # type: ignore\n",
    "    .map(\n",
    "        lambda features: {\"features\": features[:feature_len]},\n",
    "        input_columns=[\"features\"],\n",
    "        desc=\"Trimming Features\",\n",
    "    )\n",
    "    .rename_column(\"label\", \"labels\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebe055ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9825103ce3d4e32ad5d5583f46cb1ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/44386 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d25efba7681144169b042a4721728d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/44386 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "078422051b6e46c886057cce84e2a440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/44386 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cbde624736d4683a19e60dc54bd159f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/44386 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets_matched = get_matched_datasets(dataset, agent)\n",
    "datasets_matched.set_format(\"torch\", columns=[\"labels\", \"features\"])\n",
    "# dataset_train = datasets_matched[\"matched\"].train_test_split(\n",
    "#     test_size=0.2, seed=seed, shuffle=True\n",
    "# ).with_format(\"torch\", columns=[\"labels\", \"features\"])\n",
    "# dataset_test = dataset_train.pop(\"test\")\n",
    "# dataset_train = dataset_train[\"train\"].train_test_split(1 / 16, seed=seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fe23e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # first 256 features & 13 layers for gpt2\n",
    "    \"feature_dim\": (feature_len, 13),\n",
    "    \"feature_type\": \"intermediate_likelihoods\",\n",
    "    \"feature_selection\": \"first\",\n",
    "    \"projection_dim\": 32,\n",
    "    \"learning_rate\": 6e-4,\n",
    "    \"max_epochs\": 5,\n",
    "    \"gradient_clip_val\": 1.0,\n",
    "    \"train_batch_size\": 32,\n",
    "    \"eval_batch_size\": 1024,\n",
    "    \"seed\": seed,\n",
    "    \"agent\": agent,\n",
    "}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../logs/hf/\",\n",
    "    per_device_train_batch_size=config[\"train_batch_size\"],\n",
    "    per_device_eval_batch_size=config[\"eval_batch_size\"],\n",
    "    learning_rate=config[\"learning_rate\"],\n",
    "    num_train_epochs=config[\"max_epochs\"],\n",
    "    logging_steps=100,\n",
    "    warmup_ratio=1.0,\n",
    "    metric_for_best_model=\"loss\",\n",
    "    load_best_model_at_end=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7405313",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LuminarCNN(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc46492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=classifier,\n",
    "    args=training_args,\n",
    "    train_dataset=datasets_matched[\"train\"],\n",
    "    eval_dataset=datasets_matched[\"eval\"],\n",
    "    data_collator=PaddingDataCollator(config[\"feature_dim\"]),\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(3)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2055ee25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1800' max='2585' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1800/2585 05:28 < 02:23, 5.48 it/s, Epoch 3/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Each 0</th>\n",
       "      <th>F1 Each 1</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>F1 Each 0 Median</th>\n",
       "      <th>F1 Each 1 Median</th>\n",
       "      <th>F1 Weighted Median</th>\n",
       "      <th>Accuracy Median</th>\n",
       "      <th>Roc Auc Median</th>\n",
       "      <th>Threshold Median</th>\n",
       "      <th>Ground Truth 0</th>\n",
       "      <th>Ground Truth 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.693200</td>\n",
       "      <td>0.692968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.671743</td>\n",
       "      <td>0.671743</td>\n",
       "      <td>0.671743</td>\n",
       "      <td>0.671743</td>\n",
       "      <td>0.671743</td>\n",
       "      <td>0.504590</td>\n",
       "      <td>1182</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.687800</td>\n",
       "      <td>0.680940</td>\n",
       "      <td>0.691644</td>\n",
       "      <td>0.240293</td>\n",
       "      <td>0.465969</td>\n",
       "      <td>0.561337</td>\n",
       "      <td>0.561337</td>\n",
       "      <td>0.722504</td>\n",
       "      <td>0.722504</td>\n",
       "      <td>0.722504</td>\n",
       "      <td>0.722504</td>\n",
       "      <td>0.722504</td>\n",
       "      <td>0.469390</td>\n",
       "      <td>1182</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.609200</td>\n",
       "      <td>0.626644</td>\n",
       "      <td>0.553364</td>\n",
       "      <td>0.743675</td>\n",
       "      <td>0.648520</td>\n",
       "      <td>0.674281</td>\n",
       "      <td>0.674281</td>\n",
       "      <td>0.739425</td>\n",
       "      <td>0.739425</td>\n",
       "      <td>0.739425</td>\n",
       "      <td>0.739425</td>\n",
       "      <td>0.739425</td>\n",
       "      <td>0.733670</td>\n",
       "      <td>1182</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.566100</td>\n",
       "      <td>0.518602</td>\n",
       "      <td>0.761457</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.740729</td>\n",
       "      <td>0.742386</td>\n",
       "      <td>0.742386</td>\n",
       "      <td>0.753807</td>\n",
       "      <td>0.753807</td>\n",
       "      <td>0.753807</td>\n",
       "      <td>0.753807</td>\n",
       "      <td>0.753807</td>\n",
       "      <td>0.415944</td>\n",
       "      <td>1182</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.485968</td>\n",
       "      <td>0.782539</td>\n",
       "      <td>0.756611</td>\n",
       "      <td>0.769575</td>\n",
       "      <td>0.770305</td>\n",
       "      <td>0.770305</td>\n",
       "      <td>0.772420</td>\n",
       "      <td>0.772420</td>\n",
       "      <td>0.772420</td>\n",
       "      <td>0.772420</td>\n",
       "      <td>0.772420</td>\n",
       "      <td>0.434010</td>\n",
       "      <td>1182</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.461900</td>\n",
       "      <td>0.463680</td>\n",
       "      <td>0.790905</td>\n",
       "      <td>0.772627</td>\n",
       "      <td>0.781766</td>\n",
       "      <td>0.782149</td>\n",
       "      <td>0.782149</td>\n",
       "      <td>0.787648</td>\n",
       "      <td>0.787648</td>\n",
       "      <td>0.787648</td>\n",
       "      <td>0.787648</td>\n",
       "      <td>0.787648</td>\n",
       "      <td>0.437262</td>\n",
       "      <td>1182</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.463400</td>\n",
       "      <td>0.490676</td>\n",
       "      <td>0.799702</td>\n",
       "      <td>0.737665</td>\n",
       "      <td>0.768683</td>\n",
       "      <td>0.772843</td>\n",
       "      <td>0.772843</td>\n",
       "      <td>0.799492</td>\n",
       "      <td>0.799492</td>\n",
       "      <td>0.799492</td>\n",
       "      <td>0.799492</td>\n",
       "      <td>0.799492</td>\n",
       "      <td>0.264896</td>\n",
       "      <td>1182</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.426200</td>\n",
       "      <td>0.444031</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.792134</td>\n",
       "      <td>0.795685</td>\n",
       "      <td>0.795685</td>\n",
       "      <td>0.820643</td>\n",
       "      <td>0.820643</td>\n",
       "      <td>0.820643</td>\n",
       "      <td>0.820643</td>\n",
       "      <td>0.820643</td>\n",
       "      <td>0.290383</td>\n",
       "      <td>1182</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.383800</td>\n",
       "      <td>0.377916</td>\n",
       "      <td>0.813898</td>\n",
       "      <td>0.851161</td>\n",
       "      <td>0.832530</td>\n",
       "      <td>0.834602</td>\n",
       "      <td>0.834602</td>\n",
       "      <td>0.865482</td>\n",
       "      <td>0.865482</td>\n",
       "      <td>0.865482</td>\n",
       "      <td>0.865482</td>\n",
       "      <td>0.865482</td>\n",
       "      <td>0.776102</td>\n",
       "      <td>1182</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.329900</td>\n",
       "      <td>0.430345</td>\n",
       "      <td>0.833994</td>\n",
       "      <td>0.763711</td>\n",
       "      <td>0.798852</td>\n",
       "      <td>0.804992</td>\n",
       "      <td>0.804992</td>\n",
       "      <td>0.894247</td>\n",
       "      <td>0.894247</td>\n",
       "      <td>0.894247</td>\n",
       "      <td>0.894247</td>\n",
       "      <td>0.894247</td>\n",
       "      <td>0.110612</td>\n",
       "      <td>1182</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.284700</td>\n",
       "      <td>0.247832</td>\n",
       "      <td>0.903894</td>\n",
       "      <td>0.899741</td>\n",
       "      <td>0.901817</td>\n",
       "      <td>0.901861</td>\n",
       "      <td>0.901861</td>\n",
       "      <td>0.907783</td>\n",
       "      <td>0.907783</td>\n",
       "      <td>0.907783</td>\n",
       "      <td>0.907783</td>\n",
       "      <td>0.907783</td>\n",
       "      <td>0.396912</td>\n",
       "      <td>1182</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.262800</td>\n",
       "      <td>0.227102</td>\n",
       "      <td>0.913204</td>\n",
       "      <td>0.908141</td>\n",
       "      <td>0.910673</td>\n",
       "      <td>0.910745</td>\n",
       "      <td>0.910745</td>\n",
       "      <td>0.916244</td>\n",
       "      <td>0.916244</td>\n",
       "      <td>0.916244</td>\n",
       "      <td>0.916244</td>\n",
       "      <td>0.916244</td>\n",
       "      <td>0.410453</td>\n",
       "      <td>1182</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.283000</td>\n",
       "      <td>0.222206</td>\n",
       "      <td>0.910744</td>\n",
       "      <td>0.906412</td>\n",
       "      <td>0.908578</td>\n",
       "      <td>0.908629</td>\n",
       "      <td>0.908629</td>\n",
       "      <td>0.917090</td>\n",
       "      <td>0.917090</td>\n",
       "      <td>0.917090</td>\n",
       "      <td>0.917090</td>\n",
       "      <td>0.917090</td>\n",
       "      <td>0.409403</td>\n",
       "      <td>1182</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.235600</td>\n",
       "      <td>0.192378</td>\n",
       "      <td>0.926334</td>\n",
       "      <td>0.926458</td>\n",
       "      <td>0.926396</td>\n",
       "      <td>0.926396</td>\n",
       "      <td>0.926396</td>\n",
       "      <td>0.925550</td>\n",
       "      <td>0.925550</td>\n",
       "      <td>0.925550</td>\n",
       "      <td>0.925550</td>\n",
       "      <td>0.925550</td>\n",
       "      <td>0.501516</td>\n",
       "      <td>1182</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.280800</td>\n",
       "      <td>0.192126</td>\n",
       "      <td>0.922414</td>\n",
       "      <td>0.925249</td>\n",
       "      <td>0.923831</td>\n",
       "      <td>0.923858</td>\n",
       "      <td>0.923858</td>\n",
       "      <td>0.923012</td>\n",
       "      <td>0.923012</td>\n",
       "      <td>0.923012</td>\n",
       "      <td>0.923012</td>\n",
       "      <td>0.923012</td>\n",
       "      <td>0.585181</td>\n",
       "      <td>1182</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.292400</td>\n",
       "      <td>0.198358</td>\n",
       "      <td>0.922363</td>\n",
       "      <td>0.921968</td>\n",
       "      <td>0.922165</td>\n",
       "      <td>0.922166</td>\n",
       "      <td>0.922166</td>\n",
       "      <td>0.922166</td>\n",
       "      <td>0.922166</td>\n",
       "      <td>0.922166</td>\n",
       "      <td>0.922166</td>\n",
       "      <td>0.922166</td>\n",
       "      <td>0.488433</td>\n",
       "      <td>1182</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.251600</td>\n",
       "      <td>0.286270</td>\n",
       "      <td>0.864510</td>\n",
       "      <td>0.888632</td>\n",
       "      <td>0.876571</td>\n",
       "      <td>0.877750</td>\n",
       "      <td>0.877750</td>\n",
       "      <td>0.920474</td>\n",
       "      <td>0.920474</td>\n",
       "      <td>0.920474</td>\n",
       "      <td>0.920474</td>\n",
       "      <td>0.920474</td>\n",
       "      <td>0.849520</td>\n",
       "      <td>1182</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.301400</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.888974</td>\n",
       "      <td>0.876487</td>\n",
       "      <td>0.877750</td>\n",
       "      <td>0.877750</td>\n",
       "      <td>0.920474</td>\n",
       "      <td>0.920474</td>\n",
       "      <td>0.920474</td>\n",
       "      <td>0.920474</td>\n",
       "      <td>0.920474</td>\n",
       "      <td>0.875680</td>\n",
       "      <td>1182</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1800, training_loss=0.4077093675401476, metrics={'train_runtime': 328.7459, 'train_samples_per_second': 251.532, 'train_steps_per_second': 7.863, 'total_flos': 0.0, 'train_loss': 0.4077093675401476, 'epoch': 3.481624758220503})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a17f6ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:57]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.19212588667869568,\n",
       " 'eval_f1_each_0': 0.9224137931034483,\n",
       " 'eval_f1_each_1': 0.925249169435216,\n",
       " 'eval_f1_weighted': 0.923831481269332,\n",
       " 'eval_accuracy': 0.9238578680203046,\n",
       " 'eval_roc_auc': 0.9238578680203046,\n",
       " 'eval_f1_each_0_median': 0.9230118443316413,\n",
       " 'eval_f1_each_1_median': 0.9230118443316413,\n",
       " 'eval_f1_weighted_median': 0.9230118443316413,\n",
       " 'eval_accuracy_median': 0.9230118443316413,\n",
       " 'eval_roc_auc_median': 0.9230118443316413,\n",
       " 'eval_threshold_median': 0.5851811766624451,\n",
       " 'eval_ground_truth_0': 1182,\n",
       " 'eval_ground_truth_1': 1182,\n",
       " 'eval_runtime': 7.82,\n",
       " 'eval_samples_per_second': 302.3,\n",
       " 'eval_steps_per_second': 0.384,\n",
       " 'epoch': 3.481624758220503}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e879d274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "early stopping required metric_for_best_model, but did not find eval_loss so early stopping is disabled\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.20134906470775604,\n",
       " 'test_f1_each_0': 0.9155080213903743,\n",
       " 'test_f1_each_1': 0.9173121205777685,\n",
       " 'test_f1_weighted': 0.9164100709840715,\n",
       " 'test_accuracy': 0.9164198053322048,\n",
       " 'test_roc_auc': 0.9164198053322048,\n",
       " 'test_f1_each_0_median': 0.9166314007617435,\n",
       " 'test_f1_each_1_median': 0.9166314007617435,\n",
       " 'test_f1_weighted_median': 0.9166314007617435,\n",
       " 'test_accuracy_median': 0.9166314007617435,\n",
       " 'test_roc_auc_median': 0.9166314007617435,\n",
       " 'test_threshold_median': 0.5584132671356201,\n",
       " 'test_ground_truth_0': 2363,\n",
       " 'test_ground_truth_1': 2363,\n",
       " 'test_runtime': 15.073,\n",
       " 'test_samples_per_second': 313.54,\n",
       " 'test_steps_per_second': 0.332,\n",
       " 'epoch': 3.481624758220503}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(datasets_matched[\"test\"], metric_key_prefix=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c34613c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "early stopping required metric_for_best_model, but did not find eval_loss so early stopping is disabled\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'unmatched_loss': 0.4239790737628937,\n",
       " 'unmatched_f1_each_0': 0.838589487691284,\n",
       " 'unmatched_f1_each_1': 0.7747864834756777,\n",
       " 'unmatched_f1_weighted': 0.8092028160341154,\n",
       " 'unmatched_accuracy': 0.8119525618169134,\n",
       " 'unmatched_roc_auc': 0.8039393376283043,\n",
       " 'unmatched_f1_each_0_median': 0.8381804623415362,\n",
       " 'unmatched_f1_each_1_median': 0.8248870238863784,\n",
       " 'unmatched_f1_weighted_median': 0.8320577112911876,\n",
       " 'unmatched_accuracy_median': 0.8317959848073793,\n",
       " 'unmatched_roc_auc_median': 0.8338676976544206,\n",
       " 'unmatched_threshold_median': 0.2178930938243866,\n",
       " 'unmatched_ground_truth_0': 6959,\n",
       " 'unmatched_ground_truth_1': 5942,\n",
       " 'unmatched_runtime': 41.3477,\n",
       " 'unmatched_samples_per_second': 312.013,\n",
       " 'unmatched_steps_per_second': 0.314,\n",
       " 'epoch': 3.481624758220503}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(datasets_matched[\"unmatched\"], metric_key_prefix=\"unmatched\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ea5390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3542678a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d405f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204bf89b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b95ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732ce273",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classifier)\n",
    "print(\n",
    "    \"Parameters:\\n  conv_layers:\",\n",
    "    sum(\n",
    "        param.numel()\n",
    "        for param in classifier.conv_layers.parameters()\n",
    "        if param.requires_grad\n",
    "    ),\n",
    "    \"\\n  projection:\",\n",
    "    sum(\n",
    "        param.numel()\n",
    "        for param in classifier.projection.parameters()\n",
    "        if param.requires_grad\n",
    "    ),\n",
    "    \"\\n  classifier:\",\n",
    "    sum(\n",
    "        param.numel()\n",
    "        for param in classifier.classifier.parameters()\n",
    "        if param.requires_grad\n",
    "    ),\n",
    "    \"\\n  total:\",\n",
    "    sum(param.numel() for param in classifier.parameters() if param.requires_grad),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47c00fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise RuntimeError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc98970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(scores, indent=4))\n",
    "with open(\"../logs/luminar/gpt2_first_128-3_epochs.json\", \"w\") as f:\n",
    "    json.dump(scores, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d739a695",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for subset in [\n",
    "    \"blog_authorship_corpus\",\n",
    "    \"student_essays\",\n",
    "    \"cnn_news\",\n",
    "    \"euro_court_cases\",\n",
    "    \"house_of_commons\",\n",
    "    \"arxiv_papers\",\n",
    "    \"gutenberg_en\",\n",
    "    \"en\",\n",
    "    \"bundestag\",\n",
    "    \"spiegel_articles\",\n",
    "    \"gutenberg_de\",\n",
    "    \"de\",\n",
    "]:\n",
    "    config_name = f\"{subset}-fulltext\"\n",
    "    datasets[config_name] = load_dataset(\n",
    "        \"liberi-luminaris/PrismAI-encoded-gpt2\",\n",
    "        config_name,\n",
    "        token=HF_TOKEN,\n",
    "        split=\"human+gpt_4o_mini\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531a62b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    \"liberi-luminaris/PrismAI-fulltext\", \"cnn_news\", split=\"human+gpt_4o_mini\"\n",
    ")\n",
    "dataset_human = dataset.filter(lambda sample: sample[\"agent\"] == \"human\")\n",
    "source_ids = set(\n",
    "    dataset_human.shuffle(seed=42).take(len(dataset_human) // 10 * 8)[\"id_source\"]\n",
    ")\n",
    "dataset_train = dataset.filter(lambda sample: sample[\"id_source\"] in source_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ec3e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_truncated = {}\n",
    "for config_name, dataset in datasets.items():\n",
    "    datasets_truncated[config_name] = dataset.with_format(\n",
    "        \"numpy\", columns=[\"features\"], output_all_columns=True\n",
    "    ).map(\n",
    "        lambda batch: {\"features\": batch[\"features\"][:, :256]},\n",
    "        batched=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18961af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_considered = {\n",
    "    key: value\n",
    "    for key, value in datasets_truncated.items()\n",
    "    if not key.startswith(\"de-\") and not key.startswith(\"en-\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2174dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "domains = [\n",
    "    \"Web Blogs\",\n",
    "    \"Essays\",\n",
    "    \"CNN\",\n",
    "    \"ECHR\",\n",
    "    \"HoC\",\n",
    "    \"arXiv\",\n",
    "    \"Gutenberg$_{en}$\",\n",
    "    \"Bundestag$_{de}$\",\n",
    "    \"Spiegel$_{de}$\",\n",
    "    \"Gutenberg$_{de}$\",\n",
    "    \"All$_{en}$\",\n",
    "    \"All$_{de}$\",\n",
    "]\n",
    "name_map = {\n",
    "    \"blog_authorship_corpus\": \"Web Blogs\",\n",
    "    \"student_essays\": \"Essays\",\n",
    "    \"cnn_news\": \"CNN\",\n",
    "    \"euro_court_cases\": \"ECHR\",\n",
    "    \"house_of_commons\": \"HoC\",\n",
    "    \"arxiv_papers\": \"arXiv\",\n",
    "    \"gutenberg_en\": \"Gutenberg$_{en}$\",\n",
    "    \"bundestag\": \"Bundestag$_{de}$\",\n",
    "    \"spiegel_articles\": \"Spiegel$_{de}$\",\n",
    "    \"gutenberg_de\": \"Gutenberg$_{de}$\",\n",
    "    \"en\": \"All$_{en}$\",\n",
    "    \"de\": \"All$_{de}$\",\n",
    "}\n",
    "\n",
    "results = [\n",
    "    {\"domain\": name_map[key.split(\"-\", 1)[0]]}\n",
    "    | {\n",
    "        \"f1\": value[\"f1\"],\n",
    "        \"acc\": value[\"accuracy\"],\n",
    "        \"auroc\": value[\"auroc\"],\n",
    "    }\n",
    "    for key, value in scores.items()\n",
    "]\n",
    "metric_df = (\n",
    "    pd.DataFrame(results)\n",
    "    .set_index(\"domain\")\n",
    "    .sort_index(key=lambda x: list(map(domains.index, x)))\n",
    ")\n",
    "print(metric_df.to_latex(float_format=\"%.3f\", index=True))\n",
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e71e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_detector(\n",
    "#     detector: DetectorABC, datasets: dict[str, DatasetDict]\n",
    "# ) -> dict[str, float]:\n",
    "#     scores = {}\n",
    "#     for config_name, ds in tqdm(datasets.items(), desc=\"Predicting on Datasets\"):\n",
    "#         dataset: Dataset = ds[\"test\"].map(\n",
    "#             detector.tokenize,\n",
    "#             input_columns=[\"text\"],\n",
    "#             batched=True,\n",
    "#             batch_size=1024,\n",
    "#             desc=\"Tokenizing\",\n",
    "#         )\n",
    "#         dataset = dataset.sort(\"length\")\n",
    "#         dataset = dataset.map(\n",
    "#             detector.process,\n",
    "#             batched=True,\n",
    "#             batch_size=128,\n",
    "#             desc=\"Predicting\",\n",
    "#         )\n",
    "\n",
    "#         dataset_np = dataset.select_columns([\"prediction\", \"label\"]).with_format(\n",
    "#             \"numpy\"\n",
    "#         )\n",
    "\n",
    "#         acc, f1, auroc = get_scores(dataset_np[\"label\"], dataset_np[\"prediction\"])\n",
    "#         scores[config_name] = {\"accuracy\": acc, \"f1\": f1, \"auroc\": auroc}\n",
    "\n",
    "#         acc, f1, auroc = get_scores(\n",
    "#             dataset_np[\"label\"],\n",
    "#             dataset_np[\"prediction\"],\n",
    "#             calibrated=True,\n",
    "#         )\n",
    "#         scores[config_name] |= {\n",
    "#             \"accuracy_calibrated\": acc,\n",
    "#             \"f1_calibrated\": f1,\n",
    "#             \"auroc_calibrated\": auroc,\n",
    "#         }\n",
    "#     return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7958c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(model: LuminarClassifier, datasets: dict[str, DatasetDict]) -> dict:\n",
    "#     scores = {}\n",
    "#     for config_name, dataset in tqdm(datasets.items(), desc=\"Evaluating\", leave=False):\n",
    "#         ds = (\n",
    "#             dataset[\"test\"]\n",
    "#             .with_format(\"torch\", [\"features\"])\n",
    "#             .map(model.process, batched=True, batch_size=32, desc=\"Predicting\")\n",
    "#         )\n",
    "#         dataset_np = ds.select_columns([\"prediction\", \"label\"]).with_format(\"numpy\")\n",
    "\n",
    "#         acc, f1, auroc = get_scores(dataset_np[\"label\"], dataset_np[\"prediction\"])\n",
    "#         scores[config_name] = {\n",
    "#             \"accuracy\": acc,\n",
    "#             \"f1\": f1,\n",
    "#             \"auroc\": auroc,\n",
    "#         }\n",
    "\n",
    "#         acc, f1, auroc = get_scores(\n",
    "#             dataset_np[\"label\"],\n",
    "#             dataset_np[\"prediction\"],\n",
    "#             calibrated=True,\n",
    "#         )\n",
    "#         scores[config_name] |= {\n",
    "#             \"accuracy_calibrated\": acc,\n",
    "#             \"f1_calibrated\": f1,\n",
    "#             \"auroc_calibrated\": auroc,\n",
    "#         }\n",
    "\n",
    "#     return scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
