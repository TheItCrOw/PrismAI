{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26864b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from torch import Tensor, nn\n",
    "from tqdm import tqdm\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "from luminar.classifier import LuminarClassifier\n",
    "from luminar.utils import PaddingDataCollator, get_matched_datasets\n",
    "\n",
    "HF_TOKEN = (Path.home() / \".hf_token\").read_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d21c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f065414a",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf68ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from luminar.encoder import LuminarEncoder\n",
    "\n",
    "\n",
    "# encoder = LuminarEncoder()\n",
    "# encoder.device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f7e778",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a429a29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    scores = torch.tensor(logits).sigmoid().cpu().flatten().numpy()\n",
    "    labels = np.array(labels).flatten()\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    metrics[\"acc\"] = float(accuracy_score(labels, scores > 0.5))\n",
    "    metrics[\"f1\"] = float(f1_score(labels, scores > 0.5))\n",
    "\n",
    "    threshold = sorted(scores)[len(labels) - sum(labels) - 1]\n",
    "    metrics[\"acc_calibrated\"] = float(accuracy_score(labels, scores > threshold))\n",
    "    metrics[\"f1_calibrated\"] = float(f1_score(labels, scores > threshold))\n",
    "    metrics[\"threshold\"] = threshold\n",
    "\n",
    "    if sum(labels) == 0 or sum(labels) == len(labels):\n",
    "        auroc = -1\n",
    "    else:\n",
    "        auroc = float(roc_auc_score(labels, scores))\n",
    "    metrics[\"auroc\"] = auroc\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "06afa49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "acc = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    # convert the logits to their predicted class\n",
    "    predictions = np.array(logits) > 0.0\n",
    "    labels = np.array(labels)\n",
    "    # acc.compute(predictions=predictions, references=labels)\n",
    "    f1_score = f1.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    acc_score = acc.compute(predictions=predictions, references=labels)\n",
    "    return f1_score | acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c528f341",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = \"gpt_4o_mini\"\n",
    "feature_len = 256\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c0be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset: Dataset = (\n",
    "    load_dataset(\n",
    "        \"liberi-luminaris/PrismAI-encoded-gpt2\",\n",
    "        \"cnn_news-fulltext\",\n",
    "        split=f\"human+{agent}\",\n",
    "        token=HF_TOKEN,\n",
    "    )  # type: ignore\n",
    "    .map(\n",
    "        lambda features: {\"features\": features[:feature_len]},\n",
    "        input_columns=[\"features\"],\n",
    "        desc=\"Trimming Features\",\n",
    "    )\n",
    "    .rename_column(\"label\", \"labels\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe055ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_matched = get_matched_datasets(dataset, agent)\n",
    "datasets_matched.set_format(\"torch\", columns=[\"labels\", \"features\"])\n",
    "datasets_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d638c20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = datasets_matched[\"train\"].train_test_split(\n",
    "    test_size=1 / 8,\n",
    "    shuffle=True,\n",
    "    seed=seed,\n",
    ").with_format(\n",
    "    \"torch\", columns=[\"labels\", \"features\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe23e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # first 256 features & 13 layers for gpt2\n",
    "    \"feature_dim\": (feature_len, 13),\n",
    "    \"feature_type\": \"intermediate_likelihoods\",\n",
    "    \"feature_selection\": \"first\",\n",
    "    # \"projection_dim\": None,\n",
    "    \"projection_dim\": 32,\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"max_epochs\": 5,\n",
    "    \"gradient_clip_val\": 1.0,\n",
    "    \"train_batch_size\": 32,\n",
    "    \"eval_batch_size\": 1024,\n",
    "    \"seed\": seed,\n",
    "    \"agent\": agent,\n",
    "}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../logs/hf/\",\n",
    "    per_device_train_batch_size=config[\"train_batch_size\"],\n",
    "    per_device_eval_batch_size=config[\"eval_batch_size\"],\n",
    "    learning_rate=config[\"learning_rate\"],\n",
    "    num_train_epochs=config[\"max_epochs\"],\n",
    "    logging_steps=100,\n",
    "    warmup_ratio=1.0,\n",
    "    metric_for_best_model=\"loss\",\n",
    "    load_best_model_at_end=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2055ee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = LuminarClassifier(**config)\n",
    "trainer = Trainer(\n",
    "    model=classifier,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train[\"train\"],\n",
    "    eval_dataset=dataset_train[\"test\"],\n",
    "    data_collator=PaddingDataCollator(config[\"feature_dim\"]),\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(3)],\n",
    ")\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a17f6ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2590530812740326,\n",
       " 'eval_model_preparation_time': 0.0002,\n",
       " 'eval_f1': 0.890358123870099,\n",
       " 'eval_accuracy': 0.890393567498942,\n",
       " 'eval_runtime': 7.8173,\n",
       " 'eval_samples_per_second': 302.28,\n",
       " 'eval_steps_per_second': 0.384}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e879d274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.24068349599838257,\n",
       " 'eval_model_preparation_time': 0.0002,\n",
       " 'eval_f1': 0.8961064161686484,\n",
       " 'eval_accuracy': 0.8961066440964875,\n",
       " 'eval_runtime': 14.8392,\n",
       " 'eval_samples_per_second': 318.48,\n",
       " 'eval_steps_per_second': 0.337}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(datasets_matched[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c34613c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2373393177986145,\n",
       " 'eval_model_preparation_time': 0.0002,\n",
       " 'eval_f1': 0.9464042392127177,\n",
       " 'eval_accuracy': 0.8982612444316712,\n",
       " 'eval_runtime': 21.9345,\n",
       " 'eval_samples_per_second': 317.262,\n",
       " 'eval_steps_per_second': 0.319}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(datasets_matched[\"test_unmatched\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732ce273",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classifier)\n",
    "print(\n",
    "    \"Parameters:\"\n",
    "    \"\\n  conv_layers:\",\n",
    "    sum(\n",
    "        param.numel()\n",
    "        for param in classifier.conv_layers.parameters()\n",
    "        if param.requires_grad\n",
    "    ),\n",
    "    \"\\n  projection:\",\n",
    "    sum(\n",
    "        param.numel()\n",
    "        for param in classifier.projection.parameters()\n",
    "        if param.requires_grad\n",
    "    ),\n",
    "    \"\\n  classifier:\",\n",
    "    sum(\n",
    "        param.numel()\n",
    "        for param in classifier.classifier.parameters()\n",
    "        if param.requires_grad\n",
    "    ),\n",
    "    \"\\n  total:\",\n",
    "    sum(param.numel() for param in classifier.parameters() if param.requires_grad),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05efd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import json\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "scores = {}\n",
    "for config_name, dataset in tqdm(datasets_truncated.items(), desc=\"Training Models\"):\n",
    "    model = LuminarClassifier()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.00005)\n",
    "\n",
    "    dataset_train = dataset[\"train\"].with_format(\"torch\", [\"features\", \"label\"])\n",
    "\n",
    "    tq = tqdm(range(3), desc=\"Training \" + config_name, leave=False)\n",
    "    for i in tq:\n",
    "        for batch in dataset_train.shuffle(i).batch(batch_size=32):\n",
    "            optimizer.zero_grad()\n",
    "            features = batch[\"features\"]\n",
    "            labels = batch[\"label\"].float().unsqueeze(-1)\n",
    "\n",
    "            preds = model(features)\n",
    "\n",
    "            loss = criterion(preds, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            tq.set_postfix_str(f\"loss: {loss.item()}\")\n",
    "\n",
    "    model.eval()\n",
    "    scores[config_name] = evaluate(model, {config_name: dataset})[config_name]\n",
    "    ## OOD Evaluation\n",
    "    # scores[config_name] = evaluate(model, datasets_truncated)\n",
    "\n",
    "    print(config_name, json.dumps(scores[config_name], indent=4))\n",
    "\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ea5390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3542678a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d405f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204bf89b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b95ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47c00fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise RuntimeError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc98970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(scores, indent=4))\n",
    "with open(\"../logs/luminar/gpt2_first_128-3_epochs.json\", \"w\") as f:\n",
    "    json.dump(scores, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d739a695",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for subset in [\n",
    "    \"blog_authorship_corpus\",\n",
    "    \"student_essays\",\n",
    "    \"cnn_news\",\n",
    "    \"euro_court_cases\",\n",
    "    \"house_of_commons\",\n",
    "    \"arxiv_papers\",\n",
    "    \"gutenberg_en\",\n",
    "    \"en\",\n",
    "    \"bundestag\",\n",
    "    \"spiegel_articles\",\n",
    "    \"gutenberg_de\",\n",
    "    \"de\",\n",
    "]:\n",
    "    config_name = f\"{subset}-fulltext\"\n",
    "    datasets[config_name] = load_dataset(\n",
    "        \"liberi-luminaris/PrismAI-encoded-gpt2\",\n",
    "        config_name,\n",
    "        token=HF_TOKEN,\n",
    "        split=\"human+gpt_4o_mini\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531a62b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    \"liberi-luminaris/PrismAI-fulltext\", \"cnn_news\", split=\"human+gpt_4o_mini\"\n",
    ")\n",
    "dataset_human = dataset.filter(lambda sample: sample[\"agent\"] == \"human\")\n",
    "source_ids = set(\n",
    "    dataset_human.shuffle(seed=42).take(len(dataset_human) // 10 * 8)[\"id_source\"]\n",
    ")\n",
    "dataset_train = dataset.filter(lambda sample: sample[\"id_source\"] in source_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ec3e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_truncated = {}\n",
    "for config_name, dataset in datasets.items():\n",
    "    datasets_truncated[config_name] = dataset.with_format(\n",
    "        \"numpy\", columns=[\"features\"], output_all_columns=True\n",
    "    ).map(\n",
    "        lambda batch: {\"features\": batch[\"features\"][:, :256]},\n",
    "        batched=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18961af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_considered = {\n",
    "    key: value\n",
    "    for key, value in datasets_truncated.items()\n",
    "    if not key.startswith(\"de-\") and not key.startswith(\"en-\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2174dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "domains = [\n",
    "    \"Web Blogs\",\n",
    "    \"Essays\",\n",
    "    \"CNN\",\n",
    "    \"ECHR\",\n",
    "    \"HoC\",\n",
    "    \"arXiv\",\n",
    "    \"Gutenberg$_{en}$\",\n",
    "    \"Bundestag$_{de}$\",\n",
    "    \"Spiegel$_{de}$\",\n",
    "    \"Gutenberg$_{de}$\",\n",
    "    \"All$_{en}$\",\n",
    "    \"All$_{de}$\",\n",
    "]\n",
    "name_map = {\n",
    "    \"blog_authorship_corpus\": \"Web Blogs\",\n",
    "    \"student_essays\": \"Essays\",\n",
    "    \"cnn_news\": \"CNN\",\n",
    "    \"euro_court_cases\": \"ECHR\",\n",
    "    \"house_of_commons\": \"HoC\",\n",
    "    \"arxiv_papers\": \"arXiv\",\n",
    "    \"gutenberg_en\": \"Gutenberg$_{en}$\",\n",
    "    \"bundestag\": \"Bundestag$_{de}$\",\n",
    "    \"spiegel_articles\": \"Spiegel$_{de}$\",\n",
    "    \"gutenberg_de\": \"Gutenberg$_{de}$\",\n",
    "    \"en\": \"All$_{en}$\",\n",
    "    \"de\": \"All$_{de}$\",\n",
    "}\n",
    "\n",
    "results = [\n",
    "    {\"domain\": name_map[key.split(\"-\", 1)[0]]}\n",
    "    | {\n",
    "        \"f1\": value[\"f1\"],\n",
    "        \"acc\": value[\"accuracy\"],\n",
    "        \"auroc\": value[\"auroc\"],\n",
    "    }\n",
    "    for key, value in scores.items()\n",
    "]\n",
    "metric_df = (\n",
    "    pd.DataFrame(results)\n",
    "    .set_index(\"domain\")\n",
    "    .sort_index(key=lambda x: list(map(domains.index, x)))\n",
    ")\n",
    "print(metric_df.to_latex(float_format=\"%.3f\", index=True))\n",
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e71e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_detector(\n",
    "#     detector: DetectorABC, datasets: dict[str, DatasetDict]\n",
    "# ) -> dict[str, float]:\n",
    "#     scores = {}\n",
    "#     for config_name, ds in tqdm(datasets.items(), desc=\"Predicting on Datasets\"):\n",
    "#         dataset: Dataset = ds[\"test\"].map(\n",
    "#             detector.tokenize,\n",
    "#             input_columns=[\"text\"],\n",
    "#             batched=True,\n",
    "#             batch_size=1024,\n",
    "#             desc=\"Tokenizing\",\n",
    "#         )\n",
    "#         dataset = dataset.sort(\"length\")\n",
    "#         dataset = dataset.map(\n",
    "#             detector.process,\n",
    "#             batched=True,\n",
    "#             batch_size=128,\n",
    "#             desc=\"Predicting\",\n",
    "#         )\n",
    "\n",
    "#         dataset_np = dataset.select_columns([\"prediction\", \"label\"]).with_format(\n",
    "#             \"numpy\"\n",
    "#         )\n",
    "\n",
    "#         acc, f1, auroc = get_scores(dataset_np[\"label\"], dataset_np[\"prediction\"])\n",
    "#         scores[config_name] = {\"accuracy\": acc, \"f1\": f1, \"auroc\": auroc}\n",
    "\n",
    "#         acc, f1, auroc = get_scores(\n",
    "#             dataset_np[\"label\"],\n",
    "#             dataset_np[\"prediction\"],\n",
    "#             calibrated=True,\n",
    "#         )\n",
    "#         scores[config_name] |= {\n",
    "#             \"accuracy_calibrated\": acc,\n",
    "#             \"f1_calibrated\": f1,\n",
    "#             \"auroc_calibrated\": auroc,\n",
    "#         }\n",
    "#     return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7958c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(model: LuminarClassifier, datasets: dict[str, DatasetDict]) -> dict:\n",
    "#     scores = {}\n",
    "#     for config_name, dataset in tqdm(datasets.items(), desc=\"Evaluating\", leave=False):\n",
    "#         ds = (\n",
    "#             dataset[\"test\"]\n",
    "#             .with_format(\"torch\", [\"features\"])\n",
    "#             .map(model.process, batched=True, batch_size=32, desc=\"Predicting\")\n",
    "#         )\n",
    "#         dataset_np = ds.select_columns([\"prediction\", \"label\"]).with_format(\"numpy\")\n",
    "\n",
    "#         acc, f1, auroc = get_scores(dataset_np[\"label\"], dataset_np[\"prediction\"])\n",
    "#         scores[config_name] = {\n",
    "#             \"accuracy\": acc,\n",
    "#             \"f1\": f1,\n",
    "#             \"auroc\": auroc,\n",
    "#         }\n",
    "\n",
    "#         acc, f1, auroc = get_scores(\n",
    "#             dataset_np[\"label\"],\n",
    "#             dataset_np[\"prediction\"],\n",
    "#             calibrated=True,\n",
    "#         )\n",
    "#         scores[config_name] |= {\n",
    "#             \"accuracy_calibrated\": acc,\n",
    "#             \"f1_calibrated\": f1,\n",
    "#             \"auroc_calibrated\": auroc,\n",
    "#         }\n",
    "\n",
    "#     return scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
