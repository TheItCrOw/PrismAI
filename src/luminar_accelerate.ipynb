{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a39fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26864b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from numpy.typing import NDArray\n",
    "from torch import Tensor, nn\n",
    "from tqdm import tqdm\n",
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments\n",
    "\n",
    "from luminar.classifier import ConvolutionalLayerSpec, LuminarCNN, LuminarCNN2D\n",
    "from luminar.utils import (\n",
    "    PaddingDataCollator,\n",
    "    compute_metrics,\n",
    "    get_matched_datasets,\n",
    "    get_pad_to_fixed_length_fn,\n",
    "    save_model,\n",
    ")\n",
    "\n",
    "HF_TOKEN = (Path.home() / \".hf_token\").read_text().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f065414a",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bf68ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from luminar.encoder import LuminarEncoder\n",
    "\n",
    "\n",
    "# encoder = LuminarEncoder()\n",
    "# encoder.device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f7e778",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c528f341",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_len = 256\n",
    "seed = 42\n",
    "\n",
    "pad_to_fixed_length: Callable[[NDArray], NDArray] = get_pad_to_fixed_length_fn(\n",
    "    feature_len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dbf35dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = \"gpt_4o_mini\"\n",
    "other_agents = \"gemma2_9b\"\n",
    "domain = \"blog_authorship_corpus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4c0be7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91bda6c6ecd042b78eb3e478761ff0f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating o3_mini split:   0%|          | 0/275 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3418297c670e45dba7ba6867cfe50e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating human split:   0%|          | 0/18614 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "900db8df48d0475daf7aa182fbabce37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating nemotron split:   0%|          | 0/1265 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9c38078f2348b4a09cb04ec8fd8606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating gemma2_9b split:   0%|          | 0/14674 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5435d3b5f90c4786ae008f936f30903c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating gpt_4o_mini split:   0%|          | 0/4576 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d3314b492e4f0da06fa0040f149925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating deepseek_r1_1.5b split:   0%|          | 0/182 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc08b10397e4a3094a3120143deedfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating deepseek_r1_32b split:   0%|          | 0/71 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe2fe0a6e4c4aa3940518c3e90fef36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating phi3_3.8b split:   0%|          | 0/3268 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19d6ead407f4746aea16d592109aa18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=8):   0%|          | 0/37864 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300944d7782a49bc878f4d4019576664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Trimming & Padding Features (num_proc=8):   0%|          | 0/37864 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['agent', 'id_sample', 'id_source', 'labels', 'length', 'features'],\n",
       "    num_rows: 37864\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datset_config_name = f\"{domain}-fulltext\"\n",
    "dataset_split_name = f\"human+{agent}+{other_agents}\"\n",
    "dataset: Dataset = (\n",
    "    load_dataset(\n",
    "        \"liberi-luminaris/PrismAI-encoded-gpt2\",\n",
    "        datset_config_name,\n",
    "        split=dataset_split_name,\n",
    "        token=HF_TOKEN,\n",
    "    )  # type: ignore\n",
    "    .rename_column(\"label\", \"labels\")\n",
    "    .filter(\n",
    "        lambda features: len(features) > 0,\n",
    "        input_columns=[\"features\"],\n",
    "        num_proc=8,\n",
    "    )\n",
    "    .with_format(\"numpy\", columns=[\"features\"])\n",
    "    .map(\n",
    "        lambda features: {\"features\": pad_to_fixed_length(features)},\n",
    "        input_columns=[\"features\"],\n",
    "        desc=\"Trimming & Padding Features\",\n",
    "        num_proc=8,\n",
    "    )\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebe055ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930dcdcae04c457ba497bac5aba493cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/37864 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e10274eef904ff985290b040fe3e733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/37864 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9004fe31892f457e8fed1b99f96c6595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/37864 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a054ff9bc4c4d33be396367b052b986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/37864 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f3e10887264267a885adf5d907544f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/37864 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b12923894794622a111e3ba4b65a157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/37864 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets_matched, dataset_unmatched = get_matched_datasets(dataset, agent)\n",
    "datasets_matched.set_format(\"torch\", columns=[\"labels\", \"features\"])\n",
    "dataset_unmatched.set_format(\"torch\", columns=[\"labels\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa53974c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['agent', 'id_sample', 'id_source', 'labels', 'length', 'features'],\n",
       "        num_rows: 6406\n",
       "    })\n",
       "    eval: Dataset({\n",
       "        features: ['agent', 'id_sample', 'id_source', 'labels', 'length', 'features'],\n",
       "        num_rows: 914\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['agent', 'id_sample', 'id_source', 'labels', 'length', 'features'],\n",
       "        num_rows: 1832\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fe23e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # first 256 features & 13 layers for gpt2\n",
    "    \"feature_dim\": (feature_len, 13),\n",
    "    \"feature_type\": \"intermediate_likelihoods\",\n",
    "    \"feature_selection\": \"first\",\n",
    "    \"conv_layer_shapes\": (\n",
    "        ConvolutionalLayerSpec(32, 5),\n",
    "        ConvolutionalLayerSpec(64, 5),\n",
    "        ConvolutionalLayerSpec(32, 3),\n",
    "    ),\n",
    "    \"projection_dim\": (1024, 32),\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"max_epochs\": 25,\n",
    "    \"gradient_clip_val\": 1.0,\n",
    "    \"train_batch_size\": 32,\n",
    "    \"eval_batch_size\": 1024,\n",
    "    \"warmup_ratio\": 1.0,\n",
    "    \"seed\": seed,\n",
    "    \"agent\": agent,\n",
    "    \"domain\": domain,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4748dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The speedups for torchdynamo mostly come with GPU Ampere or higher and which is not detected here.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../logs/hf/\" + hex(hash(json.dumps(config)))[2:],\n",
    "    per_device_train_batch_size=config[\"train_batch_size\"],\n",
    "    per_device_eval_batch_size=config[\"eval_batch_size\"],\n",
    "    learning_rate=config[\"learning_rate\"],\n",
    "    num_train_epochs=config[\"max_epochs\"],\n",
    "    warmup_ratio=config[\"warmup_ratio\"],\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"loss\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    eval_delay=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    torch_compile=True,\n",
    "    torch_compile_mode=\"reduce-overhead\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7405313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LuminarCNN(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv1d(13, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (projection): Sequential(\n",
      "    (0): Linear(in_features=32, out_features=1024, bias=True)\n",
      "    (1): SiLU()\n",
      "    (2): Linear(in_features=1024, out_features=32, bias=True)\n",
      "    (3): SiLU()\n",
      "    (4): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (classifier): Linear(in_features=8192, out_features=1, bias=True)\n",
      "  (criterion): BCEWithLogitsLoss()\n",
      ")\n",
      "Parameters:\n",
      "  conv_layers: 18592 \n",
      "  projection: 66592 \n",
      "  classifier: 8193 \n",
      "  total: 93377\n"
     ]
    }
   ],
   "source": [
    "classifier = LuminarCNN(**config)\n",
    "\n",
    "print(classifier)\n",
    "print(\n",
    "    \"Parameters:\\n  conv_layers:\",\n",
    "    sum(\n",
    "        param.numel()\n",
    "        for param in classifier.conv_layers.parameters()\n",
    "        if param.requires_grad\n",
    "    ),\n",
    "    \"\\n  projection:\",\n",
    "    sum(\n",
    "        param.numel()\n",
    "        for param in classifier.projection.parameters()\n",
    "        if param.requires_grad\n",
    "    ),\n",
    "    \"\\n  classifier:\",\n",
    "    sum(\n",
    "        param.numel()\n",
    "        for param in classifier.classifier.parameters()\n",
    "        if param.requires_grad\n",
    "    ),\n",
    "    \"\\n  total:\",\n",
    "    sum(param.numel() for param in classifier.parameters() if param.requires_grad),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493a1f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_layer_spec = (\n",
    "#     ConvolutionalLayerSpec(8, (7, 1)),\n",
    "#     ConvolutionalLayerSpec(16, (7, 1)),\n",
    "#     ConvolutionalLayerSpec(32, 7),\n",
    "#     ConvolutionalLayerSpec(64, 5),\n",
    "#     ConvolutionalLayerSpec(32, 3),\n",
    "#     ConvolutionalLayerSpec(3, 3),\n",
    "# )\n",
    "\n",
    "# classifier = LuminarCNN2D(conv_layer_shapes=conv_layer_spec, **config)\n",
    "# print(classifier)\n",
    "# print(\"num. parameters:\", sum(1 for p in classifier.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc46492b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0527 12:46:45.950000 15692 torch/_inductor/utils.py:1250] [0/0] Not enough SMs to use max_autotune_gemm mode\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2650' max='5025' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2650/5025 07:26 < 06:40, 5.93 it/s, Epoch 13/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Human</th>\n",
       "      <th>F1 Ai</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>F1 Human Median</th>\n",
       "      <th>F1 Ai Median</th>\n",
       "      <th>F1 Weighted Median</th>\n",
       "      <th>Accuracy Median</th>\n",
       "      <th>Roc Auc Median</th>\n",
       "      <th>Threshold Median</th>\n",
       "      <th>Ground Truth Human</th>\n",
       "      <th>Ground Truth Ai</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.693100</td>\n",
       "      <td>0.693188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.515847</td>\n",
       "      <td>0.514786</td>\n",
       "      <td>0.515317</td>\n",
       "      <td>0.515317</td>\n",
       "      <td>0.515317</td>\n",
       "      <td>0.504259</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.693300</td>\n",
       "      <td>0.693159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.518033</td>\n",
       "      <td>0.516977</td>\n",
       "      <td>0.517505</td>\n",
       "      <td>0.517505</td>\n",
       "      <td>0.517505</td>\n",
       "      <td>0.502709</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.693100</td>\n",
       "      <td>0.693216</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.522976</td>\n",
       "      <td>0.522976</td>\n",
       "      <td>0.522976</td>\n",
       "      <td>0.522976</td>\n",
       "      <td>0.522976</td>\n",
       "      <td>0.493509</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.693200</td>\n",
       "      <td>0.693218</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.538293</td>\n",
       "      <td>0.538293</td>\n",
       "      <td>0.538293</td>\n",
       "      <td>0.538293</td>\n",
       "      <td>0.538293</td>\n",
       "      <td>0.492708</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.692700</td>\n",
       "      <td>0.693485</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555799</td>\n",
       "      <td>0.555799</td>\n",
       "      <td>0.555799</td>\n",
       "      <td>0.555799</td>\n",
       "      <td>0.555799</td>\n",
       "      <td>0.485933</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.693800</td>\n",
       "      <td>0.693044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.566740</td>\n",
       "      <td>0.566740</td>\n",
       "      <td>0.566740</td>\n",
       "      <td>0.566740</td>\n",
       "      <td>0.566740</td>\n",
       "      <td>0.501967</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.692900</td>\n",
       "      <td>0.692967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.560175</td>\n",
       "      <td>0.560175</td>\n",
       "      <td>0.560175</td>\n",
       "      <td>0.560175</td>\n",
       "      <td>0.560175</td>\n",
       "      <td>0.505519</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.693200</td>\n",
       "      <td>0.692609</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.654321</td>\n",
       "      <td>0.406108</td>\n",
       "      <td>0.509847</td>\n",
       "      <td>0.509847</td>\n",
       "      <td>0.571116</td>\n",
       "      <td>0.571116</td>\n",
       "      <td>0.571116</td>\n",
       "      <td>0.571116</td>\n",
       "      <td>0.571116</td>\n",
       "      <td>0.502338</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.692400</td>\n",
       "      <td>0.691161</td>\n",
       "      <td>0.394326</td>\n",
       "      <td>0.619768</td>\n",
       "      <td>0.507047</td>\n",
       "      <td>0.532823</td>\n",
       "      <td>0.532823</td>\n",
       "      <td>0.562363</td>\n",
       "      <td>0.562363</td>\n",
       "      <td>0.562363</td>\n",
       "      <td>0.562363</td>\n",
       "      <td>0.562363</td>\n",
       "      <td>0.505605</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.690100</td>\n",
       "      <td>0.685972</td>\n",
       "      <td>0.342065</td>\n",
       "      <td>0.637829</td>\n",
       "      <td>0.489947</td>\n",
       "      <td>0.532823</td>\n",
       "      <td>0.532823</td>\n",
       "      <td>0.564551</td>\n",
       "      <td>0.564551</td>\n",
       "      <td>0.564551</td>\n",
       "      <td>0.564551</td>\n",
       "      <td>0.564551</td>\n",
       "      <td>0.530294</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.682200</td>\n",
       "      <td>0.676482</td>\n",
       "      <td>0.450194</td>\n",
       "      <td>0.597156</td>\n",
       "      <td>0.523675</td>\n",
       "      <td>0.535011</td>\n",
       "      <td>0.535011</td>\n",
       "      <td>0.579869</td>\n",
       "      <td>0.579869</td>\n",
       "      <td>0.579869</td>\n",
       "      <td>0.579869</td>\n",
       "      <td>0.579869</td>\n",
       "      <td>0.541051</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.677800</td>\n",
       "      <td>0.666586</td>\n",
       "      <td>0.505128</td>\n",
       "      <td>0.631679</td>\n",
       "      <td>0.568404</td>\n",
       "      <td>0.577681</td>\n",
       "      <td>0.577681</td>\n",
       "      <td>0.599562</td>\n",
       "      <td>0.599562</td>\n",
       "      <td>0.599562</td>\n",
       "      <td>0.599562</td>\n",
       "      <td>0.599562</td>\n",
       "      <td>0.537979</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>0.660518</td>\n",
       "      <td>0.655610</td>\n",
       "      <td>0.560399</td>\n",
       "      <td>0.608004</td>\n",
       "      <td>0.613786</td>\n",
       "      <td>0.613786</td>\n",
       "      <td>0.603939</td>\n",
       "      <td>0.603939</td>\n",
       "      <td>0.603939</td>\n",
       "      <td>0.603939</td>\n",
       "      <td>0.603939</td>\n",
       "      <td>0.470919</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.664100</td>\n",
       "      <td>0.658300</td>\n",
       "      <td>0.547677</td>\n",
       "      <td>0.633663</td>\n",
       "      <td>0.590670</td>\n",
       "      <td>0.595186</td>\n",
       "      <td>0.595186</td>\n",
       "      <td>0.597374</td>\n",
       "      <td>0.597374</td>\n",
       "      <td>0.597374</td>\n",
       "      <td>0.597374</td>\n",
       "      <td>0.597374</td>\n",
       "      <td>0.537329</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.664600</td>\n",
       "      <td>0.651029</td>\n",
       "      <td>0.620838</td>\n",
       "      <td>0.606466</td>\n",
       "      <td>0.613652</td>\n",
       "      <td>0.613786</td>\n",
       "      <td>0.613786</td>\n",
       "      <td>0.606127</td>\n",
       "      <td>0.606127</td>\n",
       "      <td>0.606127</td>\n",
       "      <td>0.606127</td>\n",
       "      <td>0.606127</td>\n",
       "      <td>0.492612</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.664800</td>\n",
       "      <td>0.662244</td>\n",
       "      <td>0.691099</td>\n",
       "      <td>0.480938</td>\n",
       "      <td>0.586019</td>\n",
       "      <td>0.612691</td>\n",
       "      <td>0.612691</td>\n",
       "      <td>0.608315</td>\n",
       "      <td>0.608315</td>\n",
       "      <td>0.608315</td>\n",
       "      <td>0.608315</td>\n",
       "      <td>0.608315</td>\n",
       "      <td>0.423245</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.646277</td>\n",
       "      <td>0.631804</td>\n",
       "      <td>0.612795</td>\n",
       "      <td>0.622299</td>\n",
       "      <td>0.622538</td>\n",
       "      <td>0.622538</td>\n",
       "      <td>0.612691</td>\n",
       "      <td>0.612691</td>\n",
       "      <td>0.612691</td>\n",
       "      <td>0.612691</td>\n",
       "      <td>0.612691</td>\n",
       "      <td>0.492218</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.659100</td>\n",
       "      <td>0.645054</td>\n",
       "      <td>0.603949</td>\n",
       "      <td>0.647363</td>\n",
       "      <td>0.625656</td>\n",
       "      <td>0.626915</td>\n",
       "      <td>0.626915</td>\n",
       "      <td>0.628009</td>\n",
       "      <td>0.628009</td>\n",
       "      <td>0.628009</td>\n",
       "      <td>0.628009</td>\n",
       "      <td>0.628009</td>\n",
       "      <td>0.517807</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.656500</td>\n",
       "      <td>0.641453</td>\n",
       "      <td>0.652632</td>\n",
       "      <td>0.624146</td>\n",
       "      <td>0.638389</td>\n",
       "      <td>0.638950</td>\n",
       "      <td>0.638950</td>\n",
       "      <td>0.632385</td>\n",
       "      <td>0.632385</td>\n",
       "      <td>0.632385</td>\n",
       "      <td>0.632385</td>\n",
       "      <td>0.632385</td>\n",
       "      <td>0.487508</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.642900</td>\n",
       "      <td>0.639191</td>\n",
       "      <td>0.668669</td>\n",
       "      <td>0.600724</td>\n",
       "      <td>0.634696</td>\n",
       "      <td>0.637856</td>\n",
       "      <td>0.637856</td>\n",
       "      <td>0.625821</td>\n",
       "      <td>0.625821</td>\n",
       "      <td>0.625821</td>\n",
       "      <td>0.625821</td>\n",
       "      <td>0.625821</td>\n",
       "      <td>0.463196</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.643400</td>\n",
       "      <td>0.649941</td>\n",
       "      <td>0.525308</td>\n",
       "      <td>0.683683</td>\n",
       "      <td>0.604495</td>\n",
       "      <td>0.620350</td>\n",
       "      <td>0.620350</td>\n",
       "      <td>0.647702</td>\n",
       "      <td>0.647702</td>\n",
       "      <td>0.647702</td>\n",
       "      <td>0.647702</td>\n",
       "      <td>0.647702</td>\n",
       "      <td>0.600030</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.643100</td>\n",
       "      <td>0.631400</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.683794</td>\n",
       "      <td>0.645819</td>\n",
       "      <td>0.649891</td>\n",
       "      <td>0.649891</td>\n",
       "      <td>0.654267</td>\n",
       "      <td>0.654267</td>\n",
       "      <td>0.654267</td>\n",
       "      <td>0.654267</td>\n",
       "      <td>0.654267</td>\n",
       "      <td>0.539085</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.646200</td>\n",
       "      <td>0.626321</td>\n",
       "      <td>0.681909</td>\n",
       "      <td>0.610706</td>\n",
       "      <td>0.646307</td>\n",
       "      <td>0.649891</td>\n",
       "      <td>0.649891</td>\n",
       "      <td>0.656455</td>\n",
       "      <td>0.656455</td>\n",
       "      <td>0.656455</td>\n",
       "      <td>0.656455</td>\n",
       "      <td>0.656455</td>\n",
       "      <td>0.455156</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.628300</td>\n",
       "      <td>0.618984</td>\n",
       "      <td>0.643021</td>\n",
       "      <td>0.672956</td>\n",
       "      <td>0.657988</td>\n",
       "      <td>0.658643</td>\n",
       "      <td>0.658643</td>\n",
       "      <td>0.669584</td>\n",
       "      <td>0.669584</td>\n",
       "      <td>0.669584</td>\n",
       "      <td>0.669584</td>\n",
       "      <td>0.669584</td>\n",
       "      <td>0.520648</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.634100</td>\n",
       "      <td>0.612397</td>\n",
       "      <td>0.647919</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.657293</td>\n",
       "      <td>0.657549</td>\n",
       "      <td>0.657549</td>\n",
       "      <td>0.673961</td>\n",
       "      <td>0.673961</td>\n",
       "      <td>0.673961</td>\n",
       "      <td>0.673961</td>\n",
       "      <td>0.673961</td>\n",
       "      <td>0.514005</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.613200</td>\n",
       "      <td>0.617413</td>\n",
       "      <td>0.635118</td>\n",
       "      <td>0.714146</td>\n",
       "      <td>0.674632</td>\n",
       "      <td>0.679431</td>\n",
       "      <td>0.679431</td>\n",
       "      <td>0.673961</td>\n",
       "      <td>0.673961</td>\n",
       "      <td>0.673961</td>\n",
       "      <td>0.673961</td>\n",
       "      <td>0.673961</td>\n",
       "      <td>0.582295</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.604700</td>\n",
       "      <td>0.590762</td>\n",
       "      <td>0.690021</td>\n",
       "      <td>0.670429</td>\n",
       "      <td>0.680225</td>\n",
       "      <td>0.680525</td>\n",
       "      <td>0.680525</td>\n",
       "      <td>0.676149</td>\n",
       "      <td>0.676149</td>\n",
       "      <td>0.676149</td>\n",
       "      <td>0.676149</td>\n",
       "      <td>0.676149</td>\n",
       "      <td>0.483170</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.589100</td>\n",
       "      <td>0.582543</td>\n",
       "      <td>0.693111</td>\n",
       "      <td>0.662069</td>\n",
       "      <td>0.677590</td>\n",
       "      <td>0.678337</td>\n",
       "      <td>0.678337</td>\n",
       "      <td>0.689278</td>\n",
       "      <td>0.689278</td>\n",
       "      <td>0.689278</td>\n",
       "      <td>0.689278</td>\n",
       "      <td>0.689278</td>\n",
       "      <td>0.466738</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.586400</td>\n",
       "      <td>0.573962</td>\n",
       "      <td>0.684685</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.693406</td>\n",
       "      <td>0.693654</td>\n",
       "      <td>0.693654</td>\n",
       "      <td>0.698031</td>\n",
       "      <td>0.698031</td>\n",
       "      <td>0.698031</td>\n",
       "      <td>0.698031</td>\n",
       "      <td>0.698031</td>\n",
       "      <td>0.526634</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.586400</td>\n",
       "      <td>0.563692</td>\n",
       "      <td>0.675513</td>\n",
       "      <td>0.730731</td>\n",
       "      <td>0.703122</td>\n",
       "      <td>0.705689</td>\n",
       "      <td>0.705689</td>\n",
       "      <td>0.713348</td>\n",
       "      <td>0.713348</td>\n",
       "      <td>0.713348</td>\n",
       "      <td>0.713348</td>\n",
       "      <td>0.713348</td>\n",
       "      <td>0.568148</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.551100</td>\n",
       "      <td>0.556794</td>\n",
       "      <td>0.690992</td>\n",
       "      <td>0.715037</td>\n",
       "      <td>0.703014</td>\n",
       "      <td>0.703501</td>\n",
       "      <td>0.703501</td>\n",
       "      <td>0.713348</td>\n",
       "      <td>0.713348</td>\n",
       "      <td>0.713348</td>\n",
       "      <td>0.713348</td>\n",
       "      <td>0.713348</td>\n",
       "      <td>0.542299</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.543100</td>\n",
       "      <td>0.557841</td>\n",
       "      <td>0.674938</td>\n",
       "      <td>0.743640</td>\n",
       "      <td>0.709289</td>\n",
       "      <td>0.713348</td>\n",
       "      <td>0.713348</td>\n",
       "      <td>0.717724</td>\n",
       "      <td>0.717724</td>\n",
       "      <td>0.717724</td>\n",
       "      <td>0.717724</td>\n",
       "      <td>0.717724</td>\n",
       "      <td>0.622881</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.554500</td>\n",
       "      <td>0.563192</td>\n",
       "      <td>0.656876</td>\n",
       "      <td>0.761816</td>\n",
       "      <td>0.709346</td>\n",
       "      <td>0.718818</td>\n",
       "      <td>0.718818</td>\n",
       "      <td>0.730853</td>\n",
       "      <td>0.730853</td>\n",
       "      <td>0.730853</td>\n",
       "      <td>0.730853</td>\n",
       "      <td>0.730853</td>\n",
       "      <td>0.688443</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.520800</td>\n",
       "      <td>0.515671</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.752083</td>\n",
       "      <td>0.738945</td>\n",
       "      <td>0.739606</td>\n",
       "      <td>0.739606</td>\n",
       "      <td>0.735230</td>\n",
       "      <td>0.735230</td>\n",
       "      <td>0.735230</td>\n",
       "      <td>0.735230</td>\n",
       "      <td>0.735230</td>\n",
       "      <td>0.546969</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.522200</td>\n",
       "      <td>0.507646</td>\n",
       "      <td>0.740821</td>\n",
       "      <td>0.733925</td>\n",
       "      <td>0.737373</td>\n",
       "      <td>0.737418</td>\n",
       "      <td>0.737418</td>\n",
       "      <td>0.741794</td>\n",
       "      <td>0.741794</td>\n",
       "      <td>0.741794</td>\n",
       "      <td>0.741794</td>\n",
       "      <td>0.741794</td>\n",
       "      <td>0.485631</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.520700</td>\n",
       "      <td>0.522008</td>\n",
       "      <td>0.695107</td>\n",
       "      <td>0.764306</td>\n",
       "      <td>0.729707</td>\n",
       "      <td>0.734136</td>\n",
       "      <td>0.734136</td>\n",
       "      <td>0.741794</td>\n",
       "      <td>0.741794</td>\n",
       "      <td>0.741794</td>\n",
       "      <td>0.741794</td>\n",
       "      <td>0.741794</td>\n",
       "      <td>0.631634</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.522900</td>\n",
       "      <td>0.593895</td>\n",
       "      <td>0.747780</td>\n",
       "      <td>0.595442</td>\n",
       "      <td>0.671611</td>\n",
       "      <td>0.689278</td>\n",
       "      <td>0.689278</td>\n",
       "      <td>0.737418</td>\n",
       "      <td>0.737418</td>\n",
       "      <td>0.737418</td>\n",
       "      <td>0.737418</td>\n",
       "      <td>0.737418</td>\n",
       "      <td>0.299162</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.505000</td>\n",
       "      <td>0.494125</td>\n",
       "      <td>0.737778</td>\n",
       "      <td>0.745690</td>\n",
       "      <td>0.741734</td>\n",
       "      <td>0.741794</td>\n",
       "      <td>0.741794</td>\n",
       "      <td>0.743982</td>\n",
       "      <td>0.743982</td>\n",
       "      <td>0.743982</td>\n",
       "      <td>0.743982</td>\n",
       "      <td>0.743982</td>\n",
       "      <td>0.515845</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.481000</td>\n",
       "      <td>0.488964</td>\n",
       "      <td>0.728121</td>\n",
       "      <td>0.760041</td>\n",
       "      <td>0.744081</td>\n",
       "      <td>0.745077</td>\n",
       "      <td>0.745077</td>\n",
       "      <td>0.754923</td>\n",
       "      <td>0.754923</td>\n",
       "      <td>0.754923</td>\n",
       "      <td>0.754923</td>\n",
       "      <td>0.754923</td>\n",
       "      <td>0.562841</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.490100</td>\n",
       "      <td>0.527311</td>\n",
       "      <td>0.706468</td>\n",
       "      <td>0.769531</td>\n",
       "      <td>0.737999</td>\n",
       "      <td>0.741794</td>\n",
       "      <td>0.741794</td>\n",
       "      <td>0.741794</td>\n",
       "      <td>0.741794</td>\n",
       "      <td>0.741794</td>\n",
       "      <td>0.741794</td>\n",
       "      <td>0.741794</td>\n",
       "      <td>0.670002</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.481700</td>\n",
       "      <td>0.478455</td>\n",
       "      <td>0.741071</td>\n",
       "      <td>0.751073</td>\n",
       "      <td>0.746072</td>\n",
       "      <td>0.746171</td>\n",
       "      <td>0.746171</td>\n",
       "      <td>0.750547</td>\n",
       "      <td>0.750547</td>\n",
       "      <td>0.750547</td>\n",
       "      <td>0.750547</td>\n",
       "      <td>0.750547</td>\n",
       "      <td>0.513259</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.476700</td>\n",
       "      <td>0.602643</td>\n",
       "      <td>0.636492</td>\n",
       "      <td>0.770740</td>\n",
       "      <td>0.703616</td>\n",
       "      <td>0.718818</td>\n",
       "      <td>0.718818</td>\n",
       "      <td>0.759300</td>\n",
       "      <td>0.759300</td>\n",
       "      <td>0.759300</td>\n",
       "      <td>0.759300</td>\n",
       "      <td>0.759300</td>\n",
       "      <td>0.782767</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.524500</td>\n",
       "      <td>0.530112</td>\n",
       "      <td>0.691635</td>\n",
       "      <td>0.759494</td>\n",
       "      <td>0.725565</td>\n",
       "      <td>0.729759</td>\n",
       "      <td>0.729759</td>\n",
       "      <td>0.754923</td>\n",
       "      <td>0.754923</td>\n",
       "      <td>0.754923</td>\n",
       "      <td>0.754923</td>\n",
       "      <td>0.754923</td>\n",
       "      <td>0.633530</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.486500</td>\n",
       "      <td>0.543845</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.775926</td>\n",
       "      <td>0.726198</td>\n",
       "      <td>0.735230</td>\n",
       "      <td>0.735230</td>\n",
       "      <td>0.763676</td>\n",
       "      <td>0.763676</td>\n",
       "      <td>0.763676</td>\n",
       "      <td>0.763676</td>\n",
       "      <td>0.763676</td>\n",
       "      <td>0.694203</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.490100</td>\n",
       "      <td>0.534789</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>0.737417</td>\n",
       "      <td>0.747265</td>\n",
       "      <td>0.747265</td>\n",
       "      <td>0.757112</td>\n",
       "      <td>0.757112</td>\n",
       "      <td>0.757112</td>\n",
       "      <td>0.757112</td>\n",
       "      <td>0.757112</td>\n",
       "      <td>0.279811</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.492300</td>\n",
       "      <td>0.473192</td>\n",
       "      <td>0.770199</td>\n",
       "      <td>0.749714</td>\n",
       "      <td>0.759957</td>\n",
       "      <td>0.760394</td>\n",
       "      <td>0.760394</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.451565</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.475700</td>\n",
       "      <td>0.472376</td>\n",
       "      <td>0.763130</td>\n",
       "      <td>0.753073</td>\n",
       "      <td>0.758101</td>\n",
       "      <td>0.758206</td>\n",
       "      <td>0.758206</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.466983</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.447500</td>\n",
       "      <td>0.489513</td>\n",
       "      <td>0.739631</td>\n",
       "      <td>0.764583</td>\n",
       "      <td>0.752107</td>\n",
       "      <td>0.752735</td>\n",
       "      <td>0.752735</td>\n",
       "      <td>0.757112</td>\n",
       "      <td>0.757112</td>\n",
       "      <td>0.757112</td>\n",
       "      <td>0.757112</td>\n",
       "      <td>0.757112</td>\n",
       "      <td>0.571031</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.477100</td>\n",
       "      <td>0.484669</td>\n",
       "      <td>0.770042</td>\n",
       "      <td>0.752273</td>\n",
       "      <td>0.761157</td>\n",
       "      <td>0.761488</td>\n",
       "      <td>0.761488</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.450517</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.474800</td>\n",
       "      <td>0.484644</td>\n",
       "      <td>0.736196</td>\n",
       "      <td>0.787759</td>\n",
       "      <td>0.761978</td>\n",
       "      <td>0.764770</td>\n",
       "      <td>0.764770</td>\n",
       "      <td>0.761488</td>\n",
       "      <td>0.761488</td>\n",
       "      <td>0.761488</td>\n",
       "      <td>0.761488</td>\n",
       "      <td>0.761488</td>\n",
       "      <td>0.634145</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.467300</td>\n",
       "      <td>0.505687</td>\n",
       "      <td>0.794752</td>\n",
       "      <td>0.712221</td>\n",
       "      <td>0.753486</td>\n",
       "      <td>0.760394</td>\n",
       "      <td>0.760394</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.296675</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.439500</td>\n",
       "      <td>0.522290</td>\n",
       "      <td>0.703218</td>\n",
       "      <td>0.748231</td>\n",
       "      <td>0.725724</td>\n",
       "      <td>0.727571</td>\n",
       "      <td>0.727571</td>\n",
       "      <td>0.743982</td>\n",
       "      <td>0.743982</td>\n",
       "      <td>0.743982</td>\n",
       "      <td>0.743982</td>\n",
       "      <td>0.743982</td>\n",
       "      <td>0.602056</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='55' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 03:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "early stopping required metric_for_best_model, but did not find eval_loss so early stopping is disabled\n",
      "early stopping required metric_for_best_model, but did not find eval_loss so early stopping is disabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on eval set\n",
      "{\n",
      "    \"eval_loss\": 0.4723757207393646,\n",
      "    \"eval_f1_human\": 0.7631296891747053,\n",
      "    \"eval_f1_ai\": 0.753072625698324,\n",
      "    \"eval_f1_weighted\": 0.7581011574365147,\n",
      "    \"eval_accuracy\": 0.7582056892778993,\n",
      "    \"eval_roc_auc\": 0.7582056892778993,\n",
      "    \"eval_f1_human_median\": 0.7658643326039387,\n",
      "    \"eval_f1_ai_median\": 0.7658643326039387,\n",
      "    \"eval_f1_weighted_median\": 0.7658643326039387,\n",
      "    \"eval_accuracy_median\": 0.7658643326039387,\n",
      "    \"eval_roc_auc_median\": 0.7658643326039387,\n",
      "    \"eval_threshold_median\": 0.4669828712940216,\n",
      "    \"eval_ground_truth_human\": 457,\n",
      "    \"eval_ground_truth_ai\": 457,\n",
      "    \"eval_runtime\": 3.0184,\n",
      "    \"eval_samples_per_second\": 302.81,\n",
      "    \"eval_steps_per_second\": 0.331,\n",
      "    \"epoch\": 13.18407960199005\n",
      "}\n",
      "Evaluating on test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "early stopping required metric_for_best_model, but did not find eval_loss so early stopping is disabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"test_loss\": 0.48548758029937744,\n",
      "    \"test_f1_human\": 0.7638085218306154,\n",
      "    \"test_f1_ai\": 0.7453204764605785,\n",
      "    \"test_f1_weighted\": 0.754564499145597,\n",
      "    \"test_accuracy\": 0.7549126637554585,\n",
      "    \"test_roc_auc\": 0.7549126637554585,\n",
      "    \"test_f1_human_median\": 0.7554585152838428,\n",
      "    \"test_f1_ai_median\": 0.7554585152838428,\n",
      "    \"test_f1_weighted_median\": 0.7554585152838428,\n",
      "    \"test_accuracy_median\": 0.7554585152838428,\n",
      "    \"test_roc_auc_median\": 0.7554585152838428,\n",
      "    \"test_threshold_median\": 0.4562075734138489,\n",
      "    \"test_ground_truth_human\": 916,\n",
      "    \"test_ground_truth_ai\": 916,\n",
      "    \"test_runtime\": 5.9088,\n",
      "    \"test_samples_per_second\": 310.045,\n",
      "    \"test_steps_per_second\": 0.338,\n",
      "    \"epoch\": 13.18407960199005\n",
      "}\n",
      "Evaluating on unmatched set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "early stopping required metric_for_best_model, but did not find eval_loss so early stopping is disabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"unmatched_loss\": 0.711101770401001,\n",
      "    \"unmatched_f1_human\": 0.7261893381767199,\n",
      "    \"unmatched_f1_ai\": 0.4997380217733015,\n",
      "    \"unmatched_f1_weighted\": 0.6306656815620655,\n",
      "    \"unmatched_accuracy\": 0.6460873146622734,\n",
      "    \"unmatched_roc_auc\": 0.6153920472896133,\n",
      "    \"unmatched_f1_human_mean\": 0.6853739055547582,\n",
      "    \"unmatched_f1_ai_mean\": 0.5762613570462014,\n",
      "    \"unmatched_f1_weighted_mean\": 0.6393471048206297,\n",
      "    \"unmatched_accuracy_mean\": 0.6388797364085668,\n",
      "    \"unmatched_roc_auc_mean\": 0.6312046035450574,\n",
      "    \"unmatched_threshold_mean\": 0.35619881749153137,\n",
      "    \"unmatched_ground_truth_human\": 14038,\n",
      "    \"unmatched_ground_truth_ai\": 10242,\n",
      "    \"unmatched_runtime\": 78.9497,\n",
      "    \"unmatched_samples_per_second\": 307.537,\n",
      "    \"unmatched_steps_per_second\": 0.304,\n",
      "    \"epoch\": 13.18407960199005\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=classifier,\n",
    "    args=training_args,\n",
    "    train_dataset=datasets_matched[\"train\"],\n",
    "    eval_dataset=datasets_matched[\"eval\"],\n",
    "    # data_collator=PaddingDataCollator(config[\"feature_dim\"]),\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(5)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06616066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1650' max='5025' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1650/5025 04:34 < 09:22, 6.00 it/s, Epoch 8/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>F1 Human</th>\n",
       "      <th>F1 Ai</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>F1 Human Median</th>\n",
       "      <th>F1 Ai Median</th>\n",
       "      <th>F1 Weighted Median</th>\n",
       "      <th>Accuracy Median</th>\n",
       "      <th>Roc Auc Median</th>\n",
       "      <th>Threshold Median</th>\n",
       "      <th>Ground Truth Human</th>\n",
       "      <th>Ground Truth Ai</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.434900</td>\n",
       "      <td>0.464132</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.765160</td>\n",
       "      <td>0.768730</td>\n",
       "      <td>0.766945</td>\n",
       "      <td>0.766958</td>\n",
       "      <td>0.766958</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.509632</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.430400</td>\n",
       "      <td>0.464665</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.771214</td>\n",
       "      <td>0.762542</td>\n",
       "      <td>0.766878</td>\n",
       "      <td>0.766958</td>\n",
       "      <td>0.766958</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.469459</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.429200</td>\n",
       "      <td>0.467792</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.758465</td>\n",
       "      <td>0.772824</td>\n",
       "      <td>0.765644</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.541059</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.418000</td>\n",
       "      <td>0.464086</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.767721</td>\n",
       "      <td>0.766191</td>\n",
       "      <td>0.766956</td>\n",
       "      <td>0.766958</td>\n",
       "      <td>0.766958</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.494606</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.452100</td>\n",
       "      <td>0.462940</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.764904</td>\n",
       "      <td>0.777423</td>\n",
       "      <td>0.771164</td>\n",
       "      <td>0.771335</td>\n",
       "      <td>0.771335</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.526848</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.408500</td>\n",
       "      <td>0.465042</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.775293</td>\n",
       "      <td>0.762655</td>\n",
       "      <td>0.768974</td>\n",
       "      <td>0.769147</td>\n",
       "      <td>0.769147</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.462333</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.464100</td>\n",
       "      <td>0.464560</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.762014</td>\n",
       "      <td>0.781971</td>\n",
       "      <td>0.771992</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.564801</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.442200</td>\n",
       "      <td>0.459317</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.776931</td>\n",
       "      <td>0.774477</td>\n",
       "      <td>0.775704</td>\n",
       "      <td>0.775711</td>\n",
       "      <td>0.775711</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.492813</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.419900</td>\n",
       "      <td>0.461984</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.780591</td>\n",
       "      <td>0.772114</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.546638</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.455200</td>\n",
       "      <td>0.460499</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.771186</td>\n",
       "      <td>0.755656</td>\n",
       "      <td>0.763421</td>\n",
       "      <td>0.763676</td>\n",
       "      <td>0.763676</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.446511</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.427900</td>\n",
       "      <td>0.459588</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.765295</td>\n",
       "      <td>0.772874</td>\n",
       "      <td>0.769084</td>\n",
       "      <td>0.769147</td>\n",
       "      <td>0.769147</td>\n",
       "      <td>0.770241</td>\n",
       "      <td>0.770241</td>\n",
       "      <td>0.770241</td>\n",
       "      <td>0.770241</td>\n",
       "      <td>0.770241</td>\n",
       "      <td>0.524668</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.435200</td>\n",
       "      <td>0.456131</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.775956</td>\n",
       "      <td>0.775465</td>\n",
       "      <td>0.775711</td>\n",
       "      <td>0.775711</td>\n",
       "      <td>0.775711</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.498913</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.456220</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.773987</td>\n",
       "      <td>0.761798</td>\n",
       "      <td>0.767892</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.460383</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.434200</td>\n",
       "      <td>0.462992</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.768335</td>\n",
       "      <td>0.794634</td>\n",
       "      <td>0.781484</td>\n",
       "      <td>0.782276</td>\n",
       "      <td>0.782276</td>\n",
       "      <td>0.778993</td>\n",
       "      <td>0.778993</td>\n",
       "      <td>0.778993</td>\n",
       "      <td>0.778993</td>\n",
       "      <td>0.778993</td>\n",
       "      <td>0.576560</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.456400</td>\n",
       "      <td>0.489876</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.726582</td>\n",
       "      <td>0.791908</td>\n",
       "      <td>0.759245</td>\n",
       "      <td>0.763676</td>\n",
       "      <td>0.763676</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.669729</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.433500</td>\n",
       "      <td>0.523501</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.726852</td>\n",
       "      <td>0.755187</td>\n",
       "      <td>0.741019</td>\n",
       "      <td>0.741794</td>\n",
       "      <td>0.741794</td>\n",
       "      <td>0.746171</td>\n",
       "      <td>0.746171</td>\n",
       "      <td>0.746171</td>\n",
       "      <td>0.746171</td>\n",
       "      <td>0.746171</td>\n",
       "      <td>0.571582</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.453700</td>\n",
       "      <td>0.456050</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.768700</td>\n",
       "      <td>0.790407</td>\n",
       "      <td>0.779553</td>\n",
       "      <td>0.780088</td>\n",
       "      <td>0.780088</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.558615</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.405300</td>\n",
       "      <td>0.471757</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.778816</td>\n",
       "      <td>0.753757</td>\n",
       "      <td>0.766287</td>\n",
       "      <td>0.766958</td>\n",
       "      <td>0.766958</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.416394</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.437700</td>\n",
       "      <td>0.474661</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.781609</td>\n",
       "      <td>0.760046</td>\n",
       "      <td>0.770828</td>\n",
       "      <td>0.771335</td>\n",
       "      <td>0.771335</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.433063</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.443900</td>\n",
       "      <td>0.485010</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.779456</td>\n",
       "      <td>0.737725</td>\n",
       "      <td>0.758590</td>\n",
       "      <td>0.760394</td>\n",
       "      <td>0.760394</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.365931</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.421000</td>\n",
       "      <td>0.478728</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.732057</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.753125</td>\n",
       "      <td>0.754923</td>\n",
       "      <td>0.754923</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.625872</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.425500</td>\n",
       "      <td>0.451738</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.783527</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.775418</td>\n",
       "      <td>0.775711</td>\n",
       "      <td>0.775711</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.454458</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.432600</td>\n",
       "      <td>0.465142</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.796353</td>\n",
       "      <td>0.760999</td>\n",
       "      <td>0.778676</td>\n",
       "      <td>0.780088</td>\n",
       "      <td>0.780088</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.414045</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.415600</td>\n",
       "      <td>0.459871</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.759725</td>\n",
       "      <td>0.779874</td>\n",
       "      <td>0.769800</td>\n",
       "      <td>0.770241</td>\n",
       "      <td>0.770241</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.578485</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.443000</td>\n",
       "      <td>0.448068</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.771850</td>\n",
       "      <td>0.787751</td>\n",
       "      <td>0.779800</td>\n",
       "      <td>0.780088</td>\n",
       "      <td>0.780088</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.547083</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.414500</td>\n",
       "      <td>0.450112</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.769932</td>\n",
       "      <td>0.787368</td>\n",
       "      <td>0.778650</td>\n",
       "      <td>0.778993</td>\n",
       "      <td>0.778993</td>\n",
       "      <td>0.778993</td>\n",
       "      <td>0.778993</td>\n",
       "      <td>0.778993</td>\n",
       "      <td>0.778993</td>\n",
       "      <td>0.778993</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.409700</td>\n",
       "      <td>0.439669</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.778022</td>\n",
       "      <td>0.779956</td>\n",
       "      <td>0.778989</td>\n",
       "      <td>0.778993</td>\n",
       "      <td>0.778993</td>\n",
       "      <td>0.778993</td>\n",
       "      <td>0.778993</td>\n",
       "      <td>0.778993</td>\n",
       "      <td>0.778993</td>\n",
       "      <td>0.778993</td>\n",
       "      <td>0.504984</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.447400</td>\n",
       "      <td>0.449956</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.795478</td>\n",
       "      <td>0.767251</td>\n",
       "      <td>0.781365</td>\n",
       "      <td>0.782276</td>\n",
       "      <td>0.782276</td>\n",
       "      <td>0.785558</td>\n",
       "      <td>0.785558</td>\n",
       "      <td>0.785558</td>\n",
       "      <td>0.785558</td>\n",
       "      <td>0.785558</td>\n",
       "      <td>0.412202</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.422800</td>\n",
       "      <td>0.440573</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.773626</td>\n",
       "      <td>0.775599</td>\n",
       "      <td>0.774613</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.503477</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.431800</td>\n",
       "      <td>0.521334</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.715182</td>\n",
       "      <td>0.779825</td>\n",
       "      <td>0.747504</td>\n",
       "      <td>0.751641</td>\n",
       "      <td>0.751641</td>\n",
       "      <td>0.754923</td>\n",
       "      <td>0.754923</td>\n",
       "      <td>0.754923</td>\n",
       "      <td>0.754923</td>\n",
       "      <td>0.754923</td>\n",
       "      <td>0.675687</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.418400</td>\n",
       "      <td>0.440322</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.500567</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.409100</td>\n",
       "      <td>0.509271</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.739535</td>\n",
       "      <td>0.768595</td>\n",
       "      <td>0.754065</td>\n",
       "      <td>0.754923</td>\n",
       "      <td>0.754923</td>\n",
       "      <td>0.759300</td>\n",
       "      <td>0.759300</td>\n",
       "      <td>0.759300</td>\n",
       "      <td>0.759300</td>\n",
       "      <td>0.759300</td>\n",
       "      <td>0.585685</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 02:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "early stopping required metric_for_best_model, but did not find eval_loss so early stopping is disabled\n",
      "early stopping required metric_for_best_model, but did not find eval_loss so early stopping is disabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on eval set\n",
      "{\n",
      "    \"eval_loss\": 0.4396685063838959,\n",
      "    \"eval_model_preparation_time\": 0.0028,\n",
      "    \"eval_f1_human\": 0.778021978021978,\n",
      "    \"eval_f1_ai\": 0.7799564270152506,\n",
      "    \"eval_f1_weighted\": 0.7789892025186143,\n",
      "    \"eval_accuracy\": 0.7789934354485777,\n",
      "    \"eval_roc_auc\": 0.7789934354485777,\n",
      "    \"eval_f1_human_median\": 0.7789934354485777,\n",
      "    \"eval_f1_ai_median\": 0.7789934354485777,\n",
      "    \"eval_f1_weighted_median\": 0.7789934354485777,\n",
      "    \"eval_accuracy_median\": 0.7789934354485777,\n",
      "    \"eval_roc_auc_median\": 0.7789934354485777,\n",
      "    \"eval_threshold_median\": 0.5049842596054077,\n",
      "    \"eval_ground_truth_human\": 457,\n",
      "    \"eval_ground_truth_ai\": 457,\n",
      "    \"eval_runtime\": 3.1784,\n",
      "    \"eval_samples_per_second\": 287.563,\n",
      "    \"eval_steps_per_second\": 0.315,\n",
      "    \"epoch\": 8.208955223880597\n",
      "}\n",
      "Evaluating on test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "early stopping required metric_for_best_model, but did not find eval_loss so early stopping is disabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"test_loss\": 0.4434773027896881,\n",
      "    \"test_model_preparation_time\": 0.0028,\n",
      "    \"test_f1_human\": 0.7862881628280665,\n",
      "    \"test_f1_ai\": 0.7779632721202003,\n",
      "    \"test_f1_weighted\": 0.7821257174741334,\n",
      "    \"test_accuracy\": 0.7822052401746725,\n",
      "    \"test_roc_auc\": 0.7822052401746725,\n",
      "    \"test_f1_human_median\": 0.7805676855895196,\n",
      "    \"test_f1_ai_median\": 0.7805676855895196,\n",
      "    \"test_f1_weighted_median\": 0.7805676855895196,\n",
      "    \"test_accuracy_median\": 0.7805676855895196,\n",
      "    \"test_roc_auc_median\": 0.7805676855895196,\n",
      "    \"test_threshold_median\": 0.4700171649456024,\n",
      "    \"test_ground_truth_human\": 916,\n",
      "    \"test_ground_truth_ai\": 916,\n",
      "    \"test_runtime\": 5.9346,\n",
      "    \"test_samples_per_second\": 308.7,\n",
      "    \"test_steps_per_second\": 0.337,\n",
      "    \"epoch\": 8.208955223880597\n",
      "}\n",
      "Evaluating on unmatched set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "early stopping required metric_for_best_model, but did not find eval_loss so early stopping is disabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"unmatched_loss\": 0.6880214214324951,\n",
      "    \"unmatched_model_preparation_time\": 0.0028,\n",
      "    \"unmatched_f1_human\": 0.7347699552009418,\n",
      "    \"unmatched_f1_ai\": 0.5488625618777463,\n",
      "    \"unmatched_f1_weighted\": 0.6563488875561243,\n",
      "    \"unmatched_accuracy\": 0.6659390444810543,\n",
      "    \"unmatched_roc_auc\": 0.6410347646507168,\n",
      "    \"unmatched_f1_human_mean\": 0.703363477141938,\n",
      "    \"unmatched_f1_ai_mean\": 0.5968031870961473,\n",
      "    \"unmatched_f1_weighted_mean\": 0.6584132921893437,\n",
      "    \"unmatched_accuracy_mean\": 0.6581960461285008,\n",
      "    \"unmatched_roc_auc_mean\": 0.6502854388675099,\n",
      "    \"unmatched_threshold_mean\": 0.385267436504364,\n",
      "    \"unmatched_ground_truth_human\": 14038,\n",
      "    \"unmatched_ground_truth_ai\": 10242,\n",
      "    \"unmatched_runtime\": 77.2966,\n",
      "    \"unmatched_samples_per_second\": 314.115,\n",
      "    \"unmatched_steps_per_second\": 0.31,\n",
      "    \"epoch\": 8.208955223880597\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer._load_best_model()\n",
    "classifier = trainer.model\n",
    "\n",
    "metrics_eval = trainer.evaluate()\n",
    "metrics_test = trainer.evaluate(datasets_matched[\"test\"], metric_key_prefix=\"test\")\n",
    "metrics_unmatched = trainer.evaluate(dataset_unmatched, metric_key_prefix=\"unmatched\")\n",
    "\n",
    "path = save_model(trainer, config)\n",
    "\n",
    "print(\"Evaluating on eval set\")\n",
    "metrics_eval = trainer.evaluate()\n",
    "print(json.dumps(metrics_eval, indent=4))\n",
    "\n",
    "print(\"Evaluating on test set\")\n",
    "metrics_test = trainer.evaluate(\n",
    "    datasets_matched[\"test\"],  # type: ignore\n",
    "    metric_key_prefix=\"test\",\n",
    ")\n",
    "print(json.dumps(metrics_test, indent=4))\n",
    "\n",
    "print(\"Evaluating on unmatched set\")\n",
    "metrics_unmatched = trainer.evaluate(\n",
    "    dataset_unmatched,  # type: ignore\n",
    "    metric_key_prefix=\"unmatched\",\n",
    ")\n",
    "print(json.dumps(metrics_unmatched, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ea5390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib.image import AxesImage\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "cubehelix = sns.cubehelix_palette(as_cmap=True)\n",
    "\n",
    "\n",
    "def visualize_features(features: NDArray, cmap=cubehelix, size=4) -> AxesImage:\n",
    "    a = features.shape[0] / features.shape[1]\n",
    "    h, w = (size, size * a) if a > 1 else (size, size / a)\n",
    "    fig, ax = plt.subplots(figsize=(h, w))\n",
    "    fig = ax.imshow(\n",
    "        features,\n",
    "        cmap=cmap,\n",
    "        vmin=min(0.0, features.min()),\n",
    "        vmax=max(1.0, features.max()),\n",
    "        aspect=\"equal\",\n",
    "    )\n",
    "    fig.axes.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4ff18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = datasets_matched[\"test\"][0]\n",
    "print(sample[\"labels\"])\n",
    "features = sample[\"features\"]\n",
    "print(features.shape)\n",
    "visualize_features(features.T)\n",
    "plt.show()\n",
    "\n",
    "conv = (\n",
    "    classifier.conv_layers[:-1](features.T.unsqueeze(0).to(\"cuda\")).cpu().detach()[0].T\n",
    ")\n",
    "print(conv.shape)\n",
    "visualize_features(conv.clip(0, 1).numpy().T)\n",
    "plt.show()\n",
    "\n",
    "ff = classifier.projection[:-1](conv.unsqueeze(0).to(\"cuda\")).cpu().detach()[0]\n",
    "print(ff.shape)\n",
    "visualize_features(ff.numpy().T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3542678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = datasets_matched[\"test\"][-1]\n",
    "print(sample[\"labels\"])\n",
    "features = sample[\"features\"]\n",
    "print(features.shape)\n",
    "visualize_features(features.T)\n",
    "plt.show()\n",
    "\n",
    "conv = (\n",
    "    classifier.conv_layers[:-1](features.T.unsqueeze(0).to(\"cuda\")).cpu().detach()[0].T\n",
    ")\n",
    "print(conv.shape)\n",
    "visualize_features(conv.clip(0, 1).numpy().T)\n",
    "plt.show()\n",
    "\n",
    "ff = classifier.projection[:-1](conv.unsqueeze(0).to(\"cuda\")).cpu().detach()[0]\n",
    "print(ff.shape)\n",
    "visualize_features(ff.numpy().T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204bf89b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b95ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47c00fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise RuntimeError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc98970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(scores, indent=4))\n",
    "with open(\"../logs/luminar/gpt2_first_128-3_epochs.json\", \"w\") as f:\n",
    "    json.dump(scores, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d739a695",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for subset in [\n",
    "    \"blog_authorship_corpus\",\n",
    "    \"student_essays\",\n",
    "    \"cnn_news\",\n",
    "    \"euro_court_cases\",\n",
    "    \"house_of_commons\",\n",
    "    \"arxiv_papers\",\n",
    "    \"gutenberg_en\",\n",
    "    \"en\",\n",
    "    \"bundestag\",\n",
    "    \"spiegel_articles\",\n",
    "    \"gutenberg_de\",\n",
    "    \"de\",\n",
    "]:\n",
    "    datset_config_name = f\"{subset}-fulltext\"\n",
    "    datasets[datset_config_name] = load_dataset(\n",
    "        \"liberi-luminaris/PrismAI-encoded-gpt2\",\n",
    "        datset_config_name,\n",
    "        token=HF_TOKEN,\n",
    "        split=\"human+gpt_4o_mini\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531a62b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    \"liberi-luminaris/PrismAI-fulltext\", \"cnn_news\", split=\"human+gpt_4o_mini\"\n",
    ")\n",
    "dataset_human = dataset.filter(lambda sample: sample[\"agent\"] == \"human\")\n",
    "source_ids = set(\n",
    "    dataset_human.shuffle(seed=42).take(len(dataset_human) // 10 * 8)[\"id_source\"]\n",
    ")\n",
    "dataset_train = dataset.filter(lambda sample: sample[\"id_source\"] in source_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ec3e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_truncated = {}\n",
    "for datset_config_name, dataset in datasets.items():\n",
    "    datasets_truncated[datset_config_name] = dataset.with_format(\n",
    "        \"numpy\", columns=[\"features\"], output_all_columns=True\n",
    "    ).map(\n",
    "        lambda batch: {\"features\": batch[\"features\"][:, :256]},\n",
    "        batched=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18961af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_considered = {\n",
    "    key: value\n",
    "    for key, value in datasets_truncated.items()\n",
    "    if not key.startswith(\"de-\") and not key.startswith(\"en-\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2174dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "domains = [\n",
    "    \"Web Blogs\",\n",
    "    \"Essays\",\n",
    "    \"CNN\",\n",
    "    \"ECHR\",\n",
    "    \"HoC\",\n",
    "    \"arXiv\",\n",
    "    \"Gutenberg$_{en}$\",\n",
    "    \"Bundestag$_{de}$\",\n",
    "    \"Spiegel$_{de}$\",\n",
    "    \"Gutenberg$_{de}$\",\n",
    "    \"All$_{en}$\",\n",
    "    \"All$_{de}$\",\n",
    "]\n",
    "name_map = {\n",
    "    \"blog_authorship_corpus\": \"Web Blogs\",\n",
    "    \"student_essays\": \"Essays\",\n",
    "    \"cnn_news\": \"CNN\",\n",
    "    \"euro_court_cases\": \"ECHR\",\n",
    "    \"house_of_commons\": \"HoC\",\n",
    "    \"arxiv_papers\": \"arXiv\",\n",
    "    \"gutenberg_en\": \"Gutenberg$_{en}$\",\n",
    "    \"bundestag\": \"Bundestag$_{de}$\",\n",
    "    \"spiegel_articles\": \"Spiegel$_{de}$\",\n",
    "    \"gutenberg_de\": \"Gutenberg$_{de}$\",\n",
    "    \"en\": \"All$_{en}$\",\n",
    "    \"de\": \"All$_{de}$\",\n",
    "}\n",
    "\n",
    "results = [\n",
    "    {\"domain\": name_map[key.split(\"-\", 1)[0]]}\n",
    "    | {\n",
    "        \"f1\": value[\"f1\"],\n",
    "        \"acc\": value[\"accuracy\"],\n",
    "        \"auroc\": value[\"auroc\"],\n",
    "    }\n",
    "    for key, value in scores.items()\n",
    "]\n",
    "metric_df = (\n",
    "    pd.DataFrame(results)\n",
    "    .set_index(\"domain\")\n",
    "    .sort_index(key=lambda x: list(map(domains.index, x)))\n",
    ")\n",
    "print(metric_df.to_latex(float_format=\"%.3f\", index=True))\n",
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e71e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_detector(\n",
    "#     detector: DetectorABC, datasets: dict[str, DatasetDict]\n",
    "# ) -> dict[str, float]:\n",
    "#     scores = {}\n",
    "#     for config_name, ds in tqdm(datasets.items(), desc=\"Predicting on Datasets\"):\n",
    "#         dataset: Dataset = ds[\"test\"].map(\n",
    "#             detector.tokenize,\n",
    "#             input_columns=[\"text\"],\n",
    "#             batched=True,\n",
    "#             batch_size=1024,\n",
    "#             desc=\"Tokenizing\",\n",
    "#         )\n",
    "#         dataset = dataset.sort(\"length\")\n",
    "#         dataset = dataset.map(\n",
    "#             detector.process,\n",
    "#             batched=True,\n",
    "#             batch_size=128,\n",
    "#             desc=\"Predicting\",\n",
    "#         )\n",
    "\n",
    "#         dataset_np = dataset.select_columns([\"prediction\", \"label\"]).with_format(\n",
    "#             \"numpy\"\n",
    "#         )\n",
    "\n",
    "#         acc, f1, auroc = get_scores(dataset_np[\"label\"], dataset_np[\"prediction\"])\n",
    "#         scores[config_name] = {\"accuracy\": acc, \"f1\": f1, \"auroc\": auroc}\n",
    "\n",
    "#         acc, f1, auroc = get_scores(\n",
    "#             dataset_np[\"label\"],\n",
    "#             dataset_np[\"prediction\"],\n",
    "#             calibrated=True,\n",
    "#         )\n",
    "#         scores[config_name] |= {\n",
    "#             \"accuracy_calibrated\": acc,\n",
    "#             \"f1_calibrated\": f1,\n",
    "#             \"auroc_calibrated\": auroc,\n",
    "#         }\n",
    "#     return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7958c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(model: LuminarClassifier, datasets: dict[str, DatasetDict]) -> dict:\n",
    "#     scores = {}\n",
    "#     for config_name, dataset in tqdm(datasets.items(), desc=\"Evaluating\", leave=False):\n",
    "#         ds = (\n",
    "#             dataset[\"test\"]\n",
    "#             .with_format(\"torch\", [\"features\"])\n",
    "#             .map(model.process, batched=True, batch_size=32, desc=\"Predicting\")\n",
    "#         )\n",
    "#         dataset_np = ds.select_columns([\"prediction\", \"label\"]).with_format(\"numpy\")\n",
    "\n",
    "#         acc, f1, auroc = get_scores(dataset_np[\"label\"], dataset_np[\"prediction\"])\n",
    "#         scores[config_name] = {\n",
    "#             \"accuracy\": acc,\n",
    "#             \"f1\": f1,\n",
    "#             \"auroc\": auroc,\n",
    "#         }\n",
    "\n",
    "#         acc, f1, auroc = get_scores(\n",
    "#             dataset_np[\"label\"],\n",
    "#             dataset_np[\"prediction\"],\n",
    "#             calibrated=True,\n",
    "#         )\n",
    "#         scores[config_name] |= {\n",
    "#             \"accuracy_calibrated\": acc,\n",
    "#             \"f1_calibrated\": f1,\n",
    "#             \"auroc_calibrated\": auroc,\n",
    "#         }\n",
    "\n",
    "#     return scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
