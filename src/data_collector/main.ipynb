{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "**This is not an experimental notebook.** In here, we implement the (at best) final version(s) of the collector.\n",
    "\n",
    "-------------------\n",
    "\n",
    "A list of possible domains to fetch content from:\n",
    "\n",
    "- Politics\n",
    "    - [German Bundestag](https://www.bundestag.de/) (X)\n",
    "    - [House of Commons](https://reshare.ukdataservice.ac.uk/854292/) (X)\n",
    "- Student/School\n",
    "    - [Kaggle Student Essays](https://www.kaggle.com/competitions/learning-agency-lab-automated-essay-scoring-2/data?select=train.csv) (X)\n",
    "    - Take the english dataset and translate it?\n",
    "- Research\n",
    "    - [Arxiv](https://arxiv.org/search/advanced?advanced=&terms-0-operator=AND&terms-0-term=language+model&terms-0-field=all&classification-physics_archives=all&classification-include_cross_list=include&date-year=&date-filter_by=date_range&date-from_date=2005&date-to_date=2020&date-date_type=submitted_date&abstracts=show&size=50&order=-announced_date_first) (X)\n",
    "    - [I've seen a paper recently that creates full AI written papers. Maybe I can use it.](https://www.kaggle.com/discussions/general/527817#2958636)\n",
    "- News\n",
    "    - [Spiegel Online](https://www.spiegel.de/) (X)\n",
    "    - [CNN Articles](https://www.kaggle.com/datasets/gowrishankarp/newspaper-text-summarization-cnn-dailymail) (X)\n",
    "- Blogs/Tutorials/Forums\n",
    "- Law\n",
    "    - [German Open Legal Data](https://de.openlegaldata.io/) (X)\n",
    "    - [European Court of Human Rights Cases](https://www.kaggle.com/datasets/mathurinache/ecthrnaacl2021/data) (X)\n",
    "- Philosophy\n",
    "    - Gutenberg Project ([ENG](https://www.gutenberg.org/) | [GER](https://www.projekt-gutenberg.org/)) (X)\n",
    "- Literature\n",
    "    - Gutenberg Project ([ENG](https://www.gutenberg.org/) | [GER](https://www.projekt-gutenberg.org/)) (X)\n",
    "- Blogs, Food and Lifestyle\n",
    "    - [Food Blogs](https://detailed.com/food-blogs/)\n",
    "    - [WebBlogs](https://www.kaggle.com/datasets/rtatman/blog-authorship-corpus?select=blogtext.csv) (ENG)\n",
    "- Religion\n",
    "    - [Bible](https://github.com/mxw/grmr/blob/master/src/finaltests/bible.txt) (ENG|GER) (X)\n",
    "- Gaming\n",
    "\n",
    "Interesting Languages:\n",
    "\n",
    "- English\n",
    "- German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    SRC_ROOT_PATH = '/home/staff_homes/kboenisc/home/prismAI/PrismAI/src'\n",
    "    SRC_ROOT_PATH_COLL = '/home/staff_homes/kboenisc/home/prismAI/PrismAI/src/data_collector'\n",
    "    DATA_ROOT_PATH = '/storage/corpora/prismAI/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "\n",
    "# So that it includes local imports. This is some next level python shit import\n",
    "sys.path.insert(0, CONFIG.SRC_ROOT_PATH)\n",
    "sys.path.insert(0, CONFIG.SRC_ROOT_PATH_COLL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'collectors.blog_corpus_collector' from '/home/staff_homes/kboenisc/home/prismAI/PrismAI/src/data_collector/collectors/blog_corpus_collector.py'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collector\n",
    "import collected_item\n",
    "import collectors.bundestag_collector\n",
    "import collectors.house_of_commons_collector\n",
    "import collectors.student_essays_collector\n",
    "import collectors.arxiv_collector\n",
    "import collectors.spiegel_collector\n",
    "import collectors.cnn_news_collector\n",
    "import collectors.open_legal_data_collector\n",
    "import collectors.euro_court_cases_collector\n",
    "import collectors.religion_collector\n",
    "import collectors.gutenberg_collector\n",
    "import collectors.blog_corpus_collector\n",
    "\n",
    "importlib.reload(collector)\n",
    "importlib.reload(collected_item)\n",
    "importlib.reload(collectors.bundestag_collector)\n",
    "importlib.reload(collectors.house_of_commons_collector)\n",
    "importlib.reload(collectors.student_essays_collector)\n",
    "importlib.reload(collectors.arxiv_collector)\n",
    "importlib.reload(collectors.spiegel_collector)\n",
    "importlib.reload(collectors.cnn_news_collector)\n",
    "importlib.reload(collectors.open_legal_data_collector)\n",
    "importlib.reload(collectors.euro_court_cases_collector)\n",
    "importlib.reload(collectors.religion_collector)\n",
    "importlib.reload(collectors.gutenberg_collector)\n",
    "importlib.reload(collectors.blog_corpus_collector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init the Collectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collectors.blog_corpus_collector\n",
    "\n",
    "collection = [\n",
    "    collectors.bundestag_collector.BundestagCollector(CONFIG.DATA_ROOT_PATH),\n",
    "    collectors.house_of_commons_collector.HouseOfCommonsCollector(CONFIG.DATA_ROOT_PATH),\n",
    "    collectors.student_essays_collector.StudentEssaysCollector(CONFIG.DATA_ROOT_PATH),\n",
    "    collectors.arxiv_collector.ArxivCollector(CONFIG.DATA_ROOT_PATH),\n",
    "    collectors.spiegel_collector.SpiegelCollector(CONFIG.DATA_ROOT_PATH),\n",
    "    collectors.cnn_news_collector.CNNNewsCollector(CONFIG.DATA_ROOT_PATH),\n",
    "    collectors.open_legal_data_collector.OpenLegalDataCollector(CONFIG.DATA_ROOT_PATH),\n",
    "    collectors.euro_court_cases_collector.EuroCourtCasesCollector(CONFIG.DATA_ROOT_PATH),\n",
    "    collectors.religion_collector.ReligionCollector(CONFIG.DATA_ROOT_PATH),\n",
    "    collectors.gutenberg_collector.GutenbergCollector(CONFIG.DATA_ROOT_PATH),\n",
    "    collectors.blog_corpus_collector.BlogCorpusCollector(CONFIG.DATA_ROOT_PATH)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ============== Collection started for BUNDESTAG ============== \n",
      "\n",
      "33949 speeches were already collected at 2024-11-22 12:46:44.771996, hence we skip a redundant collection.\n",
      "If you'd like to collect anyway, set the force variable to True.\n",
      "\n",
      "\n",
      " ============== Collection started for HOUSE OF COMMONS ============== \n",
      "\n",
      "53814 speeches were already collected at 2024-11-22 12:47:58.466366, hence we skip a redundant collection.\n",
      "If you'd like to collect anyway, set the force variable to True.\n",
      "\n",
      "\n",
      " ============== Collection started for STUDENT ESSAYS ============== \n",
      "\n",
      "115372 essays were already collected at 2024-11-22 13:02:19.983103, hence we skip a redundant collection.\n",
      "If you'd like to collect anyway, set the force variable to True.\n",
      "\n",
      "\n",
      " ============== Collection started for ARXIV PAPERS ============== \n",
      "\n",
      "9947 papers were already collected at 2024-11-23 15:24:25.733882, hence we skip a redundant collection.\n",
      "If you'd like to collect anyway, set the force variable to True.\n",
      "\n",
      "\n",
      " ============== Collection started for SPIEGEL ARTICLES ============== \n",
      "\n",
      "105281 articles were already collected at 2024-11-23 05:43:32.662209, hence we skip a redundant collection.\n",
      "If you'd like to collect anyway, set the force variable to True.\n",
      "\n",
      "\n",
      " ============== Collection started for CNN NEWS ARTICLES ============== \n",
      "\n",
      "287226 news articles were already collected at 2024-11-24 18:53:06.344810, hence we skip a redundant collection.\n",
      "If you'd like to collect anyway, set the force variable to True.\n",
      "\n",
      "\n",
      " ============== Collection started for OPEN LEGAL DATA ARTICLES ============== \n",
      "\n",
      "920 legal articles were already collected at 2024-12-18 08:31:05.480423, hence we skip a redundant collection.\n",
      "If you'd like to collect anyway, set the force variable to True.\n",
      "\n",
      "\n",
      " ============== Collection started for EURO COURT CASES ============== \n",
      "\n",
      "10100 cases were already collected at 2024-11-25 16:50:58.474519, hence we skip a redundant collection.\n",
      "If you'd like to collect anyway, set the force variable to True.\n",
      "\n",
      "\n",
      " ============== Collection started for RELIGION ============== \n",
      "\n",
      "1478 chapters were already collected at 2024-11-25 16:48:10.369812, hence we skip a redundant collection.\n",
      "If you'd like to collect anyway, set the force variable to True.\n",
      "\n",
      "\n",
      " ============== Collection started for GUTENBERG ============== \n",
      "\n",
      "28350 books were already collected at 2024-12-18 13:16:42.930970, hence we skip a redundant collection.\n",
      "If you'd like to collect anyway, set the force variable to True.\n",
      "\n",
      "\n",
      " ============== Collection started for BLOG AUTHORSHIP CORPUS ============== \n",
      "\n",
      "200002 blogs were already collected at 2024-12-19 10:29:47.655031, hence we skip a redundant collection.\n",
      "If you'd like to collect anyway, set the force variable to True.\n",
      "\n",
      "\n",
      " ==================================================== \n",
      "\n",
      "\n",
      "All collectors finished. Total data items: 846439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/staff_homes/kboenisc/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/staff_homes/kboenisc/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "total_items = 0\n",
    "\n",
    "for coll in collection:\n",
    "    try:\n",
    "        coll.init()\n",
    "        coll.collect()\n",
    "        total_items += coll.get_count()\n",
    "    except Exception as ex:\n",
    "        print('ERROR: Current collection failed due to an error: ')\n",
    "        print(ex)\n",
    "        print('\\n ***** Continuing with the other collectors. ***** \\n')\n",
    "\n",
    "print('\\n\\n ==================================================== \\n\\n')\n",
    "print(f'All collectors finished. Total data items: {total_items}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
