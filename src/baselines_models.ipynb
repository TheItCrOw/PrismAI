{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Luminar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines: Neural Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "# Source: Ghostbuster, Verma et al. (2024)\n",
    "def get_scores(labels, probabilities, calibrated=False, precision=6):\n",
    "    assert len(labels) == len(probabilities)\n",
    "\n",
    "    if calibrated:\n",
    "        threshold = sorted(probabilities)[len(labels) - sum(labels) - 1]\n",
    "    else:\n",
    "        threshold = 0.5\n",
    "\n",
    "    acc = round(float(accuracy_score(labels, probabilities > threshold)), precision)\n",
    "    f1 = round(float(f1_score(labels, probabilities > threshold)), precision)\n",
    "\n",
    "    if sum(labels) == 0 or sum(labels) == len(labels):\n",
    "        auroc = -1\n",
    "    else:\n",
    "        auroc = round(float(roc_auc_score(labels, probabilities)), precision)\n",
    "\n",
    "    return acc, f1, auroc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de09b2520884c8b914503828d351560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/160 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2538ba9e8c0741368e1b8f3e153e4e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.10s/it]\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "datasets = {}\n",
    "for config_name in tqdm(\n",
    "    [\n",
    "        # \"blog_authorship_corpus\",\n",
    "        # \"student_essays\",\n",
    "        # \"cnn_news\",\n",
    "        # \"euro_court_cases\",\n",
    "        # \"house_of_commons\",\n",
    "        # \"arxiv_papers\",\n",
    "        # \"gutenberg_en\",\n",
    "        # \"en\",\n",
    "        # \"bundestag\",\n",
    "        # \"spiegel_articles\",\n",
    "        \"gutenberg_de\",\n",
    "        # \"de\",\n",
    "    ]\n",
    "):\n",
    "    datasets[config_name] = load_dataset(\n",
    "        \"liberi-luminaris/PrismAI\",\n",
    "        f\"{config_name}-fulltext-gpt_4o_mini\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_detector(detector, datasets: dict[str, DatasetDict], batch_size=32):\n",
    "    scores = {}\n",
    "    for config_name, dataset in tqdm(datasets.items(), desc=\"Predicting on Datasets\"):\n",
    "        dataset: Dataset = dataset[\"test\"].map(\n",
    "            detector.tokenize,\n",
    "            input_columns=[\"text\"],\n",
    "            batched=True,\n",
    "            batch_size=1024,\n",
    "            desc=\"Tokenizing\",\n",
    "        )\n",
    "        dataset = dataset.sort(\"length\")\n",
    "        dataset = dataset.map(\n",
    "            detector.process,\n",
    "            batched=True,\n",
    "            batch_size=batch_size,\n",
    "            desc=\"Predicting\",\n",
    "        )\n",
    "\n",
    "        dataset_np = dataset.select_columns([\"prediction\", \"label\"]).with_format(\n",
    "            \"numpy\"\n",
    "        )\n",
    "\n",
    "        acc, f1, auroc = get_scores(dataset_np[\"label\"], dataset_np[\"prediction\"])\n",
    "        scores[config_name] = {\n",
    "            \"accuracy\": acc,\n",
    "            \"f1\": f1,\n",
    "            \"auroc\": auroc,\n",
    "        }\n",
    "\n",
    "        acc, f1, auroc = get_scores(\n",
    "            dataset_np[\"label\"],\n",
    "            dataset_np[\"prediction\"],\n",
    "            calibrated=True,\n",
    "        )\n",
    "        scores[config_name] |= {\n",
    "            \"accuracy_calibrated\": acc,\n",
    "            \"f1_calibrated\": f1,\n",
    "            \"auroc_calibrated\": auroc,\n",
    "        }\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified from: RAID, Dugan et al. 2024\n",
    "# > https://github.com/liamdugan/raid/blob/main/detectors/models/chatgpt_roberta_detector/chatgpt_detector.py\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import DatasetDict\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from transformers.tokenization_utils_base import BatchEncoding\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "class ChatGPTDetector:\n",
    "    def __init__(self, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "        self.device = torch.device(device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            \"Hello-SimpleAI/chatgpt-detector-roberta\"\n",
    "        )\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"Hello-SimpleAI/chatgpt-detector-roberta\"\n",
    "        ).to(self.device)\n",
    "\n",
    "    def reset(self):\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"Hello-SimpleAI/chatgpt-detector-roberta\"\n",
    "        ).to(self.device)\n",
    "\n",
    "    def tokenize(self, texts: list[str]) -> BatchEncoding:\n",
    "        return self.tokenizer(\n",
    "            texts,\n",
    "            padding=False,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_length=True,\n",
    "        )\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def predict(self, inputs: dict) -> list[float]:\n",
    "        encoding = self.tokenizer.pad(inputs, return_tensors=\"pt\").to(self.device)\n",
    "        outputs = self.model(**encoding)\n",
    "        probs = outputs.logits.softmax(dim=-1)\n",
    "        return probs[:, 1].detach().cpu().flatten().tolist()\n",
    "\n",
    "    def process(self, inputs: dict) -> dict[str, list[float]]:\n",
    "        return {\n",
    "            \"prediction\": self.predict(\n",
    "                {\n",
    "                    \"input_ids\": inputs[\"input_ids\"],\n",
    "                    \"attention_mask\": inputs[\"attention_mask\"],\n",
    "                }\n",
    "            )\n",
    "        }\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def inference(self, texts: list) -> list:\n",
    "        predictions = []\n",
    "        for text in tqdm(texts):\n",
    "            inputs = self.tokenizer(text, truncation=True, return_tensors=\"pt\").to(\n",
    "                self.device\n",
    "            )\n",
    "            outputs = self.model(**inputs)\n",
    "            probs = outputs.logits.softmax(dim=-1)\n",
    "            real, fake = probs.detach().cpu().flatten().numpy().tolist()\n",
    "            predictions.append(fake)\n",
    "        return predictions\n",
    "\n",
    "    def train(self, dataset: DatasetDict, training_args: TrainingArguments):\n",
    "        data_collator = DataCollatorWithPadding(tokenizer=self.tokenizer)\n",
    "        trainer = Trainer(\n",
    "            self.model,\n",
    "            training_args,\n",
    "            train_dataset=dataset[\"train\"],\n",
    "            eval_dataset=dataset[\"test\"],\n",
    "            data_collator=data_collator,\n",
    "            compute_metrics=compute_metrics,\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "        self.model = trainer.model.to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f():\n",
    "    results = run_detector(ChatGPTDetector(device=\"cuda:3\"), datasets)\n",
    "    gc.collect()\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.empty_cache()\n",
    "    return results\n",
    "\n",
    "\n",
    "# scores_roberta = f()\n",
    "# scores_roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finetuning:   0%|                                                                                                | 0/1 [00:00<?, ?it/s, gutenberg_de]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dbb40cd8a50410ea557749b3c20e73f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing:   0%|          | 0/160 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5100c331ab4686990369b15559e9ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/home/staff_homes/mastoeck/ray/.venv/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:20, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d279c445edba4b38a5b8f58bad5261d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc3b24a890e44d939c1034f9347e7974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Predicting on Datasets: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.86s/it]\n",
      "Finetuning: 100%|████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:35<00:00, 35.72s/it, gutenberg_de]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"gutenberg_de\": {\n",
      "        \"gutenberg_de\": {\n",
      "            \"accuracy\": 0.5,\n",
      "            \"f1\": 0.0,\n",
      "            \"auroc\": 1.0,\n",
      "            \"accuracy_calibrated\": 1.0,\n",
      "            \"f1_calibrated\": 1.0,\n",
      "            \"auroc_calibrated\": 1.0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "scores_roberta_ft = {}\n",
    "\n",
    "model = ChatGPTDetector(device=\"cuda:0\")\n",
    "dataset_items = list(datasets.items())\n",
    "tq = tqdm(dataset_items, desc=\"Finetuning\")\n",
    "for config, dataset in tq:\n",
    "    tq.set_postfix_str(config)\n",
    "    model.reset()\n",
    "\n",
    "    dataset = dataset.map(\n",
    "        model.tokenize,\n",
    "        input_columns=[\"text\"],\n",
    "        batched=True,\n",
    "        batch_size=1024,\n",
    "        desc=\"Tokenizing\",\n",
    "    )\n",
    "    train_ds = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"../models/chatgpt-detector-roberta/{config}\",\n",
    "        seed=42,\n",
    "        num_train_epochs=1,\n",
    "        per_device_train_batch_size=15,\n",
    "        per_device_eval_batch_size=30,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=50,\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=1e-5,\n",
    "    )\n",
    "    model.train(train_ds, training_args)\n",
    "\n",
    "    scores_roberta_ft[config] = run_detector(model, datasets)\n",
    "\n",
    "    path = Path(\"../logs/chatgpt-detector-roberta/\")\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    with (path / f\"{config}.json\").open(\"w\") as fp:\n",
    "        json.dump(scores_roberta_ft[config], fp, indent=4)\n",
    "\n",
    "\n",
    "print(json.dumps(scores_roberta_ft, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['agent', 'label', 'label_str', 'text', 'input_ids', 'attention_mask', 'length'],\n",
       "        num_rows: 160\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['agent', 'label', 'label_str', 'text', 'input_ids', 'attention_mask', 'length'],\n",
       "        num_rows: 40\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RADAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified from: RAID, Dugan et al. 2024\n",
    "# > https://github.com/liamdugan/raid/blob/main/detectors/models/radar/radar.py\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers.tokenization_utils_base import BatchEncoding\n",
    "\n",
    "\n",
    "class Radar:\n",
    "    def __init__(self, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "        self.device = torch.device(device)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"TrustSafeAI/RADAR-Vicuna-7B\",  # cache_dir=os.environ[\"CACHE_DIR\"]\n",
    "        )\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"TrustSafeAI/RADAR-Vicuna-7B\")\n",
    "        self.model.eval()\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def tokenize(self, texts: list[str]) -> BatchEncoding:\n",
    "        return self.tokenizer(\n",
    "            texts,\n",
    "            padding=False,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_length=True,\n",
    "        )\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def predict(self, inputs: dict) -> list[float]:\n",
    "        encoding = self.tokenizer.pad(inputs, return_tensors=\"pt\").to(self.device)\n",
    "        outputs = self.model(**encoding)\n",
    "        output_probs = F.log_softmax(outputs.logits, -1)[:, 0].exp().tolist()\n",
    "        return output_probs\n",
    "\n",
    "    def process(self, inputs: dict) -> dict[str, list[float]]:\n",
    "        return {\n",
    "            \"prediction\": self.predict(\n",
    "                {\n",
    "                    \"input_ids\": inputs[\"input_ids\"],\n",
    "                    \"attention_mask\": inputs[\"attention_mask\"],\n",
    "                }\n",
    "            )\n",
    "        }\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def inference(self, texts: list) -> list:\n",
    "        predictions = []\n",
    "        for text in tqdm(texts):\n",
    "            with torch.no_grad():\n",
    "                inputs = self.tokenizer(\n",
    "                    [text],\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    max_length=512,\n",
    "                    return_tensors=\"pt\",\n",
    "                )\n",
    "                inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "                output_probs = (\n",
    "                    F.log_softmax(self.model(**inputs).logits, -1)[:, 0].exp().tolist()\n",
    "                )\n",
    "            predictions.append(output_probs[0])\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f():\n",
    "    results = run_detector(Radar(device=\"cuda:3\"), datasets)\n",
    "    gc.collect()\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.empty_cache()\n",
    "    return results\n",
    "\n",
    "\n",
    "scores_radar = f()\n",
    "scores_radar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binoculars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: RAID, Dugan et al. 2024\n",
    "# > https://github.com/liamdugan/raid/blob/main/detectors/models/binoculars/utils/metrics.py\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "ce_loss_fn = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "softmax_fn = torch.nn.Softmax(dim=-1)\n",
    "\n",
    "\n",
    "def perplexity(\n",
    "    encoding: transformers.BatchEncoding,\n",
    "    logits: torch.Tensor,\n",
    "    median: bool = False,\n",
    "    temperature: float = 1.0,\n",
    "):\n",
    "    shifted_logits = logits[..., :-1, :].contiguous() / temperature\n",
    "    shifted_labels = encoding.input_ids[..., 1:].contiguous()\n",
    "    shifted_attention_mask = encoding.attention_mask[..., 1:].contiguous()\n",
    "\n",
    "    if median:\n",
    "        ce_nan = ce_loss_fn(shifted_logits.transpose(1, 2), shifted_labels).masked_fill(\n",
    "            ~shifted_attention_mask.bool(), float(\"nan\")\n",
    "        )\n",
    "        ppl = np.nanmedian(ce_nan.cpu().float().numpy(), 1)\n",
    "\n",
    "    else:\n",
    "        ppl = (\n",
    "            ce_loss_fn(shifted_logits.transpose(1, 2), shifted_labels)\n",
    "            * shifted_attention_mask\n",
    "        ).sum(1) / shifted_attention_mask.sum(1)\n",
    "        ppl = ppl.to(\"cpu\").float().numpy()\n",
    "\n",
    "    return ppl\n",
    "\n",
    "\n",
    "def entropy(\n",
    "    p_logits: torch.Tensor,\n",
    "    q_logits: torch.Tensor,\n",
    "    encoding: transformers.BatchEncoding,\n",
    "    pad_token_id: int,\n",
    "    median: bool = False,\n",
    "    sample_p: bool = False,\n",
    "    temperature: float = 1.0,\n",
    "):\n",
    "    vocab_size = p_logits.shape[-1]\n",
    "    total_tokens_available = q_logits.shape[-2]\n",
    "    p_scores, q_scores = p_logits / temperature, q_logits / temperature\n",
    "\n",
    "    p_proba = softmax_fn(p_scores).view(-1, vocab_size)\n",
    "\n",
    "    if sample_p:\n",
    "        p_proba = torch.multinomial(\n",
    "            p_proba.view(-1, vocab_size), replacement=True, num_samples=1\n",
    "        ).view(-1)\n",
    "\n",
    "    q_scores = q_scores.view(-1, vocab_size)\n",
    "\n",
    "    ce = ce_loss_fn(input=q_scores, target=p_proba).view(-1, total_tokens_available)\n",
    "    padding_mask = (encoding.input_ids != pad_token_id).type(torch.uint8)\n",
    "\n",
    "    if median:\n",
    "        ce_nan = ce.masked_fill(~padding_mask.bool(), float(\"nan\"))\n",
    "        agg_ce = np.nanmedian(ce_nan.cpu().float().numpy(), 1)\n",
    "    else:\n",
    "        agg_ce = (\n",
    "            ((ce * padding_mask).sum(1) / padding_mask.sum(1)).to(\"cpu\").float().numpy()\n",
    "        )\n",
    "\n",
    "    return agg_ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified from: RAID, Dugan et al. 2024\n",
    "# > https://github.com/liamdugan/raid/blob/main/detectors/models/binoculars/binoculars.py\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "GLOBAL_BINOCULARS_THRESHOLD = (\n",
    "    0.9015310749276843  # selected using Falcon-7B and Falcon-7B-Instruct at bfloat16\n",
    ")\n",
    "# DEVICE_1 = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# DEVICE_2 = \"cuda:1\" if torch.cuda.device_count() > 1 else DEVICE_1\n",
    "DEVICE_1 = \"cuda:2\"\n",
    "DEVICE_2 = \"cuda:3\"\n",
    "\n",
    "\n",
    "class Binoculars(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        observer_name_or_path: str = \"tiiuae/falcon-7b\",\n",
    "        performer_name_or_path: str = \"tiiuae/falcon-7b-instruct\",\n",
    "        use_bfloat16: bool = True,\n",
    "        max_token_observed: int = 512,\n",
    "    ) -> None:\n",
    "        # assert_tokenizer_consistency(observer_name_or_path, performer_name_or_path)\n",
    "\n",
    "        self.observer_model = AutoModelForCausalLM.from_pretrained(\n",
    "            observer_name_or_path,\n",
    "            device_map={\"\": DEVICE_1},\n",
    "            trust_remote_code=True,\n",
    "            # cache_dir=os.environ[\"CACHE_DIR\"],\n",
    "            torch_dtype=torch.bfloat16 if use_bfloat16 else torch.float32,\n",
    "        )\n",
    "        self.performer_model = AutoModelForCausalLM.from_pretrained(\n",
    "            performer_name_or_path,\n",
    "            device_map={\"\": DEVICE_2},\n",
    "            trust_remote_code=True,\n",
    "            # cache_dir=os.environ[\"CACHE_DIR\"],\n",
    "            torch_dtype=torch.bfloat16 if use_bfloat16 else torch.float32,\n",
    "        )\n",
    "\n",
    "        self.observer_model.eval()\n",
    "        self.performer_model.eval()\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(observer_name_or_path)\n",
    "        if not self.tokenizer.pad_token:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "        self.max_token_observed = max_token_observed\n",
    "\n",
    "    def tokenize(self, texts: list[str]) -> BatchEncoding:\n",
    "        return self.tokenizer(\n",
    "            texts,\n",
    "            padding=False,\n",
    "            truncation=True,\n",
    "            max_length=self.max_token_observed,\n",
    "            return_length=True,\n",
    "            return_token_type_ids=False,\n",
    "        )\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def _get_logits(\n",
    "        self, encodings: transformers.BatchEncoding\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        observer_logits = self.observer_model(\n",
    "            **encodings.to(self.observer_model.device)\n",
    "        ).logits\n",
    "        performer_logits = self.performer_model(\n",
    "            **encodings.to(self.performer_model.device)\n",
    "        ).logits\n",
    "        if DEVICE_1 != \"cpu\":\n",
    "            torch.cuda.synchronize()\n",
    "        return observer_logits, performer_logits\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def predict(self, inputs: dict) -> list[float]:\n",
    "        encodings = self.tokenizer.pad(inputs, return_tensors=\"pt\")\n",
    "        observer_logits, performer_logits = self._get_logits(encodings)\n",
    "        ppl = perplexity(encodings, performer_logits)\n",
    "        x_ppl = entropy(\n",
    "            observer_logits.to(DEVICE_1),\n",
    "            performer_logits.to(DEVICE_1),\n",
    "            encodings.to(DEVICE_1),\n",
    "            self.tokenizer.pad_token_id,\n",
    "        )\n",
    "        binoculars_scores = ppl / x_ppl\n",
    "        return binoculars_scores.tolist()\n",
    "\n",
    "    def process(self, inputs: dict) -> dict[str, list[float]]:\n",
    "        return {\n",
    "            \"prediction\": self.predict(\n",
    "                {\n",
    "                    \"input_ids\": inputs[\"input_ids\"],\n",
    "                    \"attention_mask\": inputs[\"attention_mask\"],\n",
    "                }\n",
    "            )\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import disable_caching\n",
    "\n",
    "disable_caching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f():\n",
    "    results = run_detector(Binoculars(), datasets, batch_size=16)\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return results\n",
    "\n",
    "\n",
    "scores_binoculars = f()\n",
    "scores_binoculars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E5-Small LoRA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified from: RAID, Dugan et al. 2024\n",
    "# > https://github.com/liamdugan/raid/blob/main/detectors/models/radar/radar.py\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers.tokenization_utils_base import BatchEncoding\n",
    "\n",
    "\n",
    "class E5Lora:\n",
    "    def __init__(self, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "        self.device = torch.device(device)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"MayZhou/e5-small-lora-ai-generated-detector\"\n",
    "        )\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            \"MayZhou/e5-small-lora-ai-generated-detector\"\n",
    "        )\n",
    "        self.model.eval()\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def tokenize(self, texts: list[str]) -> BatchEncoding:\n",
    "        return self.tokenizer(\n",
    "            texts,\n",
    "            padding=False,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_length=True,\n",
    "        )\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def predict(self, inputs: dict) -> list[float]:\n",
    "        encoding = self.tokenizer.pad(inputs, return_tensors=\"pt\").to(self.device)\n",
    "        outputs = self.model(**encoding)\n",
    "        output_probs = F.log_softmax(outputs.logits, -1)[:, 0].exp().tolist()\n",
    "        return output_probs\n",
    "\n",
    "    def process(self, inputs: dict) -> dict[str, list[float]]:\n",
    "        return {\n",
    "            \"prediction\": self.predict(\n",
    "                {\n",
    "                    \"input_ids\": inputs[\"input_ids\"],\n",
    "                    \"attention_mask\": inputs[\"attention_mask\"],\n",
    "                }\n",
    "            )\n",
    "        }\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def inference(self, texts: list) -> list:\n",
    "        predictions = []\n",
    "        for text in tqdm(texts):\n",
    "            with torch.no_grad():\n",
    "                inputs = self.tokenizer(\n",
    "                    [text],\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    max_length=512,\n",
    "                    return_tensors=\"pt\",\n",
    "                )\n",
    "                inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "                output_probs = (\n",
    "                    F.log_softmax(self.model(**inputs).logits, -1)[:, 0].exp().tolist()\n",
    "                )\n",
    "            predictions.append(output_probs[0])\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def f():\n",
    "    results = run_detector(E5Lora(device=\"cuda:0\"), datasets)\n",
    "    gc.collect()\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.empty_cache()\n",
    "    return results\n",
    "\n",
    "\n",
    "scores_e5 = f()\n",
    "\n",
    "with open(\"../logs/e5-small-lora.json\", \"w\") as fp:\n",
    "    json.dump(scores_e5, fp, indent=4)\n",
    "\n",
    "print(json.dumps(scores_e5, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = [\n",
    "    \"Web Blogs\",\n",
    "    \"Essays\",\n",
    "    \"CNN\",\n",
    "    \"ECHR\",\n",
    "    \"HoC\",\n",
    "    \"arXiv\",\n",
    "    \"Gutenberg$_{en}$\",\n",
    "    \"Bundestag$_{de}$\",\n",
    "    \"Spiegel$_{de}$\",\n",
    "    \"Gutenberg$_{de}$\",\n",
    "    \"All$_{en}$\",\n",
    "    \"All$_{de}$\",\n",
    "]\n",
    "\n",
    "name_map = {\n",
    "    \"blog_authorship_corpus\": \"Web Blogs\",\n",
    "    \"student_essays\": \"Essays\",\n",
    "    \"cnn_news\": \"CNN\",\n",
    "    \"euro_court_cases\": \"ECHR\",\n",
    "    \"house_of_commons\": \"HoC\",\n",
    "    \"arxiv_papers\": \"arXiv\",\n",
    "    \"gutenberg_en\": \"Gutenberg$_{en}$\",\n",
    "    \"bundestag\": \"Bundestag$_{de}$\",\n",
    "    \"spiegel_articles\": \"Spiegel$_{de}$\",\n",
    "    \"gutenberg_de\": \"Gutenberg$_{de}$\",\n",
    "    \"en\": \"All$_{en}$\",\n",
    "    \"de\": \"All$_{de}$\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrrrrrrrr}\n",
      "\\toprule\n",
      " & roberta_f1 & roberta_accuracy & roberta_auroc & binoculars_f1 & binoculars_accuracy & binoculars_auroc & e5-small-lora_f1 & e5-small-lora_accuracy & e5-small-lora_auroc & radar_f1 & radar_accuracy & radar_auroc & roberta-ft_f1 & roberta-ft_accuracy & roberta-ft_auroc \\\\\n",
      "domain &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "Web Blogs & 0.481 & 0.658 & 0.998 & 0.667 & 0.500 & 0.126 & 0.022 & 0.328 & 0.147 & 0.670 & 0.587 & 0.524 & 0.996 & 0.996 & 1.000 \\\\\n",
      "Essays & 0.311 & 0.555 & 0.672 & 0.667 & 0.500 & 0.000 & 0.003 & 0.407 & 0.135 & 0.765 & 0.752 & 0.815 & 1.000 & 1.000 & 1.000 \\\\\n",
      "CNN & 0.487 & 0.644 & 0.923 & 0.666 & 0.500 & 0.000 & 0.001 & 0.360 & 0.016 & 0.954 & 0.955 & 0.991 & 0.999 & 0.999 & 1.000 \\\\\n",
      "ECHR & 0.125 & 0.533 & 0.747 & 0.652 & 0.484 & 0.001 & 0.000 & 0.482 & 0.038 & 0.975 & 0.975 & 0.992 & 0.998 & 0.998 & 1.000 \\\\\n",
      "HoC & 0.334 & 0.600 & 0.944 & 0.652 & 0.484 & 0.027 & 0.000 & 0.178 & 0.006 & 0.884 & 0.868 & 0.907 & 0.994 & 0.994 & 0.999 \\\\\n",
      "arXiv & 0.124 & 0.533 & 0.810 & 0.664 & 0.497 & 0.000 & 0.002 & 0.410 & 0.019 & 0.954 & 0.956 & 0.996 & 0.995 & 0.995 & 0.999 \\\\\n",
      "Gutenberg$_{en}$ & 0.183 & 0.551 & 0.981 & 0.667 & 0.500 & 0.003 & 0.011 & 0.071 & 0.006 & 0.850 & 0.845 & 0.918 & 0.948 & 0.949 & 0.989 \\\\\n",
      "Bundestag$_{de}$ & 0.000 & 0.500 & 0.891 & 0.667 & 0.500 & 0.010 & 0.372 & 0.564 & 0.666 & 0.127 & 0.499 & 0.753 & 0.983 & 0.983 & 0.998 \\\\\n",
      "Spiegel$_{de}$ & 0.003 & 0.501 & 0.613 & 0.666 & 0.500 & 0.009 & 0.426 & 0.347 & 0.273 & 0.044 & 0.508 & 0.628 & 0.984 & 0.984 & 0.995 \\\\\n",
      "Gutenberg$_{de}$ & 0.000 & 0.500 & 1.000 & 0.667 & 0.500 & 0.030 & 0.391 & 0.300 & 0.328 & 0.537 & 0.525 & 0.557 & 0.000 & 0.500 & 1.000 \\\\\n",
      "All$_{en}$ & 0.330 & 0.577 & 0.792 & 0.664 & 0.497 & 0.013 & 0.004 & 0.372 & 0.094 & 0.828 & 0.819 & 0.865 & 0.999 & 0.999 & 1.000 \\\\\n",
      "All$_{de}$ & 0.002 & 0.500 & 0.719 & 0.667 & 0.500 & 0.010 & 0.408 & 0.444 & 0.441 & 0.088 & 0.504 & 0.617 & 0.994 & 0.994 & 1.000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "domain",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "roberta_f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "roberta_accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "roberta_auroc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "binoculars_f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "binoculars_accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "binoculars_auroc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "e5-small-lora_f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "e5-small-lora_accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "e5-small-lora_auroc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "radar_f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "radar_accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "radar_auroc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "roberta-ft_f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "roberta-ft_accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "roberta-ft_auroc",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "fda83130-a844-4f50-9d3c-5276a6da4557",
       "rows": [
        [
         "Web Blogs",
         "0.480929",
         "0.658297",
         "0.99795",
         "0.666667",
         "0.5",
         "0.126145",
         "0.02224",
         "0.328057",
         "0.146573",
         "0.670153",
         "0.58679",
         "0.523931",
         "0.995619",
         "0.995633",
         "0.999977"
        ],
        [
         "Essays",
         "0.311258",
         "0.555188",
         "0.672401",
         "0.666667",
         "0.5",
         "0.00023",
         "0.003018",
         "0.407492",
         "0.134682",
         "0.765422",
         "0.751587",
         "0.814824",
         "0.999862",
         "0.999862",
         "1.0"
        ],
        [
         "CNN",
         "0.486569",
         "0.644096",
         "0.92327",
         "0.666479",
         "0.499788",
         "0.000113",
         "0.001321",
         "0.360135",
         "0.015566",
         "0.954192",
         "0.955142",
         "0.99115",
         "0.999365",
         "0.999365",
         "0.999995"
        ],
        [
         "ECHR",
         "0.124533",
         "0.533201",
         "0.747456",
         "0.652349",
         "0.484064",
         "0.001084",
         "0.0",
         "0.482072",
         "0.038128",
         "0.9747",
         "0.974768",
         "0.992053",
         "0.998004",
         "0.998008",
         "0.999986"
        ],
        [
         "HoC",
         "0.333566",
         "0.599749",
         "0.943618",
         "0.652358",
         "0.484074",
         "0.027122",
         "0.0",
         "0.178122",
         "0.005816",
         "0.883617",
         "0.868399",
         "0.906709",
         "0.993684",
         "0.993713",
         "0.999434"
        ],
        [
         "arXiv",
         "0.124183",
         "0.533101",
         "0.809661",
         "0.663873",
         "0.496864",
         "6.4e-05",
         "0.002356",
         "0.409756",
         "0.019123",
         "0.954002",
         "0.955749",
         "0.996115",
         "0.995101",
         "0.995122",
         "0.998943"
        ],
        [
         "Gutenberg$_{en}$",
         "0.183486",
         "0.550505",
         "0.980864",
         "0.666667",
         "0.5",
         "0.003356",
         "0.010753",
         "0.070707",
         "0.006031",
         "0.849673",
         "0.845118",
         "0.917639",
         "0.947917",
         "0.949495",
         "0.989071"
        ],
        [
         "Bundestag$_{de}$",
         "0.0",
         "0.5",
         "0.891183",
         "0.666667",
         "0.5",
         "0.00981",
         "0.371777",
         "0.564115",
         "0.665523",
         "0.127273",
         "0.499006",
         "0.753252",
         "0.983187",
         "0.98335",
         "0.998422"
        ],
        [
         "Spiegel$_{de}$",
         "0.003259",
         "0.500816",
         "0.613273",
         "0.666485",
         "0.499796",
         "0.008735",
         "0.426394",
         "0.347409",
         "0.273244",
         "0.044392",
         "0.50816",
         "0.628063",
         "0.983894",
         "0.983884",
         "0.995226"
        ],
        [
         "Gutenberg$_{de}$",
         "0.0",
         "0.5",
         "1.0",
         "0.666667",
         "0.5",
         "0.03",
         "0.391304",
         "0.3",
         "0.3275",
         "0.536585",
         "0.525",
         "0.5575",
         "0.0",
         "0.5",
         "1.0"
        ],
        [
         "All$_{en}$",
         "0.329821",
         "0.576874",
         "0.791503",
         "0.66441",
         "0.497466",
         "0.012659",
         "0.003799",
         "0.372369",
         "0.093587",
         "0.827755",
         "0.819043",
         "0.865486",
         "0.999331",
         "0.999331",
         "0.999997"
        ],
        [
         "All$_{de}$",
         "0.001783",
         "0.500446",
         "0.718762",
         "0.666568",
         "0.499888",
         "0.009683",
         "0.408081",
         "0.444457",
         "0.440565",
         "0.087813",
         "0.504127",
         "0.616852",
         "0.994099",
         "0.994089",
         "0.999518"
        ]
       ],
       "shape": {
        "columns": 15,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roberta_f1</th>\n",
       "      <th>roberta_accuracy</th>\n",
       "      <th>roberta_auroc</th>\n",
       "      <th>binoculars_f1</th>\n",
       "      <th>binoculars_accuracy</th>\n",
       "      <th>binoculars_auroc</th>\n",
       "      <th>e5-small-lora_f1</th>\n",
       "      <th>e5-small-lora_accuracy</th>\n",
       "      <th>e5-small-lora_auroc</th>\n",
       "      <th>radar_f1</th>\n",
       "      <th>radar_accuracy</th>\n",
       "      <th>radar_auroc</th>\n",
       "      <th>roberta-ft_f1</th>\n",
       "      <th>roberta-ft_accuracy</th>\n",
       "      <th>roberta-ft_auroc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>domain</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Web Blogs</th>\n",
       "      <td>0.480929</td>\n",
       "      <td>0.658297</td>\n",
       "      <td>0.997950</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.126145</td>\n",
       "      <td>0.022240</td>\n",
       "      <td>0.328057</td>\n",
       "      <td>0.146573</td>\n",
       "      <td>0.670153</td>\n",
       "      <td>0.586790</td>\n",
       "      <td>0.523931</td>\n",
       "      <td>0.995619</td>\n",
       "      <td>0.995633</td>\n",
       "      <td>0.999977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Essays</th>\n",
       "      <td>0.311258</td>\n",
       "      <td>0.555188</td>\n",
       "      <td>0.672401</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>0.407492</td>\n",
       "      <td>0.134682</td>\n",
       "      <td>0.765422</td>\n",
       "      <td>0.751587</td>\n",
       "      <td>0.814824</td>\n",
       "      <td>0.999862</td>\n",
       "      <td>0.999862</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>0.486569</td>\n",
       "      <td>0.644096</td>\n",
       "      <td>0.923270</td>\n",
       "      <td>0.666479</td>\n",
       "      <td>0.499788</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.360135</td>\n",
       "      <td>0.015566</td>\n",
       "      <td>0.954192</td>\n",
       "      <td>0.955142</td>\n",
       "      <td>0.991150</td>\n",
       "      <td>0.999365</td>\n",
       "      <td>0.999365</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECHR</th>\n",
       "      <td>0.124533</td>\n",
       "      <td>0.533201</td>\n",
       "      <td>0.747456</td>\n",
       "      <td>0.652349</td>\n",
       "      <td>0.484064</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.482072</td>\n",
       "      <td>0.038128</td>\n",
       "      <td>0.974700</td>\n",
       "      <td>0.974768</td>\n",
       "      <td>0.992053</td>\n",
       "      <td>0.998004</td>\n",
       "      <td>0.998008</td>\n",
       "      <td>0.999986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HoC</th>\n",
       "      <td>0.333566</td>\n",
       "      <td>0.599749</td>\n",
       "      <td>0.943618</td>\n",
       "      <td>0.652358</td>\n",
       "      <td>0.484074</td>\n",
       "      <td>0.027122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.178122</td>\n",
       "      <td>0.005816</td>\n",
       "      <td>0.883617</td>\n",
       "      <td>0.868399</td>\n",
       "      <td>0.906709</td>\n",
       "      <td>0.993684</td>\n",
       "      <td>0.993713</td>\n",
       "      <td>0.999434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arXiv</th>\n",
       "      <td>0.124183</td>\n",
       "      <td>0.533101</td>\n",
       "      <td>0.809661</td>\n",
       "      <td>0.663873</td>\n",
       "      <td>0.496864</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>0.409756</td>\n",
       "      <td>0.019123</td>\n",
       "      <td>0.954002</td>\n",
       "      <td>0.955749</td>\n",
       "      <td>0.996115</td>\n",
       "      <td>0.995101</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.998943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gutenberg$_{en}$</th>\n",
       "      <td>0.183486</td>\n",
       "      <td>0.550505</td>\n",
       "      <td>0.980864</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>0.070707</td>\n",
       "      <td>0.006031</td>\n",
       "      <td>0.849673</td>\n",
       "      <td>0.845118</td>\n",
       "      <td>0.917639</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>0.989071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bundestag$_{de}$</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.891183</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.009810</td>\n",
       "      <td>0.371777</td>\n",
       "      <td>0.564115</td>\n",
       "      <td>0.665523</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.499006</td>\n",
       "      <td>0.753252</td>\n",
       "      <td>0.983187</td>\n",
       "      <td>0.983350</td>\n",
       "      <td>0.998422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spiegel$_{de}$</th>\n",
       "      <td>0.003259</td>\n",
       "      <td>0.500816</td>\n",
       "      <td>0.613273</td>\n",
       "      <td>0.666485</td>\n",
       "      <td>0.499796</td>\n",
       "      <td>0.008735</td>\n",
       "      <td>0.426394</td>\n",
       "      <td>0.347409</td>\n",
       "      <td>0.273244</td>\n",
       "      <td>0.044392</td>\n",
       "      <td>0.508160</td>\n",
       "      <td>0.628063</td>\n",
       "      <td>0.983894</td>\n",
       "      <td>0.983884</td>\n",
       "      <td>0.995226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gutenberg$_{de}$</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.327500</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.557500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All$_{en}$</th>\n",
       "      <td>0.329821</td>\n",
       "      <td>0.576874</td>\n",
       "      <td>0.791503</td>\n",
       "      <td>0.664410</td>\n",
       "      <td>0.497466</td>\n",
       "      <td>0.012659</td>\n",
       "      <td>0.003799</td>\n",
       "      <td>0.372369</td>\n",
       "      <td>0.093587</td>\n",
       "      <td>0.827755</td>\n",
       "      <td>0.819043</td>\n",
       "      <td>0.865486</td>\n",
       "      <td>0.999331</td>\n",
       "      <td>0.999331</td>\n",
       "      <td>0.999997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All$_{de}$</th>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.500446</td>\n",
       "      <td>0.718762</td>\n",
       "      <td>0.666568</td>\n",
       "      <td>0.499888</td>\n",
       "      <td>0.009683</td>\n",
       "      <td>0.408081</td>\n",
       "      <td>0.444457</td>\n",
       "      <td>0.440565</td>\n",
       "      <td>0.087813</td>\n",
       "      <td>0.504127</td>\n",
       "      <td>0.616852</td>\n",
       "      <td>0.994099</td>\n",
       "      <td>0.994089</td>\n",
       "      <td>0.999518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  roberta_f1  roberta_accuracy  roberta_auroc  binoculars_f1  \\\n",
       "domain                                                                         \n",
       "Web Blogs           0.480929          0.658297       0.997950       0.666667   \n",
       "Essays              0.311258          0.555188       0.672401       0.666667   \n",
       "CNN                 0.486569          0.644096       0.923270       0.666479   \n",
       "ECHR                0.124533          0.533201       0.747456       0.652349   \n",
       "HoC                 0.333566          0.599749       0.943618       0.652358   \n",
       "arXiv               0.124183          0.533101       0.809661       0.663873   \n",
       "Gutenberg$_{en}$    0.183486          0.550505       0.980864       0.666667   \n",
       "Bundestag$_{de}$    0.000000          0.500000       0.891183       0.666667   \n",
       "Spiegel$_{de}$      0.003259          0.500816       0.613273       0.666485   \n",
       "Gutenberg$_{de}$    0.000000          0.500000       1.000000       0.666667   \n",
       "All$_{en}$          0.329821          0.576874       0.791503       0.664410   \n",
       "All$_{de}$          0.001783          0.500446       0.718762       0.666568   \n",
       "\n",
       "                  binoculars_accuracy  binoculars_auroc  e5-small-lora_f1  \\\n",
       "domain                                                                      \n",
       "Web Blogs                    0.500000          0.126145          0.022240   \n",
       "Essays                       0.500000          0.000230          0.003018   \n",
       "CNN                          0.499788          0.000113          0.001321   \n",
       "ECHR                         0.484064          0.001084          0.000000   \n",
       "HoC                          0.484074          0.027122          0.000000   \n",
       "arXiv                        0.496864          0.000064          0.002356   \n",
       "Gutenberg$_{en}$             0.500000          0.003356          0.010753   \n",
       "Bundestag$_{de}$             0.500000          0.009810          0.371777   \n",
       "Spiegel$_{de}$               0.499796          0.008735          0.426394   \n",
       "Gutenberg$_{de}$             0.500000          0.030000          0.391304   \n",
       "All$_{en}$                   0.497466          0.012659          0.003799   \n",
       "All$_{de}$                   0.499888          0.009683          0.408081   \n",
       "\n",
       "                  e5-small-lora_accuracy  e5-small-lora_auroc  radar_f1  \\\n",
       "domain                                                                    \n",
       "Web Blogs                       0.328057             0.146573  0.670153   \n",
       "Essays                          0.407492             0.134682  0.765422   \n",
       "CNN                             0.360135             0.015566  0.954192   \n",
       "ECHR                            0.482072             0.038128  0.974700   \n",
       "HoC                             0.178122             0.005816  0.883617   \n",
       "arXiv                           0.409756             0.019123  0.954002   \n",
       "Gutenberg$_{en}$                0.070707             0.006031  0.849673   \n",
       "Bundestag$_{de}$                0.564115             0.665523  0.127273   \n",
       "Spiegel$_{de}$                  0.347409             0.273244  0.044392   \n",
       "Gutenberg$_{de}$                0.300000             0.327500  0.536585   \n",
       "All$_{en}$                      0.372369             0.093587  0.827755   \n",
       "All$_{de}$                      0.444457             0.440565  0.087813   \n",
       "\n",
       "                  radar_accuracy  radar_auroc  roberta-ft_f1  \\\n",
       "domain                                                         \n",
       "Web Blogs               0.586790     0.523931       0.995619   \n",
       "Essays                  0.751587     0.814824       0.999862   \n",
       "CNN                     0.955142     0.991150       0.999365   \n",
       "ECHR                    0.974768     0.992053       0.998004   \n",
       "HoC                     0.868399     0.906709       0.993684   \n",
       "arXiv                   0.955749     0.996115       0.995101   \n",
       "Gutenberg$_{en}$        0.845118     0.917639       0.947917   \n",
       "Bundestag$_{de}$        0.499006     0.753252       0.983187   \n",
       "Spiegel$_{de}$          0.508160     0.628063       0.983894   \n",
       "Gutenberg$_{de}$        0.525000     0.557500       0.000000   \n",
       "All$_{en}$              0.819043     0.865486       0.999331   \n",
       "All$_{de}$              0.504127     0.616852       0.994099   \n",
       "\n",
       "                  roberta-ft_accuracy  roberta-ft_auroc  \n",
       "domain                                                   \n",
       "Web Blogs                    0.995633          0.999977  \n",
       "Essays                       0.999862          1.000000  \n",
       "CNN                          0.999365          0.999995  \n",
       "ECHR                         0.998008          0.999986  \n",
       "HoC                          0.993713          0.999434  \n",
       "arXiv                        0.995122          0.998943  \n",
       "Gutenberg$_{en}$             0.949495          0.989071  \n",
       "Bundestag$_{de}$             0.983350          0.998422  \n",
       "Spiegel$_{de}$               0.983884          0.995226  \n",
       "Gutenberg$_{de}$             0.500000          1.000000  \n",
       "All$_{en}$                   0.999331          0.999997  \n",
       "All$_{de}$                   0.994089          0.999518  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "results = defaultdict(dict)\n",
    "for path in Path(\"../logs/\").iterdir():\n",
    "    if path.suffix == \".json\":\n",
    "        with path.open(\"r\") as fp:\n",
    "            data = json.load(fp)\n",
    "        model_name = path.stem\n",
    "        for domain, scores in data.items():\n",
    "            results[name_map[domain]].update(\n",
    "                {\n",
    "                    model_name + \"_f1\": scores[\"f1\"],\n",
    "                    model_name + \"_accuracy\": scores[\"accuracy\"],\n",
    "                    model_name + \"_auroc\": scores[\"auroc\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "model_name = \"roberta-ft\"\n",
    "for domain, name in name_map.items():\n",
    "    path = Path(\"../logs/chatgpt-detector-roberta/\") / (domain + \".json\")\n",
    "    with (path).open(\"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "    results[name].update(\n",
    "        {\n",
    "            model_name + \"_f1\": data[domain][\"f1\"],\n",
    "            model_name + \"_accuracy\": data[domain][\"accuracy\"],\n",
    "            model_name + \"_auroc\": data[domain][\"auroc\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "metric_df = (\n",
    "    pd.DataFrame([{\"domain\": domain} | dd for domain, dd in results.items()])\n",
    "    .set_index(\"domain\")\n",
    "    .sort_index(key=lambda x: list(map(domains.index, x)))\n",
    ")\n",
    "print(metric_df.to_latex(float_format=\"%.3f\", index=True))\n",
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      " & roberta-ft_f1 & roberta-ft_auroc \\\\\n",
      "domain &  &  \\\\\n",
      "\\midrule\n",
      "Web Blogs & 0.996 & 1.000 \\\\\n",
      "Essays & 1.000 & 1.000 \\\\\n",
      "CNN & 0.999 & 1.000 \\\\\n",
      "ECHR & 0.998 & 1.000 \\\\\n",
      "HoC & 0.994 & 0.999 \\\\\n",
      "arXiv & 0.995 & 0.999 \\\\\n",
      "Gutenberg$_{en}$ & 0.948 & 0.989 \\\\\n",
      "Bundestag$_{de}$ & 0.983 & 0.998 \\\\\n",
      "Spiegel$_{de}$ & 0.984 & 0.995 \\\\\n",
      "Gutenberg$_{de}$ & 0.000 & 1.000 \\\\\n",
      "All$_{en}$ & 0.999 & 1.000 \\\\\n",
      "All$_{de}$ & 0.994 & 1.000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "domain",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "roberta-ft_f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "roberta-ft_auroc",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ed52ccd0-3254-4b47-aa0f-51d504ce593d",
       "rows": [
        [
         "Web Blogs",
         "0.995619",
         "0.999977"
        ],
        [
         "Essays",
         "0.999862",
         "1.0"
        ],
        [
         "CNN",
         "0.999365",
         "0.999995"
        ],
        [
         "ECHR",
         "0.998004",
         "0.999986"
        ],
        [
         "HoC",
         "0.993684",
         "0.999434"
        ],
        [
         "arXiv",
         "0.995101",
         "0.998943"
        ],
        [
         "Gutenberg$_{en}$",
         "0.947917",
         "0.989071"
        ],
        [
         "Bundestag$_{de}$",
         "0.983187",
         "0.998422"
        ],
        [
         "Spiegel$_{de}$",
         "0.983894",
         "0.995226"
        ],
        [
         "Gutenberg$_{de}$",
         "0.0",
         "1.0"
        ],
        [
         "All$_{en}$",
         "0.999331",
         "0.999997"
        ],
        [
         "All$_{de}$",
         "0.994099",
         "0.999518"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roberta-ft_f1</th>\n",
       "      <th>roberta-ft_auroc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>domain</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Web Blogs</th>\n",
       "      <td>0.995619</td>\n",
       "      <td>0.999977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Essays</th>\n",
       "      <td>0.999862</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>0.999365</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECHR</th>\n",
       "      <td>0.998004</td>\n",
       "      <td>0.999986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HoC</th>\n",
       "      <td>0.993684</td>\n",
       "      <td>0.999434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arXiv</th>\n",
       "      <td>0.995101</td>\n",
       "      <td>0.998943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gutenberg$_{en}$</th>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.989071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bundestag$_{de}$</th>\n",
       "      <td>0.983187</td>\n",
       "      <td>0.998422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spiegel$_{de}$</th>\n",
       "      <td>0.983894</td>\n",
       "      <td>0.995226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gutenberg$_{de}$</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All$_{en}$</th>\n",
       "      <td>0.999331</td>\n",
       "      <td>0.999997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All$_{de}$</th>\n",
       "      <td>0.994099</td>\n",
       "      <td>0.999518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  roberta-ft_f1  roberta-ft_auroc\n",
       "domain                                           \n",
       "Web Blogs              0.995619          0.999977\n",
       "Essays                 0.999862          1.000000\n",
       "CNN                    0.999365          0.999995\n",
       "ECHR                   0.998004          0.999986\n",
       "HoC                    0.993684          0.999434\n",
       "arXiv                  0.995101          0.998943\n",
       "Gutenberg$_{en}$       0.947917          0.989071\n",
       "Bundestag$_{de}$       0.983187          0.998422\n",
       "Spiegel$_{de}$         0.983894          0.995226\n",
       "Gutenberg$_{de}$       0.000000          1.000000\n",
       "All$_{en}$             0.999331          0.999997\n",
       "All$_{de}$             0.994099          0.999518"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = defaultdict(dict)\n",
    "\n",
    "model_name = \"roberta-ft\"\n",
    "for domain, name in name_map.items():\n",
    "    path = Path(\"../logs/chatgpt-detector-roberta/\") / (domain + \".json\")\n",
    "    with (path).open(\"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "    results[name].update(\n",
    "        {\n",
    "            model_name + \"_f1\": data[domain][\"f1\"],\n",
    "            # model_name + \"_accuracy\": data[domain][\"accuracy\"],\n",
    "            model_name + \"_auroc\": data[domain][\"auroc\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "metric_df = (\n",
    "    pd.DataFrame([{\"domain\": domain} | dd for domain, dd in results.items()])\n",
    "    .set_index(\"domain\")\n",
    "    .sort_index(key=lambda x: list(map(domains.index, x)))\n",
    ")\n",
    "print(metric_df.to_latex(float_format=\"%.3f\", index=True))\n",
    "metric_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
