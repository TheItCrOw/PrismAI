{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-18T08:59:26.190649Z",
     "start_time": "2025-09-18T08:59:25.870535Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T09:00:23.609322Z",
     "start_time": "2025-09-18T08:59:26.495056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import torch\n",
    "import wandb\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, str(Path().resolve().parent))\n",
    "\n",
    "from luminar.utils import get_best_device\n",
    "from luminar.utils import LuminarSequenceTrainingConfig, ConvolutionalLayerSpec\n",
    "from luminar.sequence_trainer import LuminarSequenceTrainer\n",
    "from luminar.encoder import LuminarEncoder\n",
    "from data_hub.sequential_data_processor import SequentialDataProcessor\n",
    "from data_hub.hub import DataHub\n",
    "\n",
    "device = get_best_device()\n",
    "print(device)"
   ],
   "id": "75ba7872610f2cee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T09:00:55.096878Z",
     "start_time": "2025-09-18T09:00:23.814801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_hub = DataHub((Path.home() / \".hf_token\").read_text().strip())\n",
    "dataset = data_hub.get_splits(\"TheItCrOw/RAID_none-encoded-gpt2\")\n",
    "print(dataset)"
   ],
   "id": "5abe49e29123476a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/57 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "056854e1117746a6a1b3571df98e8d16"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/57 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7513d1ab6243402296cb8b6a46b8f058"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/55 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2016a331632d40ccbca64115bb964b27"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label ID mapping:\n",
      "0 → human\n",
      "1 → ai\n",
      "2 → fusion\n",
      "train distribution:\n",
      "  ai: 444035 (96.9%)\n",
      "  human: 14402 (3.1%)\n",
      "eval distribution:\n",
      "  ai: 63434 (96.9%)\n",
      "  human: 2057 (3.1%)\n",
      "test distribution:\n",
      "  ai: 126867 (96.9%)\n",
      "  human: 4115 (3.1%)\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'text', 'domain', 'date', 'source', 'lang', 'label', 'agent', 'type', 'offset_mapping', 'length', 'features', 'feature_length'],\n",
      "        num_rows: 458437\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['id', 'text', 'domain', 'date', 'source', 'lang', 'label', 'agent', 'type', 'offset_mapping', 'length', 'features', 'feature_length'],\n",
      "        num_rows: 65491\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'text', 'domain', 'date', 'source', 'lang', 'label', 'agent', 'type', 'offset_mapping', 'length', 'features', 'feature_length'],\n",
      "        num_rows: 130982\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T10:04:03.434420Z",
     "start_time": "2025-09-18T09:00:55.151782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_processor = SequentialDataProcessor(LuminarEncoder(\"gpt2\", device=device))\n",
    "dataset = data_processor.process_for_training(dataset)\n",
    "print(dataset)"
   ],
   "id": "1f9edab86b25bf7e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/staff_homes/kboenisc/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tokenizing text and extracting offsets:   0%|          | 0/458437 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0c38d3e3da4e430492c1a785ab14ce21"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tokenizing text and extracting offsets:   0%|          | 0/65491 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "25728065e4a640f99ed18559ab3d60fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tokenizing text and extracting offsets:   0%|          | 0/130982 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a77c8b77ed5442ada336cd95bc2b5ad9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Assigning sentence spans to tokenized text:   0%|          | 0/458437 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ef55df6df7b43379967e3293fccea83"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Assigning sentence spans to tokenized text:   0%|          | 0/65491 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "57770f3570eb44d8b4ab0828e598ed99"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Assigning sentence spans to tokenized text:   0%|          | 0/130982 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c03c909d5984f209b06144d7c7b63f6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Assigning labels to sentence spans:   0%|          | 0/458437 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60225aa0356945e294675e69b4b551d6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Assigning labels to sentence spans:   0%|          | 0/65491 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "182cc8cd2f6c47939c6b84843ccc66f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Assigning labels to sentence spans:   0%|          | 0/130982 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "091f3c8d7ad7414d8153bbd481ce40e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'text', 'domain', 'date', 'source', 'lang', 'label', 'agent', 'type', 'length', 'features', 'feature_length', 'tokenized_text', 'sentence_token_spans', 'span_labels'],\n",
      "        num_rows: 458437\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['id', 'text', 'domain', 'date', 'source', 'lang', 'label', 'agent', 'type', 'length', 'features', 'feature_length', 'tokenized_text', 'sentence_token_spans', 'span_labels'],\n",
      "        num_rows: 65491\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'text', 'domain', 'date', 'source', 'lang', 'label', 'agent', 'type', 'length', 'features', 'feature_length', 'tokenized_text', 'sentence_token_spans', 'span_labels'],\n",
      "        num_rows: 130982\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T10:43:55.727898Z",
     "start_time": "2025-09-18T10:04:03.616256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset, test_dataset, test_loader = data_processor.dataset_to_luminar_sequence_dataset(dataset)\n",
    "train_dataset"
   ],
   "id": "a7321f432b21431c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<luminar.utils.training.LuminarSequenceDataset at 0x7b5de5dd50a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T10:43:57.374207Z",
     "start_time": "2025-09-18T10:43:55.880708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "falcon_config = LuminarSequenceTrainingConfig(**{\n",
    "    \"feature_len\": 512,\n",
    "    \"num_intermediate_likelihoods\": 33,\n",
    "    \"conv_layer_shapes\": (\n",
    "        ConvolutionalLayerSpec(128, 5),\n",
    "        ConvolutionalLayerSpec(256, 5),\n",
    "    ),\n",
    "    \"projection_dim\": 128,\n",
    "    \"lstm_hidden_dim\": 256,\n",
    "    \"lstm_layers\": 1,\n",
    "    \"apply_delta_augmentation\": False,\n",
    "    \"apply_product_augmentation\": True,\n",
    "    \"max_epochs\": 115,\n",
    "    \"kfold\": 3,\n",
    "    \"early_stopping_patience\": 8,\n",
    "    \"learning_rate\": 1.03e-3,\n",
    "    \"batch_size\": 64,\n",
    "    \"seed\": 42,\n",
    "    \"rescale_features\": False,\n",
    "    \"stack_spans\": 3\n",
    "})\n",
    "\n",
    "gpt2_config = LuminarSequenceTrainingConfig(**{\n",
    "    \"feature_len\": 512,\n",
    "    \"num_intermediate_likelihoods\": 13,\n",
    "    \"conv_layer_shapes\": (\n",
    "        ConvolutionalLayerSpec(32, 5),\n",
    "        ConvolutionalLayerSpec(64, 5),\n",
    "        ConvolutionalLayerSpec(32, 3),\n",
    "    ),\n",
    "    \"projection_dim\": 64,\n",
    "    \"lstm_hidden_dim\": 256,\n",
    "    \"lstm_layers\": 1,\n",
    "    \"apply_delta_augmentation\": True,\n",
    "    \"apply_product_augmentation\": False,\n",
    "    \"weighted_sampling\": True,\n",
    "    \"max_epochs\": 100,\n",
    "    \"kfold\": 3,\n",
    "    \"early_stopping_patience\": 8,\n",
    "    \"learning_rate\": 0.004,\n",
    "    \"batch_size\": 64,\n",
    "    \"seed\": 42,\n",
    "    \"rescale_features\": False,\n",
    "    \"stack_spans\": 5\n",
    "})"
   ],
   "id": "6adf7e57b36d7725",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T10:44:01.003542Z",
     "start_time": "2025-09-18T10:43:57.463274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "log_to_wandb = False\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    with torch.cuda.device(torch.cuda.current_device()):\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()"
   ],
   "id": "efa9766bdf5aad3e",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T19:46:01.477780Z",
     "start_time": "2025-09-18T10:44:01.060222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = LuminarSequenceTrainer(train_dataset=train_dataset,\n",
    "                                 test_data_loader = test_loader,\n",
    "                                 collate_fn=data_processor.collate_fn,\n",
    "                                 log_to_wandb=log_to_wandb,\n",
    "                                 config=gpt2_config,\n",
    "                                 device=get_best_device(),\n",
    "                                 use_experimental_attention=False)\n",
    "\n",
    "metrics, best_model = trainer.train()\n",
    "avg_f1 = metrics.get(\"f1_score\", 0.0)"
   ],
   "id": "df8e1caa10c971db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Fold 1/3 ==========\n",
      "Applying weighted_sampling to this fold.\n",
      "[Fold 1] Weighted sampling ON | samples pos/neg = 338183/11102 | spans pos/neg = 3700431/144711\n",
      "LuminarSequenceTrainingConfig(feature_len=512, num_intermediate_likelihoods=13, apply_delta_augmentation=True, apply_product_augmentation=False, weighted_sampling=True, conv_layer_shapes=((32, 5, 1), (64, 5, 1), (32, 3, 1)), projection_dim=64, lstm_hidden_dim=256, lstm_layers=1, stack_spans=5, hf_dataset='liberi-luminaris/Ghostbuster-encoded-gpt2', dataset_root_path='/storage/projects/stoeckel/prismai/encoded/fulltext/', models_root_path='/storage/projects/boenisch/PrismAI/models/luminar_sequence/', domain=None, agent='gpt_4o_mini_gemma2_9b', feature_agent='gpt2', max_epochs=100, batch_size=64, early_stopping_patience=8, rescale_features=False, kfold=3, learning_rate=0.004, seed=42)\n",
      "\n",
      "Epoch 1/100\n",
      "Train Loss: 0.4511 | Eval Loss: 0.3548\n",
      "\n",
      "Epoch 2/100\n",
      "Train Loss: 0.3631 | Eval Loss: 0.3322\n",
      "\n",
      "Epoch 3/100\n",
      "Train Loss: 0.3461 | Eval Loss: 0.2973\n",
      "\n",
      "Epoch 4/100\n",
      "Train Loss: 0.3430 | Eval Loss: 0.3160\n",
      "\n",
      "Epoch 5/100\n",
      "Train Loss: 0.3464 | Eval Loss: 0.4446\n",
      "\n",
      "Epoch 6/100\n",
      "Train Loss: 0.3547 | Eval Loss: 0.3836\n",
      "\n",
      "Epoch 7/100\n",
      "Train Loss: 0.3666 | Eval Loss: 0.5313\n",
      "\n",
      "Epoch 8/100\n",
      "Train Loss: 0.3900 | Eval Loss: 0.5058\n",
      "\n",
      "Epoch 9/100\n",
      "Train Loss: 0.4146 | Eval Loss: 0.5726\n",
      "\n",
      "Epoch 10/100\n",
      "Train Loss: 0.4511 | Eval Loss: 0.5265\n",
      "\n",
      "Epoch 11/100\n",
      "Train Loss: 0.4463 | Eval Loss: 0.4968\n",
      "Early stopping after 11 epochs.\n",
      "\n",
      "Best Eval Loss: 0.2973 | Best Train Loss: 0.3461\n",
      "\n",
      "Fold 1 Metrics:\n",
      "  f1_score: 0.8193\n",
      "  precision: 0.9590\n",
      "  recall: 0.7383\n",
      "  accuracy: 0.7383\n",
      "  roc_auc: 0.8701\n",
      "  fpr: 0.1483\n",
      "  tpr: 0.7339\n",
      "  f1_human: 0.1968\n",
      "  f1_ai: 0.8437\n",
      "\n",
      "========== Fold 2/3 ==========\n",
      "Applying weighted_sampling to this fold.\n",
      "[Fold 2] Weighted sampling ON | samples pos/neg = 338241/11044 | spans pos/neg = 3708519/143739\n",
      "LuminarSequenceTrainingConfig(feature_len=512, num_intermediate_likelihoods=13, apply_delta_augmentation=True, apply_product_augmentation=False, weighted_sampling=True, conv_layer_shapes=((32, 5, 1), (64, 5, 1), (32, 3, 1)), projection_dim=64, lstm_hidden_dim=256, lstm_layers=1, stack_spans=5, hf_dataset='liberi-luminaris/Ghostbuster-encoded-gpt2', dataset_root_path='/storage/projects/stoeckel/prismai/encoded/fulltext/', models_root_path='/storage/projects/boenisch/PrismAI/models/luminar_sequence/', domain=None, agent='gpt_4o_mini_gemma2_9b', feature_agent='gpt2', max_epochs=100, batch_size=64, early_stopping_patience=8, rescale_features=False, kfold=3, learning_rate=0.004, seed=42)\n",
      "\n",
      "Epoch 1/100\n",
      "Train Loss: 0.4316 | Eval Loss: 0.5169\n",
      "\n",
      "Epoch 2/100\n",
      "Train Loss: 0.3515 | Eval Loss: 0.4302\n",
      "\n",
      "Epoch 3/100\n",
      "Train Loss: 0.3292 | Eval Loss: 0.3545\n",
      "\n",
      "Epoch 4/100\n",
      "Train Loss: 0.3249 | Eval Loss: 0.3168\n",
      "\n",
      "Epoch 5/100\n",
      "Train Loss: 0.3259 | Eval Loss: 0.4604\n",
      "\n",
      "Epoch 6/100\n",
      "Train Loss: 0.3322 | Eval Loss: 0.5140\n",
      "\n",
      "Epoch 7/100\n",
      "Train Loss: 0.3390 | Eval Loss: 0.3776\n",
      "\n",
      "Epoch 8/100\n",
      "Train Loss: 0.3484 | Eval Loss: 0.4742\n",
      "\n",
      "Epoch 9/100\n",
      "Train Loss: 0.3671 | Eval Loss: 0.4395\n",
      "\n",
      "Epoch 10/100\n",
      "Train Loss: 0.3990 | Eval Loss: 0.6550\n",
      "\n",
      "Epoch 11/100\n",
      "Train Loss: 0.4372 | Eval Loss: 0.5386\n",
      "\n",
      "Epoch 12/100\n",
      "Train Loss: 0.4498 | Eval Loss: 0.6448\n",
      "Early stopping after 12 epochs.\n",
      "\n",
      "Best Eval Loss: 0.3168 | Best Train Loss: 0.3249\n",
      "\n",
      "Fold 2 Metrics:\n",
      "  f1_score: 0.7503\n",
      "  precision: 0.9592\n",
      "  recall: 0.6430\n",
      "  accuracy: 0.6430\n",
      "  roc_auc: 0.8503\n",
      "  fpr: 0.1085\n",
      "  tpr: 0.6333\n",
      "  f1_human: 0.1583\n",
      "  f1_ai: 0.7735\n",
      "\n",
      "========== Fold 3/3 ==========\n",
      "Applying weighted_sampling to this fold.\n",
      "[Fold 3] Weighted sampling ON | samples pos/neg = 338194/11092 | spans pos/neg = 3708080/143940\n",
      "LuminarSequenceTrainingConfig(feature_len=512, num_intermediate_likelihoods=13, apply_delta_augmentation=True, apply_product_augmentation=False, weighted_sampling=True, conv_layer_shapes=((32, 5, 1), (64, 5, 1), (32, 3, 1)), projection_dim=64, lstm_hidden_dim=256, lstm_layers=1, stack_spans=5, hf_dataset='liberi-luminaris/Ghostbuster-encoded-gpt2', dataset_root_path='/storage/projects/stoeckel/prismai/encoded/fulltext/', models_root_path='/storage/projects/boenisch/PrismAI/models/luminar_sequence/', domain=None, agent='gpt_4o_mini_gemma2_9b', feature_agent='gpt2', max_epochs=100, batch_size=64, early_stopping_patience=8, rescale_features=False, kfold=3, learning_rate=0.004, seed=42)\n",
      "\n",
      "Epoch 1/100\n",
      "Train Loss: 0.4508 | Eval Loss: 0.4492\n",
      "\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      1\u001B[39m trainer = LuminarSequenceTrainer(train_dataset=train_dataset,\n\u001B[32m      2\u001B[39m                                  test_data_loader = test_loader,\n\u001B[32m      3\u001B[39m                                  collate_fn=data_processor.collate_fn,\n\u001B[32m   (...)\u001B[39m\u001B[32m      6\u001B[39m                                  device=get_best_device(),\n\u001B[32m      7\u001B[39m                                  use_experimental_attention=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m metrics, best_model = \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     10\u001B[39m avg_f1 = metrics.get(\u001B[33m\"\u001B[39m\u001B[33mf1_score\u001B[39m\u001B[33m\"\u001B[39m, \u001B[32m0.0\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/home/prismAI/PrismAI/src/luminar/sequence_trainer.py:121\u001B[39m, in \u001B[36mLuminarSequenceTrainer.train\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    117\u001B[39m         model.pos_weight = stats[\u001B[33m\"\u001B[39m\u001B[33mpos_weight_spans\u001B[39m\u001B[33m\"\u001B[39m].to(\u001B[38;5;28mself\u001B[39m.device)\n\u001B[32m    119\u001B[39m optimizer = torch.optim.Adam(model.parameters(), lr=\u001B[38;5;28mself\u001B[39m.config.learning_rate)\n\u001B[32m--> \u001B[39m\u001B[32m121\u001B[39m model = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_train_and_evaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    122\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmax_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfold\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mearly_stopping_patience\u001B[49m\n\u001B[32m    123\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    125\u001B[39m \u001B[38;5;66;03m# Evaluate and collect fold metrics\u001B[39;00m\n\u001B[32m    126\u001B[39m metrics = \u001B[38;5;28mself\u001B[39m._evaluate_test(model)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/home/prismAI/PrismAI/src/luminar/sequence_trainer.py:197\u001B[39m, in \u001B[36mLuminarSequenceTrainer._train_and_evaluate\u001B[39m\u001B[34m(self, model, train_loader, eval_loader, optimizer, epochs, fold, patience)\u001B[39m\n\u001B[32m    194\u001B[39m     torch.nn.utils.clip_grad_norm_(model.parameters(), \u001B[32m1.0\u001B[39m)\n\u001B[32m    195\u001B[39m     optimizer.step()\n\u001B[32m--> \u001B[39m\u001B[32m197\u001B[39m     total_train_loss += \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    198\u001B[39m avg_train_loss = total_train_loss / \u001B[38;5;28mlen\u001B[39m(train_loader)\n\u001B[32m    200\u001B[39m \u001B[38;5;66;03m# Evaluation\u001B[39;00m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T19:45:56.606437900Z",
     "start_time": "2025-09-17T09:09:47.643459Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "97f594dc3078571",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
