{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from lightning.pytorch import Trainer, seed_everything\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from luminar.document.data import (\n",
    "    FeatureDataset,\n",
    "    PaddingDataloader,\n",
    "    n_way_split,\n",
    ")\n",
    "from luminar.document.model import (\n",
    "    CNNDocumentClassficationModel,\n",
    "    ConvolutionalLayerSpec,\n",
    ")\n",
    "from luminar.features import FeatureExtractor, OneDimFeatures, Slicer, TwoDimFeatures\n",
    "from luminar.mongo import PrismaiDataset\n",
    "\n",
    "load_dotenv(\"../env\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = {\n",
    "    \"Blog Authorship\": {\"domain\": \"blog_authorship_corpus\"},\n",
    "    \"Student Essays\": {\"domain\": \"student_essays\"},\n",
    "    \"CNN News\": {\"domain\": \"cnn_news\"},\n",
    "    \"Euro Court Cases\": {\"domain\": \"euro_court_cases\"},\n",
    "    \"House of Commons\": {\"domain\": \"house_of_commons\"},\n",
    "    \"ArXiv Papers\": {\"domain\": \"arxiv_papers\"},\n",
    "    \"Gutenberg\": {\"domain\": \"gutenberg\", \"lang\": \"en-EN\"},\n",
    "    \"Bundestag [DE]\": {\"domain\": \"bundestag\"},\n",
    "    \"Spiegel [DE]\": {\"domain\": \"spiegel_articles\"},\n",
    "    # \"Gutenberg [DE]\": {\"domain\": \"gutenberg\", \"lang\": \"de-DE\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmap = {\n",
    "    \"Blog Authorship\": \"Blog Authorship\",\n",
    "    \"Student Essays\": \"Student Essays\",\n",
    "    \"CNN News\": \"CNN News\",\n",
    "    \"Euro Court Cases\": \"Euro Court Cases\",\n",
    "    \"House of Commons\": \"House of Commons\",\n",
    "    \"ArXiv Papers\": \"ArXiv Papers\",\n",
    "    \"Gutenberg [EN]\": \"Gutenberg\",\n",
    "    \"Bundestag\": \"Bundestag [DE]\",\n",
    "    \"Spiegel\": \"Spiegel [DE]\",\n",
    "    # \"Gutenberg [DE]\": \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"seed\": 42,\n",
    "    \"eval_split\": 0.1,\n",
    "    \"test_split\": 0.2,\n",
    "    \"feature_model\": \"gpt2\",\n",
    "    # \"feature_model\": \"meta-llama/Llama-3.2-1B\",\n",
    "    \"synth_agent\": \"gpt-4o-mini\",\n",
    "    # \"synth_agent\": \"gemma2:9b\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "856b5eb4803640a9add0008d9feb200a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[PrismaiDataset] Loading Documents from MongoDB: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PrismaiDataset] Writing Cache File /tmp/luminar/119e4613239c2a870617e80c50d91776c6682016415184e1039b60e5ef5d8116.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594ce02fd59d450aa734e9af74790622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[PrismaiDataset] Loading Documents from MongoDB: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PrismaiDataset] Writing Cache File /tmp/luminar/4aa6c04025b8043dccbb076975ccd2bc2492c5d5172798eb9adeeaee382f8586.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600ace298c7d4ae6899f148218574845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[PrismaiDataset] Loading Documents from MongoDB: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PrismaiDataset] Writing Cache File /tmp/luminar/3fb225030a91434546e94cddd9b435edbce7c31b51b1f14829cea50f209d1bff.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51c8da098324d209fd3cd630195be66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[PrismaiDataset] Loading Documents from MongoDB: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PrismaiDataset] Writing Cache File /tmp/luminar/841e418fa927a8868452fa7c33fecf637691d908aa5e19593c101f12bb430fc7.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032356c19ff74c68b777adbe714ec6aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[PrismaiDataset] Loading Documents from MongoDB: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PrismaiDataset] Writing Cache File /tmp/luminar/693d7989e4d059cf2330448fba44db75c0ce07c23ab3f8b5f4974a017e4ddb14.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06beebd6223a4bc287abd787eb7afce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[PrismaiDataset] Loading Documents from MongoDB: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PrismaiDataset] Writing Cache File /tmp/luminar/e17b34be8696a18364a4ffaefa50e1b68b3fee34af4a6e75203c75fc0d555a1f.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e9609c8063e4481928e8d298b645da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[PrismaiDataset] Loading Documents from MongoDB: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PrismaiDataset] Writing Cache File /tmp/luminar/ae07a41994953a0d6f9844233d8ae8858135956e65e24c00250b6f90857eaf54.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0518836a8afc4151bb48fb9280ed8aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[PrismaiDataset] Loading Documents from MongoDB: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PrismaiDataset] Writing Cache File /tmp/luminar/1f8a7aa0d5e70435378180ce907ae70bcd6369f516164db9658d06619e84da58.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b2b435b45e422689a6ab8063b01947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[PrismaiDataset] Loading Documents from MongoDB: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PrismaiDataset] Writing Cache File /tmp/luminar/5ba2b5f045656e518aaba12da3883c015cc1639b065a45b63cc1f53943330ffe.pkl\n"
     ]
    }
   ],
   "source": [
    "datasets = {\n",
    "    domain: PrismaiDataset(\n",
    "        mongo_db_connection=\"mongodb://prismai:prismai@isengart.hucompute.org:27123/?retryWrites=true&loadBalanced=false&serverSelectionTimeoutMS=5000&connectTimeoutMS=10000&authSource=admin&authMechanism=SCRAM-SHA-256\",\n",
    "        database=\"prismai\",\n",
    "        collection=\"features_prismai\",\n",
    "        feature_model=config[\"feature_model\"],\n",
    "        synth_agent=config[\"synth_agent\"],\n",
    "        # synth_agent={\"$exists\": True},\n",
    "        **kwargs,\n",
    "        # update_cache=True\n",
    "    ).load()\n",
    "    for domain, kwargs in domains.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "train_splits = {}\n",
    "eval_splits = {}\n",
    "test_splits = {}\n",
    "for domain, dataset in datasets.items():\n",
    "    seed_everything(config[\"seed\"])\n",
    "    train_dataset, eval_dataset, test_dataset = n_way_split(\n",
    "        dataset,\n",
    "        config[\"eval_split\"],\n",
    "        config[\"test_split\"],\n",
    "        infer_first=True,\n",
    "    )\n",
    "    train_splits[domain] = train_dataset\n",
    "    eval_splits[domain] = eval_dataset\n",
    "    test_splits[domain] = test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_dim = OneDimFeatures(256)\n",
    "# featurizer = FeatureExtractor.Likelihood()\n",
    "# featurizer = FeatureExtractor.LogLikelihoodLogRankRatio()\n",
    "# config[\"second_dim_as_channels\"] = False\n",
    "feature_dim = TwoDimFeatures(256, 13)\n",
    "# featurizer = FeatureExtractor.LikelihoodTopkLikelihoodRatio(16)\n",
    "featurizer = FeatureExtractor.IntermediateLogits(13)\n",
    "# config[\"second_dim_as_channels\"] = False\n",
    "config[\"second_dim_as_channels\"] = True\n",
    "\n",
    "# slicer = Slicer.Random(feature_dim[0])\n",
    "slicer = Slicer.RandomMultiple(feature_dim[0] // 4, multiple=4, stride=16)\n",
    "# slicer = Slicer.RandomMultiple(feature_dim[0] // 4, 4)\n",
    "\n",
    "config[\"feature_dim\"] = feature_dim\n",
    "config[\"featurizer\"] = repr(featurizer)\n",
    "config[\"slicer\"] = repr(slicer)\n",
    "\n",
    "config[\"num_samples\"] = None\n",
    "config[\"num_samples_test\"] = 32\n",
    "\n",
    "\n",
    "def featurize(dataset, num_samples=None) -> FeatureDataset:\n",
    "    return FeatureDataset(\n",
    "        tqdm(dataset, position=1, leave=False),\n",
    "        slicer,\n",
    "        featurizer,\n",
    "        num_samples=num_samples or config[\"num_samples\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69fca8bc87b14a84861f0660a745de12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e7c8a9165b04f649f63b8beec4017c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1050 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "index is out of bounds for dimension with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m train_datasets, eval_datasets, test_datasets \u001b[38;5;241m=\u001b[39m {}, {}, {}\n",
      "\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m domain, dataset \u001b[38;5;129;01min\u001b[39;00m tqdm(datasets\u001b[38;5;241m.\u001b[39mitems()):\n",
      "\u001b[0;32m----> 3\u001b[0m     train_datasets[domain] \u001b[38;5;241m=\u001b[39m \u001b[43mfeaturize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_splits\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m      4\u001b[0m     eval_datasets[domain] \u001b[38;5;241m=\u001b[39m featurize(eval_splits[domain])\n",
      "\u001b[1;32m      5\u001b[0m     test_datasets[domain] \u001b[38;5;241m=\u001b[39m featurize(test_splits[domain], num_samples\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples_test\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\n",
      "Cell \u001b[0;32mIn[7], line 24\u001b[0m, in \u001b[0;36mfeaturize\u001b[0;34m(dataset, num_samples)\u001b[0m\n",
      "\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfeaturize\u001b[39m(dataset, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FeatureDataset:\n",
      "\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFeatureDataset\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mslicer\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeaturizer\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_samples\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/Projects/PrismAI/src/luminar/document/data.py:36\u001b[0m, in \u001b[0;36mFeatureDataset.__init__\u001b[0;34m(self, data, slicer, featurizer, num_samples, label_field, label_zero)\u001b[0m\n",
      "\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n",
      "\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n",
      "\u001b[1;32m     29\u001b[0m     data: Iterable[\u001b[38;5;28mdict\u001b[39m],\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m     34\u001b[0m     label_zero: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m     35\u001b[0m ):\n",
      "\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m     38\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\n",
      "\u001b[1;32m     39\u001b[0m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\n",
      "\u001b[1;32m     40\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeatures\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     41\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel_field\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabel_zero\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     42\u001b[0m \u001b[43m                \u001b[49m\u001b[43m}\u001b[49m\n",
      "\u001b[1;32m     43\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeatures\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;32m     44\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_featurize\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m     45\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mFeatureValues\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtransition_scores\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     46\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mslicer\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     47\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfeaturizer\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     48\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     49\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     50\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;32m     51\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\n",
      "\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/Projects/PrismAI/src/luminar/document/data.py:23\u001b[0m, in \u001b[0;36mflatten\u001b[0;34m(iterables)\u001b[0m\n",
      "\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mflatten\u001b[39m[T](iterables: Iterable[Iterable[T]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Generator[T, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]:\n",
      "\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m (item \u001b[38;5;28;01mfor\u001b[39;00m iterable \u001b[38;5;129;01min\u001b[39;00m iterables \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m iterable)\n",
      "\n",
      "File \u001b[0;32m~/Projects/PrismAI/src/luminar/document/data.py:23\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n",
      "\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mflatten\u001b[39m[T](iterables: Iterable[Iterable[T]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Generator[T, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]:\n",
      "\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterables\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/Projects/PrismAI/src/luminar/document/data.py:44\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n",
      "\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n",
      "\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n",
      "\u001b[1;32m     29\u001b[0m     data: Iterable[\u001b[38;5;28mdict\u001b[39m],\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m     34\u001b[0m     label_zero: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m     35\u001b[0m ):\n",
      "\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n",
      "\u001b[1;32m     37\u001b[0m         flatten(\n",
      "\u001b[1;32m     38\u001b[0m             \u001b[43m[\u001b[49m\n",
      "\u001b[1;32m     39\u001b[0m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\n",
      "\u001b[1;32m     40\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeatures\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     41\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel_field\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabel_zero\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     42\u001b[0m \u001b[43m                \u001b[49m\u001b[43m}\u001b[49m\n",
      "\u001b[1;32m     43\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeatures\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;32m---> 44\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_featurize\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m     45\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mFeatureValues\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtransition_scores\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     46\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mslicer\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     47\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfeaturizer\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     48\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     49\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     50\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;32m     51\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m data\n",
      "\u001b[1;32m     52\u001b[0m         )\n",
      "\u001b[1;32m     53\u001b[0m     )\n",
      "\n",
      "File \u001b[0;32m~/Projects/PrismAI/src/luminar/document/data.py:64\u001b[0m, in \u001b[0;36mFeatureDataset._featurize\u001b[0;34m(ts, slicer, featurizer, num_samples)\u001b[0m\n",
      "\u001b[1;32m     62\u001b[0m slices \u001b[38;5;241m=\u001b[39m slicer\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mlen\u001b[39m(ts), num_samples)\n",
      "\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m slices:\n",
      "\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mfeaturizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeaturize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/Projects/PrismAI/src/luminar/features.py:370\u001b[0m, in \u001b[0;36mIntermediateLogits.featurize\u001b[0;34m(self, ts, slices)\u001b[0m\n",
      "\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfeaturize\u001b[39m(\u001b[38;5;28mself\u001b[39m, ts: FeatureValues, slices: \u001b[38;5;28mslice\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mslice\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n",
      "\u001b[0;32m--> 370\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate_probs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mslices\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;32m    371\u001b[0m     last_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_n \u001b[38;5;129;01mor\u001b[39;00m logits\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;32m    372\u001b[0m     logits \u001b[38;5;241m=\u001b[39m logits[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m-\u001b[39mlast_n:]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, last_n)\n",
      "\n",
      "\u001b[0;31mIndexError\u001b[0m: index is out of bounds for dimension with size 0"
     ]
    }
   ],
   "source": [
    "train_datasets, eval_datasets, test_datasets = {}, {}, {}\n",
    "for domain, dataset in tqdm(datasets.items()):\n",
    "    train_datasets[domain] = featurize(train_splits[domain])\n",
    "    eval_datasets[domain] = featurize(eval_splits[domain])\n",
    "    test_datasets[domain] = featurize(test_splits[domain], num_samples=config[\"num_samples_test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-Domain Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config |= {\n",
    "    # \"projection_dim\": 32,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"warmup_steps\": 69,\n",
    "    \"max_epochs\": 50,\n",
    "    \"gradient_clip_val\": 1.0,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "\n",
    "# SeqXGPT Layer Configuration\n",
    "config[\"conv_layer_shapes\"] = [\n",
    "    ConvolutionalLayerSpec(64, 5),\n",
    "    *[ConvolutionalLayerSpec(128, 3)] * 3,\n",
    "    ConvolutionalLayerSpec(64, 3),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "\n",
    "\n",
    "class PaddingDataloader(DataLoader):\n",
    "    def __init__(self, *args, feature_dim: tuple[int, ...], **kwargs):\n",
    "        kwargs[\"collate_fn\"] = self._collate_fn\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.feature_dim = feature_dim\n",
    "\n",
    "    def _collate_fn(self, batch: list[dict]) -> dict[str, torch.Tensor]:\n",
    "        features = torch.nn.utils.rnn.pad_sequence(\n",
    "            [x[\"features\"] for x in batch], batch_first=True\n",
    "        )\n",
    "\n",
    "        # In case we get a batch of sequences, that are all too short,\n",
    "        # we need to pad them to the correct length as given by the feature_dim.\n",
    "        # - First dimension is the batch size.\n",
    "        # - Second dimension is the sequence length.\n",
    "        # - Third dimension is the feature dimension, if 2D features are used.\n",
    "        match features.shape, self.feature_dim:\n",
    "            case (_, s1), (d1,) if s1 < d1:\n",
    "                p2d = (0, 0, 0, d1 - s1)\n",
    "                features = torch.nn.functional.pad(features, p2d, \"constant\", 0.0)\n",
    "            case (_, s1, _), (d1, _) if s1 < d1:\n",
    "                p2d = (0, 0, 0, d1 - s1, 0, 0)\n",
    "                features = torch.nn.functional.pad(features, p2d, \"constant\", 0.0)\n",
    "        labels = torch.tensor([x[\"labels\"] for x in batch])\n",
    "\n",
    "        return {\"features\": features, \"labels\": labels}\n",
    "\n",
    "\n",
    "# capturing config from \"closure\"\n",
    "def get_dataloader(*dataset, **kwargs) -> PaddingDataloader:\n",
    "    if len(dataset) == 1:\n",
    "        dataset = dataset[0]\n",
    "    else:\n",
    "        dataset = ConcatDataset(dataset)\n",
    "    return PaddingDataloader(\n",
    "        dataset,\n",
    "        feature_dim=config[\"feature_dim\"],\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        **kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_in_domain = {}\n",
    "for domain in tqdm(domains, position=0, leave=False):\n",
    "    seed_everything(config[\"seed\"])\n",
    "\n",
    "    train_dataloader = get_dataloader(train_datasets[domain], shuffle=True)\n",
    "    eval_dataloader = get_dataloader(eval_datasets[domain])\n",
    "\n",
    "    model = CNNDocumentClassficationModel(**config)\n",
    "    trainer = Trainer(\n",
    "        max_epochs=config[\"max_epochs\"],\n",
    "        logger=pl_loggers.TensorBoardLogger(\n",
    "            save_dir=f\"logs/in_domain/{type(featurizer).__name__}\",\n",
    "            name=domain,\n",
    "        ),\n",
    "        gradient_clip_val=config[\"gradient_clip_val\"],\n",
    "        callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=3)],\n",
    "        deterministic=True,\n",
    "    )\n",
    "\n",
    "    trainer.fit(\n",
    "        model,\n",
    "        train_dataloaders=train_dataloader,\n",
    "        val_dataloaders=eval_dataloader,\n",
    "    )\n",
    "    models_in_domain[domain] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_in_domain = {}\n",
    "for domain in tqdm(domains, position=0, leave=False):\n",
    "    trainer.progress_bar_callback.disable()\n",
    "    metrics = []\n",
    "    for other in domains:\n",
    "        trainer.validate(\n",
    "            models_in_domain[domain],\n",
    "            get_dataloader(\n",
    "                # train_datasets[other],\n",
    "                eval_datasets[other],\n",
    "            ),\n",
    "            verbose=False,\n",
    "        )\n",
    "        metrics.append(\n",
    "            {\"other\": other}\n",
    "            | trainer.test(\n",
    "                models_in_domain[domain],\n",
    "                get_dataloader(test_datasets[other]),\n",
    "                verbose=False,\n",
    "            )[0]\n",
    "        )\n",
    "    trainer.progress_bar_callback.enable()\n",
    "\n",
    "    results_in_domain[domain] = metrics\n",
    "    print(domain, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# _metric = \"test_roc_auc\"\n",
    "\n",
    "\n",
    "# results = []\n",
    "# for domain in domains:\n",
    "#     results.append(\n",
    "#         [\n",
    "#             results_in_domain[domain][\"metrics\"][i][_heatmap_metric]\n",
    "#             for i in range(len(domains))\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "# df = pd.DataFrame(results, columns=domains, index=domains)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All-Domain Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(config[\"seed\"])\n",
    "train_dataloader = get_dataloader(*train_datasets.values(), shuffle=True)\n",
    "eval_dataloader = get_dataloader(*eval_datasets.values())\n",
    "test_dataloader = get_dataloader(*test_datasets.values())\n",
    "\n",
    "model = CNNDocumentClassficationModel(**config)\n",
    "trainer = Trainer(\n",
    "    max_epochs=config[\"max_epochs\"],\n",
    "    logger=pl_loggers.TensorBoardLogger(\n",
    "        save_dir=f\"logs/all_domains/{type(featurizer).__name__}\",\n",
    "    ),\n",
    "    gradient_clip_val=config[\"gradient_clip_val\"],\n",
    "    callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=3)],\n",
    "    deterministic=True,\n",
    ")\n",
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=eval_dataloader,\n",
    ")\n",
    "models_in_domain[\"all\"] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.progress_bar_callback.disable()\n",
    "metrics_all_domains = []\n",
    "for other, dataset in test_datasets.items():\n",
    "    trainer.validate(\n",
    "        models_in_domain[\"all\"],\n",
    "        get_dataloader(\n",
    "            # train_datasets[other],\n",
    "            eval_datasets[other],\n",
    "        ),\n",
    "        verbose=False,\n",
    "    )\n",
    "    metrics_all_domains.append(\n",
    "        {\"other\": other}\n",
    "        | trainer.test(models_in_domain[\"all\"], get_dataloader(dataset), verbose=False)[\n",
    "            0\n",
    "        ]\n",
    "    )\n",
    "trainer.validate(models_in_domain[\"all\"], eval_dataloader, verbose=False)\n",
    "metrics_all_domains += [\n",
    "    {\n",
    "        \"other\": \"ALL\",\n",
    "        **trainer.test(models_in_domain[\"all\"], test_dataloader, verbose=False)[0],\n",
    "    }\n",
    "]\n",
    "trainer.progress_bar_callback.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_latex_heatmap(_df: pd.DataFrame):\n",
    "    print(\n",
    "        \"\\\\plotHeatmap{\"\n",
    "        + \",\".join(_df.index)\n",
    "        + \"}{%\\n    \"\n",
    "        + \",%\\n    \".join(\n",
    "            [\n",
    "                \"{\"\n",
    "                + \",\".join(f\"{val:.4f}/{round(val, 2):.2f}\" for val in row[1:])\n",
    "                + \"}\"\n",
    "                for row in _df.reset_index().values\n",
    "            ]\n",
    "        )\n",
    "        + \"%\\n}{\"\n",
    "        + \",\".join(_df.columns)\n",
    "        + \"}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_heatmap(_df: pd.DataFrame):\n",
    "    ax = sns.heatmap(\n",
    "        _df,\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        vmax=1.0,\n",
    "        vmin=0.0,\n",
    "        cmap=sns.cubehelix_palette(rot=-0.2, as_cmap=True),\n",
    "        yticklabels=list(domains) + [\"ALL\"],\n",
    "        xticklabels=list(domains) + [\"AVG\"],\n",
    "        square=True,\n",
    "        # reduce annotation font size\n",
    "        annot_kws={\"fontsize\": 8},\n",
    "        cbar=False,\n",
    "    )\n",
    "\n",
    "    # rotate x-axis labels by 45 degrees\n",
    "    # anchored at the right edge of the axes\n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_rotation(45)\n",
    "        tick.set_horizontalalignment(\"right\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_df_from_metrics(\n",
    "    _metrics_in_domain, _metrics_all_domains, _metric: str = \"test_f1@best\"\n",
    ") -> pd.DataFrame:\n",
    "    results = []\n",
    "    for domain in domains:\n",
    "        results.append(\n",
    "            [\n",
    "                _metrics_in_domain[domain][i][_metric]\n",
    "                for i in range(len(domains))\n",
    "            ]\n",
    "        )\n",
    "    results.append([m[_metric] for m in _metrics_all_domains[: len(domains)]])\n",
    "\n",
    "    _df = pd.DataFrame(results, columns=list(domains), index=list(domains) + [\"ALL\"])\n",
    "    _df[\"AVG\"] = _df.mean(axis=1)\n",
    "\n",
    "    # fix diagonale by replacing average of inter-domain metrics with actual value\n",
    "    _df[\"AVG\"][-1] = _metrics_all_domains[-1][_metric]\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_metric = \"test_f1@0.5\"\n",
    "# _metric = \"test_acc@0.5\"\n",
    "\n",
    "df = get_df_from_metrics(results_in_domain, metrics_all_domains, _metric)\n",
    "plot_heatmap(df)\n",
    "df_to_latex_heatmap(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_metric = \"test_f1@best\"\n",
    "# _metric = \"test_acc@best\"\n",
    "\n",
    "df = get_df_from_metrics(results_in_domain, metrics_all_domains, _metric)\n",
    "plot_heatmap(df)\n",
    "df_to_latex_heatmap(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_metric = \"test_roc_auc\"\n",
    "\n",
    "df = get_df_from_metrics(results_in_domain, metrics_all_domains, _metric)\n",
    "plot_heatmap(df)\n",
    "df_to_latex_heatmap(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def predict(model, dataloader):\n",
    "    preds = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            labels.extend(batch[\"labels\"].tolist())\n",
    "            preds.extend(model(batch[\"features\"]).sigmoid().tolist())\n",
    "\n",
    "    preds = np.array(preds)\n",
    "    labels = np.array(labels)\n",
    "    return labels, preds\n",
    "\n",
    "\n",
    "def get_f1_threshold(labels: np.ndarray, preds: np.ndarray) -> float:\n",
    "    thresholds = np.linspace(0.25, 1, 7501)\n",
    "    preds_thresholded = (preds.T > thresholds.reshape(-1, 1)).astype(float)\n",
    "    tp = np.sum(preds_thresholded[:, labels == 0] == 0, axis=1)\n",
    "    # tn = np.sum(preds_thresholded[:, labels == 1] == 1, axis=1)\n",
    "    fp = np.sum(preds_thresholded[:, labels == 0] == 1, axis=1)\n",
    "    fn = np.sum(preds_thresholded[:, labels == 1] == 0, axis=1)\n",
    "\n",
    "    f1_thresholded = 2 * tp / (2 * tp + fp + fn)\n",
    "    f1_thresholded[np.isnan(f1_thresholded)] = 0\n",
    "    f1_threshold = thresholds[np.argmax(f1_thresholded)]\n",
    "    return f1_threshold\n",
    "\n",
    "\n",
    "manual_evaluation = []\n",
    "for domain in tqdm(list(domains.keys()) + [\"all\"]):\n",
    "    model = models_in_domain[domain]\n",
    "    manual_evaluation_row = []\n",
    "    for other in domains:\n",
    "        # labels, preds = predict(model, get_dataloader(eval_datasets[other]))\n",
    "        labels, preds = predict(model, get_dataloader(test_datasets[other]))\n",
    "        f1_threshold = get_f1_threshold(labels, preds)\n",
    "        # labels, preds = predict(model, get_dataloader(test_datasets[other]))\n",
    "        manual_evaluation_row.append(f1_score(labels, preds > 0.5, average=\"binary\"))\n",
    "    manual_evaluation.append(manual_evaluation_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(manual_evaluation, columns=domains, index=list(domains.keys()) + [\"all\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Domain Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cross_domain = {}\n",
    "for domain in tqdm(domains, position=0, leave=True):\n",
    "    seed_everything(config[\"seed\"])\n",
    "\n",
    "    train_other = [train_datasets[other] for other in domains if other != domain]\n",
    "    eval_other = [eval_datasets[other] for other in domains if other != domain]\n",
    "    train_dataloader = get_dataloader(*train_other, shuffle=True)\n",
    "    eval_dataloader = get_dataloader(*eval_other)\n",
    "\n",
    "    model = CNNDocumentClassficationModel(**config)\n",
    "    trainer = Trainer(\n",
    "        max_epochs=config[\"max_epochs\"],\n",
    "        logger=pl_loggers.TensorBoardLogger(\n",
    "            save_dir=f\"logs/in_domain/{type(featurizer).__name__}\",\n",
    "            name=domain,\n",
    "        ),\n",
    "        gradient_clip_val=config[\"gradient_clip_val\"],\n",
    "        callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=3)],\n",
    "        deterministic=True,\n",
    "    )\n",
    "\n",
    "    trainer.fit(\n",
    "        model,\n",
    "        train_dataloaders=train_dataloader,\n",
    "        val_dataloaders=eval_dataloader,\n",
    "    )\n",
    "\n",
    "    trainer.progress_bar_callback.disable()\n",
    "    metrics = []\n",
    "    for other, dataset in test_datasets.items():\n",
    "        trainer.validate(model, get_dataloader(eval_datasets[other]), verbose=False)\n",
    "        metrics.append(\n",
    "            {\n",
    "                \"other\": other,\n",
    "            }\n",
    "            | trainer.test(\n",
    "                model,\n",
    "                get_dataloader(dataset),\n",
    "                verbose=False,\n",
    "            )[0]\n",
    "        )\n",
    "    trainer.progress_bar_callback.enable()\n",
    "\n",
    "    results_cross_domain[domain] = {\n",
    "        \"domain\": domain,\n",
    "        \"config\": copy.deepcopy(config),\n",
    "        \"metrics\": metrics,\n",
    "    }\n",
    "    print(domain, metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_metric = \"test_roc_auc\"\n",
    "# _metric = \"test_acc@best\"\n",
    "\n",
    "results = []\n",
    "for domain in domains:\n",
    "    results.append(\n",
    "        [\n",
    "            results_cross_domain[domain][\"metrics\"][i][_metric]\n",
    "            for i in range(len(domains))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(results, columns=list(domains), index=list(domains))\n",
    "df[\"AVG\"] = df.mean(axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    df,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    vmax=1.0,\n",
    "    vmin=0.0,\n",
    "    cmap=sns.cubehelix_palette(rot=-0.2, as_cmap=True),\n",
    "    yticklabels=list(domains),\n",
    "    xticklabels=list(domains) + [\"AVG\"],\n",
    "    square=True,\n",
    "    # reduce annotation font size\n",
    "    annot_kws={\"fontsize\": 8},\n",
    "    cbar=False,\n",
    ")\n",
    "\n",
    "# rotate x-axis labels by 45 degrees\n",
    "# anchored at the right edge of the axes\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(45)\n",
    "    tick.set_horizontalalignment(\"right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\n",
    "#     \"../figures/evaluation-trained_in_domain-test_0.1-gpt2_256-rand_4-il_13_as_channels.pdf\",\n",
    "#     dpi=300,\n",
    "# )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise RuntimeError(\"Stop here.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from luminar.mongo import MongoFindDataset\n",
    "\n",
    "metric_datasets = {\n",
    "    name: MongoFindDataset(\n",
    "        {\n",
    "            \"model.name\": config[\"feature_model\"],\n",
    "            \"document.agent\": {\"$in\": [None, \"gpt-4o-mini\"]},\n",
    "            # \"document.agent\": {\"$in\": [None, \"gemma2:9b\"]},\n",
    "            \"document.domain\": kwargs[\"domain\"],\n",
    "            \"document.type\": {\"$in\": [\"source\", \"fulltext\"]},\n",
    "        },\n",
    "        projection={\"metrics\": 1, \"type\": \"$document.type\"},\n",
    "        mongo_db_connection=os.environ.get(\"MONGO_DB_CONNECTION\"),\n",
    "        database=\"prismai\",\n",
    "        collection=\"features_prismai\",\n",
    "        update_cache=True,\n",
    "    ).load()\n",
    "    for name, kwargs in domains.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, f1_score, roc_curve\n",
    "\n",
    "results = {\n",
    "    \"domain\": [],\n",
    "    \"llr_auroc\": [],\n",
    "    \"llr_f1\": [],\n",
    "    \"fdg_auroc\": [],\n",
    "    \"fdg_f1\": [],\n",
    "}\n",
    "for name, dataset in metric_datasets.items():\n",
    "    metrics = [\n",
    "        (\n",
    "            x[\"metrics\"][0][\"llr\"],\n",
    "            x[\"metrics\"][0][\"fast_detect_gpt\"],\n",
    "            int(x[\"type\"] != \"source\"),\n",
    "        )\n",
    "        for x in dataset\n",
    "    ]\n",
    "    llr, fdg, labels = zip(*metrics)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(labels, llr)\n",
    "    llr_auroc = auc(fpr, tpr)\n",
    "\n",
    "    human_mean, ai_mean = np.mean(llr[labels==0]), np.mean(llr[labels==1])\n",
    "    threshold = (human_mean + ai_mean) / 2\n",
    "    llr_f1 = max(f1_score(labels, llr > threshold), f1_score(labels, llr < threshold))\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(labels, fdg)\n",
    "    fdg_auroc = auc(fpr, tpr)\n",
    "\n",
    "    human_mean, ai_mean = np.mean(fdg[labels==0]), np.mean(fdg[labels==1])\n",
    "    threshold = (human_mean + ai_mean) / 2\n",
    "    fdg_f1 = max(f1_score(labels, fdg > threshold), f1_score(labels, fdg < threshold))\n",
    "\n",
    "    results[\"domain\"].append(name)\n",
    "    results[\"llr_auroc\"].append(llr_auroc)\n",
    "    results[\"llr_f1\"].append(llr_f1)\n",
    "    results[\"fdg_auroc\"].append(fdg_auroc)\n",
    "    results[\"fdg_f1\"].append(fdg_f1)\n",
    "\n",
    "metric_df = pd.DataFrame.from_dict(results).T\n",
    "print(metric_df.to_latex(float_format=\"\\\\np{%.3f}\"))\n",
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(x=fdg, y=[\"Human\" if x else \"AI\" for x in labels], hue=labels, kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ad-Hoc LLR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from luminar.baselines import llr_from_transition_scores\n",
    "from simple_dataset import Dataset as SimpleDataset\n",
    "from transition_scores.data import FeatureValues\n",
    "\n",
    "\n",
    "def precompute_llr(split: list[dict]):\n",
    "    lrr_dataset = (\n",
    "        SimpleDataset(split)\n",
    "        .flat_map(lambda doc: doc[\"features\"])\n",
    "        .map(\n",
    "            lambda x: {\n",
    "                \"llr\": llr_from_transition_scores(\n",
    "                    FeatureValues(**x[\"transition_scores\"])\n",
    "                ),\n",
    "                \"labels\": int(x[\"type\"] != \"source\"),\n",
    "            },\n",
    "            in_place=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    llr = np.array(lrr_dataset[\"llr\"])\n",
    "    labels = np.array(lrr_dataset[\"labels\"])\n",
    "\n",
    "    return {\"llr\": llr, \"labels\": labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "\n",
    "\n",
    "def llr_metrics(llr: np.ndarray, labels: np.ndarray):\n",
    "    mean_0 = float(np.mean(llr[labels == 0]))\n",
    "    mean_1 = float(np.mean(llr[labels == 1]))\n",
    "    threshold_simple = mean_0 + (mean_1 - mean_0) / 2\n",
    "    acc_simple = np.mean((llr > threshold_simple) == labels)\n",
    "\n",
    "    # thresholds = np.linspace(round(mean_0, 1) - 0.2, round(mean_1, 1) + 0.3, 1001)\n",
    "\n",
    "    threshold_space = np.linspace(llr.min(), llr.max(), 10001)\n",
    "    preds_thresholded: np.ndarray = llr > threshold_space.reshape(-1, 1)\n",
    "    acc_thresholded = np.mean((preds_thresholded == labels), axis=1)\n",
    "    idx = np.argmax(acc_thresholded)\n",
    "    threshold_best = threshold_space[idx]\n",
    "    acc_best = acc_thresholded[idx]\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(labels, llr)\n",
    "    auroc = auc(fpr, tpr)\n",
    "\n",
    "    return {\n",
    "        \"acc_simple\": acc_simple,\n",
    "        \"threshold_simple\": threshold_simple,\n",
    "        \"acc_best\": acc_best,\n",
    "        \"threshold_best\": threshold_best,\n",
    "        \"auroc\": auroc,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLR on Whole Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llr_datasets = {}\n",
    "for domain, dataset in tqdm(datasets.items()):\n",
    "    llr_datasets[domain] = precompute_llr(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_llr = []\n",
    "for domain, split in llr_datasets.items():\n",
    "    results_llr.append({\"domain\": domain} | llr_metrics(split[\"llr\"], split[\"labels\"]))\n",
    "\n",
    "pd.DataFrame(results_llr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLR on Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llr_test_datasets = {}\n",
    "for domain, test_dataset in tqdm(test_splits.items()):\n",
    "    llr_test_datasets[domain] = precompute_llr(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test_llr = []\n",
    "for domain, split in llr_test_datasets.items():\n",
    "    results_test_llr.append(\n",
    "        {\"domain\": domain} | llr_metrics(split[\"llr\"], split[\"labels\"])\n",
    "    )\n",
    "\n",
    "pd.DataFrame(results_test_llr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    df,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    vmax=1.0,\n",
    "    vmin=0.0,\n",
    "    cmap=sns.cubehelix_palette(rot=-0.2, as_cmap=True),\n",
    "    yticklabels=list(domains) + [\"ALL\"],\n",
    "    xticklabels=list(domains) + [\"AVG\"],\n",
    "    square=True,\n",
    "    # reduce annotation font size\n",
    "    annot_kws={\"fontsize\": 8},\n",
    "    cbar=False,\n",
    ")\n",
    "\n",
    "# rotate x-axis labels by 45 degrees\n",
    "# anchored at the right edge of the axes\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(45)\n",
    "    tick.set_horizontalalignment(\"right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\n",
    "#     \"../figures/evaluation-trained_in_domain-test_0.1-gpt2_256-rand_4-il_13_as_channels.pdf\",\n",
    "#     dpi=300,\n",
    "# )\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
