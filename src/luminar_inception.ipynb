{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a39fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26864b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from numpy.typing import NDArray\n",
    "from torch import Tensor, nn\n",
    "from tqdm import tqdm\n",
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments\n",
    "from ulid import ulid\n",
    "\n",
    "from luminar.utils.training import LuminarTrainingConfig\n",
    "from luminar.classifier import LuminarCNN\n",
    "from luminar.utils import (\n",
    "    ConvolutionalLayerSpec,\n",
    "    compute_metrics,\n",
    "    get_matched_datasets,\n",
    "    get_pad_to_fixed_length_fn,\n",
    "    save_model,\n",
    ")\n",
    "\n",
    "HF_TOKEN = (Path.home() / \".hf_token\").read_text().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f065414a",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bf68ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from luminar.encoder import LuminarEncoder\n",
    "\n",
    "\n",
    "# encoder = LuminarEncoder()\n",
    "# encoder.device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f7e778",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dbf35dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = \"gpt_4o_mini\"\n",
    "other_agents = \"gemma2_9b\"\n",
    "domain = \"blog_authorship_corpus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c528f341",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_len = 128\n",
    "seed = 42\n",
    "\n",
    "pad_to_fixed_length: Callable[[NDArray], NDArray] = get_pad_to_fixed_length_fn(\n",
    "    feature_len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4c0be7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b29269722164462a945751711435ef11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Trimming & Padding Features (num_proc=8):   0%|          | 0/37864 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['agent', 'id_sample', 'id_source', 'labels', 'length', 'features'],\n",
       "    num_rows: 37864\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datset_config_name = f\"{domain}-fulltext\"\n",
    "dataset_split_name = f\"human+{agent}+{other_agents}\"\n",
    "dataset: Dataset = (\n",
    "    load_dataset(\n",
    "        \"liberi-luminaris/PrismAI-encoded-gpt2\",\n",
    "        datset_config_name,\n",
    "        split=dataset_split_name,\n",
    "        token=HF_TOKEN,\n",
    "    )  # type: ignore\n",
    "    .rename_column(\"label\", \"labels\")\n",
    "    .filter(\n",
    "        lambda features: len(features) > 0,\n",
    "        input_columns=[\"features\"],\n",
    "        num_proc=8,\n",
    "    )\n",
    "    .with_format(\"numpy\", columns=[\"features\"])\n",
    "    .map(\n",
    "        lambda features: {\"features\": pad_to_fixed_length(features)},\n",
    "        input_columns=[\"features\"],\n",
    "        desc=\"Trimming & Padding Features\",\n",
    "        num_proc=8,\n",
    "    )\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebe055ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0022cdd251714f08a2143f2bb8108b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/37864 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87cafe5c7af4c1abfb4bbf6a931e2ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/37864 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fec0ddf61f14ec5a00bd430cd75e254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/37864 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f404a364274e41b4f6a793c2a0451e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/37864 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c78402201d42579da7a1a7d46a037a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/37864 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da7c9153a28429ea1b582d2950b8330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/37864 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets_matched, dataset_unmatched = get_matched_datasets(dataset, agent)\n",
    "datasets_matched.set_format(\"torch\", columns=[\"labels\", \"features\"])\n",
    "dataset_unmatched.set_format(\"torch\", columns=[\"labels\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fe23e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 32\n",
    "steps_per_epoch = len(datasets_matched[\"train\"]) // train_batch_size\n",
    "eval_steps = steps_per_epoch // 5\n",
    "\n",
    "run_ulid = ulid()\n",
    "config = LuminarTrainingConfig(\n",
    "    feature_len=feature_len,\n",
    "    feature_dim=(feature_len, 13),\n",
    "    feature_type=\"intermediate_likelihoods\",\n",
    "    feature_model=\"gpt2\",\n",
    "    feature_selection=\"first\",\n",
    "    agent=agent,\n",
    "    domain=domain,\n",
    "    other_agents=other_agents,\n",
    "    datset_config_name=other_agents,\n",
    "    dataset_split_name=\"+\".join((\"human\", agent, *other_agents)),\n",
    "    conv_layer_shapes=(\n",
    "        ConvolutionalLayerSpec(32, 7),\n",
    "        ConvolutionalLayerSpec(64, 5),\n",
    "        ConvolutionalLayerSpec(32, 3),\n",
    "    ),\n",
    "    projection_dim=(512, 32),\n",
    "    seed=seed,\n",
    "    run_ulid=run_ulid,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4748dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../logs/hf/\" + run_ulid,\n",
    "    per_device_train_batch_size=train_batch_size,\n",
    "    per_device_eval_batch_size=1024,\n",
    "    learning_rate=5e-4,\n",
    "    num_train_epochs=10,\n",
    "    # lr_scheduler_type=\"reduce_lr_on_plateau\",\n",
    "    # lr_scheduler_kwargs={\n",
    "    #     \"mode\": \"min\",\n",
    "    #     \"factor\": 0.5,\n",
    "    #     \"patience\": 3,\n",
    "    #     \"threshold\": 0.001,\n",
    "    #     \"threshold_mode\": \"rel\",\n",
    "    #     # \"cooldown\": 1,\n",
    "    #     \"min_lr\": 1e-6,\n",
    "    # },\n",
    "    warmup_steps=steps_per_epoch,\n",
    "    logging_steps=eval_steps,\n",
    "    load_best_model_at_end=True,\n",
    "    # metric_for_best_model=\"accuracy\",\n",
    "    # greater_is_better=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=eval_steps,\n",
    "    eval_delay=steps_per_epoch,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=eval_steps,\n",
    "    # torch_compile=True,\n",
    "    # torch_compile_mode=\"reduce-overhead\"\n",
    "    seed=seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dd296a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "from transformers.utils.generic import ModelOutput\n",
    "\n",
    "\n",
    "class Inception(nn.Module):\n",
    "    # c1--c4 are the number of output channels for each branch\n",
    "    def __init__(self, c1, c2, c3, c4, **kwargs):\n",
    "        super(Inception, self).__init__(**kwargs)\n",
    "        # Branch 1\n",
    "        self.b1 = nn.LazyConv1d(c1, kernel_size=1)\n",
    "        # Branch 2\n",
    "        self.b2 = nn.Sequential(\n",
    "            nn.LazyConv1d(c2[0], kernel_size=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.LazyConv1d(c2[1], kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        # Branch 3\n",
    "        self.b3 = nn.Sequential(\n",
    "            nn.LazyConv1d(c3[0], kernel_size=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.LazyConv1d(c3[1], kernel_size=5, padding=2),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        # Branch 4\n",
    "        self.b4 = nn.Sequential(\n",
    "            nn.MaxPool1d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.LazyConv1d(c4, kernel_size=1),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat((self.b1(x), self.b2(x), self.b3(x), self.b4(x)), dim=1)\n",
    "\n",
    "\n",
    "class AltLuminarCNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        config = LuminarTrainingConfig(**kwargs)\n",
    "\n",
    "        feature_len, feature_depth = config.feature_dim\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                {\n",
    "                    \"conv1\": nn.Sequential(\n",
    "                        nn.Conv1d(feature_depth, 64, 7, 2, 3),\n",
    "                        nn.LeakyReLU(),\n",
    "                        nn.MaxPool1d(3, 2, 1),\n",
    "                    ),\n",
    "                    \"conv2\": nn.Sequential(\n",
    "                        nn.Conv1d(64, 64, 1, 1, 0),\n",
    "                        nn.LeakyReLU(),\n",
    "                        nn.Conv1d(64, 192, 3, 1, 1),\n",
    "                        nn.LeakyReLU(),\n",
    "                        nn.MaxPool1d(3, 2, 1),\n",
    "                    ),\n",
    "                    \"conv3\": nn.Sequential(\n",
    "                        Inception(64, (96, 128), (16, 32), 32),\n",
    "                        Inception(128, (128, 192), (32, 96), 64),\n",
    "                        nn.MaxPool1d(3, 2, 1),\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.LazyLinear(1)\n",
    "\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        features: torch.Tensor,\n",
    "        labels: torch.Tensor | None = None,\n",
    "        **kwargs,\n",
    "    ) -> ModelOutput:\n",
    "        # We are using 2D features (so `features` is a 3D tensor)\n",
    "        # but we want to treat the second feature dimension as channels.\n",
    "        # Thus, we need to transpose the tensor here\n",
    "        logits = self.classifier(\n",
    "            self.cnn(features.mul(2).tanh().transpose(1, 2))\n",
    "            .transpose(1, 2)\n",
    "            .flatten(1, -1)\n",
    "        )\n",
    "\n",
    "        if labels is None:\n",
    "            return ModelOutput(\n",
    "                logits=logits,\n",
    "            )\n",
    "\n",
    "        loss = self.criterion(logits.view(-1), labels.float().view(-1))\n",
    "\n",
    "        return ModelOutput(\n",
    "            logits=logits,\n",
    "            loss=loss,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7405313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AltLuminarCNN(\n",
      "  (cnn): Sequential(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv1d(13, 64, kernel_size=(7,), stride=(2,), padding=(3,))\n",
      "      (1): LeakyReLU(negative_slope=0.01)\n",
      "      (2): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "      (1): LeakyReLU(negative_slope=0.01)\n",
      "      (2): Conv1d(64, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (3): LeakyReLU(negative_slope=0.01)\n",
      "      (4): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (conv3): Sequential(\n",
      "      (0): Inception(\n",
      "        (b1): Conv1d(192, 64, kernel_size=(1,), stride=(1,))\n",
      "        (b2): Sequential(\n",
      "          (0): Conv1d(192, 96, kernel_size=(1,), stride=(1,))\n",
      "          (1): LeakyReLU(negative_slope=0.01)\n",
      "          (2): Conv1d(96, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (3): LeakyReLU(negative_slope=0.01)\n",
      "        )\n",
      "        (b3): Sequential(\n",
      "          (0): Conv1d(192, 16, kernel_size=(1,), stride=(1,))\n",
      "          (1): LeakyReLU(negative_slope=0.01)\n",
      "          (2): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "          (3): LeakyReLU(negative_slope=0.01)\n",
      "        )\n",
      "        (b4): Sequential(\n",
      "          (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "          (1): Conv1d(192, 32, kernel_size=(1,), stride=(1,))\n",
      "          (2): LeakyReLU(negative_slope=0.01)\n",
      "        )\n",
      "      )\n",
      "      (1): Inception(\n",
      "        (b1): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
      "        (b2): Sequential(\n",
      "          (0): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
      "          (1): LeakyReLU(negative_slope=0.01)\n",
      "          (2): Conv1d(128, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (3): LeakyReLU(negative_slope=0.01)\n",
      "        )\n",
      "        (b3): Sequential(\n",
      "          (0): Conv1d(256, 32, kernel_size=(1,), stride=(1,))\n",
      "          (1): LeakyReLU(negative_slope=0.01)\n",
      "          (2): Conv1d(32, 96, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "          (3): LeakyReLU(negative_slope=0.01)\n",
      "        )\n",
      "        (b4): Sequential(\n",
      "          (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "          (1): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
      "          (2): LeakyReLU(negative_slope=0.01)\n",
      "        )\n",
      "      )\n",
      "      (2): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Linear(in_features=3840, out_features=1, bias=True)\n",
      "  (criterion): BCEWithLogitsLoss()\n",
      ")\n",
      "Parameters \n",
      "  conv_layers: 306672 \n",
      "  classifier: 3841 \n",
      "  total: 310513\n"
     ]
    }
   ],
   "source": [
    "classifier = AltLuminarCNN(**config.asdict())\n",
    "classifier.forward(\n",
    "    torch.randn(32, feature_len, 13),\n",
    ")\n",
    "\n",
    "print(classifier)\n",
    "print(\n",
    "    \"Parameters\",\n",
    "    \"\\n  conv_layers:\",\n",
    "    sum(\n",
    "        param.numel()\n",
    "        for param in classifier.cnn.parameters()\n",
    "        if param.requires_grad\n",
    "    ),\n",
    "    \"\\n  classifier:\",\n",
    "    sum(\n",
    "        param.numel()\n",
    "        for param in classifier.classifier.parameters()\n",
    "        if param.requires_grad\n",
    "    ),\n",
    "    \"\\n  total:\",\n",
    "    sum(param.numel() for param in classifier.parameters() if param.requires_grad),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "493a1f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_layer_spec = (\n",
    "#     ConvolutionalLayerSpec(8, (7, 1)),\n",
    "#     ConvolutionalLayerSpec(16, (7, 1)),\n",
    "#     ConvolutionalLayerSpec(32, 7),\n",
    "#     ConvolutionalLayerSpec(64, 5),\n",
    "#     ConvolutionalLayerSpec(32, 3),\n",
    "#     ConvolutionalLayerSpec(3, 3),\n",
    "# )\n",
    "\n",
    "# classifier = LuminarCNN2D(conv_layer_shapes=conv_layer_spec, **config)\n",
    "# print(classifier)\n",
    "# print(\"num. parameters:\", sum(1 for p in classifier.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc46492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=classifier,\n",
    "    args=training_args,\n",
    "    train_dataset=datasets_matched[\"train\"],\n",
    "    eval_dataset=datasets_matched[\"eval\"],\n",
    "    # data_collator=PaddingDataCollator(config[\"feature_dim\"]),\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(10)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06616066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1960' max='2010' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1960/2010 05:47 < 00:08, 5.64 it/s, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>F1 Human</th>\n",
       "      <th>F1 Ai</th>\n",
       "      <th>N Samples</th>\n",
       "      <th>F1 Weighted Median</th>\n",
       "      <th>Accuracy Median</th>\n",
       "      <th>Roc Auc Median</th>\n",
       "      <th>F1 Human Median</th>\n",
       "      <th>F1 Ai Median</th>\n",
       "      <th>Threshold Median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.664900</td>\n",
       "      <td>0.646779</td>\n",
       "      <td>0.618889</td>\n",
       "      <td>0.632385</td>\n",
       "      <td>0.712338</td>\n",
       "      <td>0.547170</td>\n",
       "      <td>0.690608</td>\n",
       "      <td>914</td>\n",
       "      <td>0.654267</td>\n",
       "      <td>0.654267</td>\n",
       "      <td>0.712338</td>\n",
       "      <td>0.654267</td>\n",
       "      <td>0.654267</td>\n",
       "      <td>0.546878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.635900</td>\n",
       "      <td>0.652927</td>\n",
       "      <td>0.600807</td>\n",
       "      <td>0.630197</td>\n",
       "      <td>0.747885</td>\n",
       "      <td>0.492492</td>\n",
       "      <td>0.709122</td>\n",
       "      <td>914</td>\n",
       "      <td>0.673961</td>\n",
       "      <td>0.673961</td>\n",
       "      <td>0.747885</td>\n",
       "      <td>0.673961</td>\n",
       "      <td>0.673961</td>\n",
       "      <td>0.667615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.610800</td>\n",
       "      <td>0.620490</td>\n",
       "      <td>0.587967</td>\n",
       "      <td>0.624726</td>\n",
       "      <td>0.786405</td>\n",
       "      <td>0.711036</td>\n",
       "      <td>0.464899</td>\n",
       "      <td>914</td>\n",
       "      <td>0.713348</td>\n",
       "      <td>0.713348</td>\n",
       "      <td>0.786405</td>\n",
       "      <td>0.713348</td>\n",
       "      <td>0.713348</td>\n",
       "      <td>0.328016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.569700</td>\n",
       "      <td>0.551523</td>\n",
       "      <td>0.704424</td>\n",
       "      <td>0.704595</td>\n",
       "      <td>0.784849</td>\n",
       "      <td>0.697309</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>914</td>\n",
       "      <td>0.693654</td>\n",
       "      <td>0.693654</td>\n",
       "      <td>0.784849</td>\n",
       "      <td>0.693654</td>\n",
       "      <td>0.693654</td>\n",
       "      <td>0.522445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.526000</td>\n",
       "      <td>0.604579</td>\n",
       "      <td>0.657854</td>\n",
       "      <td>0.665208</td>\n",
       "      <td>0.772166</td>\n",
       "      <td>0.708015</td>\n",
       "      <td>0.607692</td>\n",
       "      <td>914</td>\n",
       "      <td>0.704595</td>\n",
       "      <td>0.704595</td>\n",
       "      <td>0.772166</td>\n",
       "      <td>0.704595</td>\n",
       "      <td>0.704595</td>\n",
       "      <td>0.374061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.516400</td>\n",
       "      <td>0.491743</td>\n",
       "      <td>0.749417</td>\n",
       "      <td>0.749453</td>\n",
       "      <td>0.838199</td>\n",
       "      <td>0.752432</td>\n",
       "      <td>0.746401</td>\n",
       "      <td>914</td>\n",
       "      <td>0.750547</td>\n",
       "      <td>0.750547</td>\n",
       "      <td>0.838199</td>\n",
       "      <td>0.750547</td>\n",
       "      <td>0.750547</td>\n",
       "      <td>0.480892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.473500</td>\n",
       "      <td>0.504985</td>\n",
       "      <td>0.753468</td>\n",
       "      <td>0.753829</td>\n",
       "      <td>0.835245</td>\n",
       "      <td>0.762908</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>914</td>\n",
       "      <td>0.748359</td>\n",
       "      <td>0.748359</td>\n",
       "      <td>0.835245</td>\n",
       "      <td>0.748359</td>\n",
       "      <td>0.748359</td>\n",
       "      <td>0.449426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.465700</td>\n",
       "      <td>0.505468</td>\n",
       "      <td>0.741145</td>\n",
       "      <td>0.742888</td>\n",
       "      <td>0.844811</td>\n",
       "      <td>0.762386</td>\n",
       "      <td>0.719905</td>\n",
       "      <td>914</td>\n",
       "      <td>0.752735</td>\n",
       "      <td>0.752735</td>\n",
       "      <td>0.844811</td>\n",
       "      <td>0.752735</td>\n",
       "      <td>0.752735</td>\n",
       "      <td>0.395091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.481900</td>\n",
       "      <td>0.508310</td>\n",
       "      <td>0.752365</td>\n",
       "      <td>0.756018</td>\n",
       "      <td>0.853037</td>\n",
       "      <td>0.782439</td>\n",
       "      <td>0.722291</td>\n",
       "      <td>914</td>\n",
       "      <td>0.759300</td>\n",
       "      <td>0.759300</td>\n",
       "      <td>0.853037</td>\n",
       "      <td>0.759300</td>\n",
       "      <td>0.759300</td>\n",
       "      <td>0.353561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.472700</td>\n",
       "      <td>0.470337</td>\n",
       "      <td>0.772245</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.858510</td>\n",
       "      <td>0.765766</td>\n",
       "      <td>0.778723</td>\n",
       "      <td>914</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.858510</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.533881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.476900</td>\n",
       "      <td>0.467257</td>\n",
       "      <td>0.771988</td>\n",
       "      <td>0.773523</td>\n",
       "      <td>0.861350</td>\n",
       "      <td>0.753278</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>914</td>\n",
       "      <td>0.770241</td>\n",
       "      <td>0.770241</td>\n",
       "      <td>0.861350</td>\n",
       "      <td>0.770241</td>\n",
       "      <td>0.770241</td>\n",
       "      <td>0.589939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.425500</td>\n",
       "      <td>0.490212</td>\n",
       "      <td>0.758402</td>\n",
       "      <td>0.760394</td>\n",
       "      <td>0.863289</td>\n",
       "      <td>0.736462</td>\n",
       "      <td>0.780341</td>\n",
       "      <td>914</td>\n",
       "      <td>0.770241</td>\n",
       "      <td>0.770241</td>\n",
       "      <td>0.863289</td>\n",
       "      <td>0.770241</td>\n",
       "      <td>0.770241</td>\n",
       "      <td>0.637921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.452000</td>\n",
       "      <td>0.461670</td>\n",
       "      <td>0.768881</td>\n",
       "      <td>0.769147</td>\n",
       "      <td>0.862719</td>\n",
       "      <td>0.761042</td>\n",
       "      <td>0.776720</td>\n",
       "      <td>914</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.862719</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.554111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.439500</td>\n",
       "      <td>0.471854</td>\n",
       "      <td>0.769551</td>\n",
       "      <td>0.770241</td>\n",
       "      <td>0.861498</td>\n",
       "      <td>0.782158</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>914</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.861498</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.422673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.457288</td>\n",
       "      <td>0.776719</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.867574</td>\n",
       "      <td>0.781116</td>\n",
       "      <td>0.772321</td>\n",
       "      <td>914</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.867574</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.471254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.445300</td>\n",
       "      <td>0.444029</td>\n",
       "      <td>0.783344</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.870821</td>\n",
       "      <td>0.780973</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>914</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.870821</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.513339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.420300</td>\n",
       "      <td>0.444484</td>\n",
       "      <td>0.782275</td>\n",
       "      <td>0.782276</td>\n",
       "      <td>0.872065</td>\n",
       "      <td>0.782037</td>\n",
       "      <td>0.782514</td>\n",
       "      <td>914</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.872065</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.502879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.397000</td>\n",
       "      <td>0.464725</td>\n",
       "      <td>0.781747</td>\n",
       "      <td>0.782276</td>\n",
       "      <td>0.872338</td>\n",
       "      <td>0.771001</td>\n",
       "      <td>0.792492</td>\n",
       "      <td>914</td>\n",
       "      <td>0.781182</td>\n",
       "      <td>0.781182</td>\n",
       "      <td>0.872338</td>\n",
       "      <td>0.781182</td>\n",
       "      <td>0.781182</td>\n",
       "      <td>0.581900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.421000</td>\n",
       "      <td>0.461990</td>\n",
       "      <td>0.780576</td>\n",
       "      <td>0.781182</td>\n",
       "      <td>0.870528</td>\n",
       "      <td>0.792100</td>\n",
       "      <td>0.769053</td>\n",
       "      <td>914</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.870528</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.425288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.388200</td>\n",
       "      <td>0.447397</td>\n",
       "      <td>0.782244</td>\n",
       "      <td>0.782276</td>\n",
       "      <td>0.876394</td>\n",
       "      <td>0.784865</td>\n",
       "      <td>0.779623</td>\n",
       "      <td>914</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.876394</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.484543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.402700</td>\n",
       "      <td>0.462085</td>\n",
       "      <td>0.777310</td>\n",
       "      <td>0.777899</td>\n",
       "      <td>0.874464</td>\n",
       "      <td>0.765859</td>\n",
       "      <td>0.788762</td>\n",
       "      <td>914</td>\n",
       "      <td>0.781182</td>\n",
       "      <td>0.781182</td>\n",
       "      <td>0.874464</td>\n",
       "      <td>0.781182</td>\n",
       "      <td>0.781182</td>\n",
       "      <td>0.591290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.408100</td>\n",
       "      <td>0.455841</td>\n",
       "      <td>0.773210</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.877079</td>\n",
       "      <td>0.791075</td>\n",
       "      <td>0.755344</td>\n",
       "      <td>914</td>\n",
       "      <td>0.785558</td>\n",
       "      <td>0.785558</td>\n",
       "      <td>0.877079</td>\n",
       "      <td>0.785558</td>\n",
       "      <td>0.785558</td>\n",
       "      <td>0.380114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.357900</td>\n",
       "      <td>0.506992</td>\n",
       "      <td>0.759764</td>\n",
       "      <td>0.762582</td>\n",
       "      <td>0.873090</td>\n",
       "      <td>0.785785</td>\n",
       "      <td>0.733742</td>\n",
       "      <td>914</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.873090</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.314028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.413100</td>\n",
       "      <td>0.438362</td>\n",
       "      <td>0.783244</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.879602</td>\n",
       "      <td>0.778027</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>914</td>\n",
       "      <td>0.789934</td>\n",
       "      <td>0.789934</td>\n",
       "      <td>0.879602</td>\n",
       "      <td>0.789934</td>\n",
       "      <td>0.789934</td>\n",
       "      <td>0.535901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.398200</td>\n",
       "      <td>0.450241</td>\n",
       "      <td>0.777782</td>\n",
       "      <td>0.777899</td>\n",
       "      <td>0.876246</td>\n",
       "      <td>0.782888</td>\n",
       "      <td>0.772676</td>\n",
       "      <td>914</td>\n",
       "      <td>0.778993</td>\n",
       "      <td>0.778993</td>\n",
       "      <td>0.876246</td>\n",
       "      <td>0.778993</td>\n",
       "      <td>0.778993</td>\n",
       "      <td>0.455017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.364300</td>\n",
       "      <td>0.453869</td>\n",
       "      <td>0.782432</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.879650</td>\n",
       "      <td>0.768150</td>\n",
       "      <td>0.796715</td>\n",
       "      <td>914</td>\n",
       "      <td>0.781182</td>\n",
       "      <td>0.781182</td>\n",
       "      <td>0.879650</td>\n",
       "      <td>0.781182</td>\n",
       "      <td>0.781182</td>\n",
       "      <td>0.601942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.361100</td>\n",
       "      <td>0.451218</td>\n",
       "      <td>0.790846</td>\n",
       "      <td>0.791028</td>\n",
       "      <td>0.880464</td>\n",
       "      <td>0.784667</td>\n",
       "      <td>0.797024</td>\n",
       "      <td>914</td>\n",
       "      <td>0.796499</td>\n",
       "      <td>0.796499</td>\n",
       "      <td>0.880464</td>\n",
       "      <td>0.796499</td>\n",
       "      <td>0.796499</td>\n",
       "      <td>0.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.398000</td>\n",
       "      <td>0.438714</td>\n",
       "      <td>0.791898</td>\n",
       "      <td>0.792123</td>\n",
       "      <td>0.882092</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.798729</td>\n",
       "      <td>914</td>\n",
       "      <td>0.789934</td>\n",
       "      <td>0.789934</td>\n",
       "      <td>0.882092</td>\n",
       "      <td>0.789934</td>\n",
       "      <td>0.789934</td>\n",
       "      <td>0.564819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.372100</td>\n",
       "      <td>0.493695</td>\n",
       "      <td>0.753353</td>\n",
       "      <td>0.756018</td>\n",
       "      <td>0.872358</td>\n",
       "      <td>0.778989</td>\n",
       "      <td>0.727717</td>\n",
       "      <td>914</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.872358</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.327083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>0.346100</td>\n",
       "      <td>0.439029</td>\n",
       "      <td>0.784433</td>\n",
       "      <td>0.784464</td>\n",
       "      <td>0.884649</td>\n",
       "      <td>0.781838</td>\n",
       "      <td>0.787027</td>\n",
       "      <td>914</td>\n",
       "      <td>0.785558</td>\n",
       "      <td>0.785558</td>\n",
       "      <td>0.884649</td>\n",
       "      <td>0.785558</td>\n",
       "      <td>0.785558</td>\n",
       "      <td>0.518424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.371800</td>\n",
       "      <td>0.436139</td>\n",
       "      <td>0.786646</td>\n",
       "      <td>0.786652</td>\n",
       "      <td>0.881302</td>\n",
       "      <td>0.787813</td>\n",
       "      <td>0.785479</td>\n",
       "      <td>914</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.881302</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.489012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.342400</td>\n",
       "      <td>0.439113</td>\n",
       "      <td>0.795350</td>\n",
       "      <td>0.795405</td>\n",
       "      <td>0.882695</td>\n",
       "      <td>0.791991</td>\n",
       "      <td>0.798708</td>\n",
       "      <td>914</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.882695</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.525284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>0.333800</td>\n",
       "      <td>0.449875</td>\n",
       "      <td>0.794089</td>\n",
       "      <td>0.794311</td>\n",
       "      <td>0.884208</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.800847</td>\n",
       "      <td>914</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.884208</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.567969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>0.343400</td>\n",
       "      <td>0.453664</td>\n",
       "      <td>0.782092</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.885329</td>\n",
       "      <td>0.765403</td>\n",
       "      <td>0.798780</td>\n",
       "      <td>914</td>\n",
       "      <td>0.794311</td>\n",
       "      <td>0.794311</td>\n",
       "      <td>0.885329</td>\n",
       "      <td>0.794311</td>\n",
       "      <td>0.794311</td>\n",
       "      <td>0.634105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.350500</td>\n",
       "      <td>0.433290</td>\n",
       "      <td>0.786650</td>\n",
       "      <td>0.786652</td>\n",
       "      <td>0.884405</td>\n",
       "      <td>0.785950</td>\n",
       "      <td>0.787350</td>\n",
       "      <td>914</td>\n",
       "      <td>0.785558</td>\n",
       "      <td>0.785558</td>\n",
       "      <td>0.884405</td>\n",
       "      <td>0.785558</td>\n",
       "      <td>0.785558</td>\n",
       "      <td>0.505691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.361400</td>\n",
       "      <td>0.435745</td>\n",
       "      <td>0.784443</td>\n",
       "      <td>0.784464</td>\n",
       "      <td>0.884323</td>\n",
       "      <td>0.782320</td>\n",
       "      <td>0.786566</td>\n",
       "      <td>914</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.884323</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.526594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640</td>\n",
       "      <td>0.328700</td>\n",
       "      <td>0.435363</td>\n",
       "      <td>0.796183</td>\n",
       "      <td>0.796499</td>\n",
       "      <td>0.885645</td>\n",
       "      <td>0.788155</td>\n",
       "      <td>0.804211</td>\n",
       "      <td>914</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.885645</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.563047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.326000</td>\n",
       "      <td>0.449478</td>\n",
       "      <td>0.786578</td>\n",
       "      <td>0.786652</td>\n",
       "      <td>0.884361</td>\n",
       "      <td>0.790548</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>914</td>\n",
       "      <td>0.781182</td>\n",
       "      <td>0.781182</td>\n",
       "      <td>0.884361</td>\n",
       "      <td>0.781182</td>\n",
       "      <td>0.781182</td>\n",
       "      <td>0.470115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1720</td>\n",
       "      <td>0.325700</td>\n",
       "      <td>0.459684</td>\n",
       "      <td>0.776698</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.878793</td>\n",
       "      <td>0.781585</td>\n",
       "      <td>0.771812</td>\n",
       "      <td>914</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.878793</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.457657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>0.332300</td>\n",
       "      <td>0.440892</td>\n",
       "      <td>0.789764</td>\n",
       "      <td>0.789934</td>\n",
       "      <td>0.884859</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.795745</td>\n",
       "      <td>914</td>\n",
       "      <td>0.785558</td>\n",
       "      <td>0.785558</td>\n",
       "      <td>0.884859</td>\n",
       "      <td>0.785558</td>\n",
       "      <td>0.785558</td>\n",
       "      <td>0.544673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.355600</td>\n",
       "      <td>0.440948</td>\n",
       "      <td>0.781172</td>\n",
       "      <td>0.781182</td>\n",
       "      <td>0.885903</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.779736</td>\n",
       "      <td>914</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.885903</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.486669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1840</td>\n",
       "      <td>0.316200</td>\n",
       "      <td>0.447599</td>\n",
       "      <td>0.791867</td>\n",
       "      <td>0.792123</td>\n",
       "      <td>0.886674</td>\n",
       "      <td>0.784580</td>\n",
       "      <td>0.799154</td>\n",
       "      <td>914</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.886674</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.567743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1880</td>\n",
       "      <td>0.331600</td>\n",
       "      <td>0.453948</td>\n",
       "      <td>0.786946</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.887095</td>\n",
       "      <td>0.773893</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>914</td>\n",
       "      <td>0.794311</td>\n",
       "      <td>0.794311</td>\n",
       "      <td>0.887095</td>\n",
       "      <td>0.794311</td>\n",
       "      <td>0.794311</td>\n",
       "      <td>0.614767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.306500</td>\n",
       "      <td>0.446617</td>\n",
       "      <td>0.789737</td>\n",
       "      <td>0.789934</td>\n",
       "      <td>0.886641</td>\n",
       "      <td>0.783296</td>\n",
       "      <td>0.796178</td>\n",
       "      <td>914</td>\n",
       "      <td>0.792123</td>\n",
       "      <td>0.792123</td>\n",
       "      <td>0.886641</td>\n",
       "      <td>0.792123</td>\n",
       "      <td>0.792123</td>\n",
       "      <td>0.560118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1960</td>\n",
       "      <td>0.312900</td>\n",
       "      <td>0.447741</td>\n",
       "      <td>0.782244</td>\n",
       "      <td>0.782276</td>\n",
       "      <td>0.884955</td>\n",
       "      <td>0.784865</td>\n",
       "      <td>0.779623</td>\n",
       "      <td>914</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.884955</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.470156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 01:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "early stopping required metric_for_best_model, but did not find eval_loss so early stopping is disabled\n",
      "early stopping required metric_for_best_model, but did not find eval_loss so early stopping is disabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on eval set\n",
      "{\n",
      "    \"eval_loss\": 0.4332904517650604,\n",
      "    \"eval_f1_weighted\": 0.7866497802814744,\n",
      "    \"eval_accuracy\": 0.7866520787746171,\n",
      "    \"eval_roc_auc\": 0.8844045219273254,\n",
      "    \"eval_f1_human\": 0.7859495060373216,\n",
      "    \"eval_f1_ai\": 0.787350054525627,\n",
      "    \"eval_n_samples\": 914,\n",
      "    \"eval_f1_weighted_median\": 0.7855579868708972,\n",
      "    \"eval_accuracy_median\": 0.7855579868708972,\n",
      "    \"eval_roc_auc_median\": 0.8844045219273254,\n",
      "    \"eval_f1_human_median\": 0.7855579868708972,\n",
      "    \"eval_f1_ai_median\": 0.7855579868708972,\n",
      "    \"eval_threshold_median\": 0.5056906342506409,\n",
      "    \"eval_runtime\": 6.5166,\n",
      "    \"eval_samples_per_second\": 140.258,\n",
      "    \"eval_steps_per_second\": 0.153,\n",
      "    \"epoch\": 9.751243781094526\n",
      "}\n",
      "Evaluating on test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "early stopping required metric_for_best_model, but did not find eval_loss so early stopping is disabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"test_loss\": 0.40844404697418213,\n",
      "    \"test_f1_weighted\": 0.8028911593517408,\n",
      "    \"test_accuracy\": 0.8029475982532751,\n",
      "    \"test_roc_auc\": 0.895299002688736,\n",
      "    \"test_f1_human\": 0.7995558023320377,\n",
      "    \"test_f1_ai\": 0.8062265163714439,\n",
      "    \"test_n_samples\": 1832,\n",
      "    \"test_f1_weighted_median\": 0.8034934497816594,\n",
      "    \"test_accuracy_median\": 0.8034934497816594,\n",
      "    \"test_roc_auc_median\": 0.895299002688736,\n",
      "    \"test_f1_human_median\": 0.8034934497816594,\n",
      "    \"test_f1_ai_median\": 0.8034934497816594,\n",
      "    \"test_threshold_median\": 0.5382753610610962,\n",
      "    \"test_runtime\": 6.4001,\n",
      "    \"test_samples_per_second\": 286.247,\n",
      "    \"test_steps_per_second\": 0.312,\n",
      "    \"epoch\": 9.751243781094526\n",
      "}\n",
      "Evaluating on unmatched set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "early stopping required metric_for_best_model, but did not find eval_loss so early stopping is disabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"unmatched_loss\": 0.7418467402458191,\n",
      "    \"unmatched_f1_weighted\": 0.6549759640254106,\n",
      "    \"unmatched_accuracy\": 0.660996705107084,\n",
      "    \"unmatched_roc_auc\": 0.7125407599408184,\n",
      "    \"unmatched_f1_human\": 0.7243007871378329,\n",
      "    \"unmatched_f1_ai\": 0.5599572306869821,\n",
      "    \"unmatched_n_samples\": 24280,\n",
      "    \"unmatched_f1_weighted_mean\": 0.6562964295067472,\n",
      "    \"unmatched_accuracy_mean\": 0.6559719934102142,\n",
      "    \"unmatched_roc_auc_mean\": 0.7125407599408184,\n",
      "    \"unmatched_f1_human_mean\": 0.7008987717979017,\n",
      "    \"unmatched_f1_ai_mean\": 0.5951630882566762,\n",
      "    \"unmatched_threshold_mean\": 0.38968026638031006,\n",
      "    \"unmatched_n_samples_human\": 14038,\n",
      "    \"unmatched_n_samples_ai\": 10242,\n",
      "    \"unmatched_runtime\": 41.5494,\n",
      "    \"unmatched_samples_per_second\": 584.364,\n",
      "    \"unmatched_steps_per_second\": 0.578,\n",
      "    \"epoch\": 9.751243781094526\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer._load_best_model()\n",
    "classifier = trainer.model\n",
    "\n",
    "metrics_eval = trainer.evaluate()\n",
    "metrics_test = trainer.evaluate(datasets_matched[\"test\"], metric_key_prefix=\"test\")\n",
    "metrics_unmatched = trainer.evaluate(dataset_unmatched, metric_key_prefix=\"unmatched\")\n",
    "\n",
    "path = save_model(trainer, config)\n",
    "\n",
    "print(\"Evaluating on eval set\")\n",
    "metrics_eval = trainer.evaluate()\n",
    "print(json.dumps(metrics_eval, indent=4))\n",
    "\n",
    "print(\"Evaluating on test set\")\n",
    "metrics_test = trainer.evaluate(\n",
    "    datasets_matched[\"test\"],  # type: ignore\n",
    "    metric_key_prefix=\"test\",\n",
    ")\n",
    "print(json.dumps(metrics_test, indent=4))\n",
    "\n",
    "print(\"Evaluating on unmatched set\")\n",
    "metrics_unmatched = trainer.evaluate(\n",
    "    dataset_unmatched,  # type: ignore\n",
    "    metric_key_prefix=\"unmatched\",\n",
    ")\n",
    "print(json.dumps(metrics_unmatched, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2ea5390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib.image import AxesImage\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "cubehelix = sns.cubehelix_palette(as_cmap=True)\n",
    "\n",
    "\n",
    "def visualize_features(features: NDArray, cmap=cubehelix, size=4) -> AxesImage:\n",
    "    a = features.shape[0] / features.shape[1]\n",
    "    h, w = (size, size * a) if a > 1 else (size, size / a)\n",
    "    fig, ax = plt.subplots(figsize=(h, w))\n",
    "    fig = ax.imshow(\n",
    "        features,\n",
    "        cmap=cmap,\n",
    "        vmin=min(0.0, features.min()),\n",
    "        vmax=max(1.0, features.max()),\n",
    "        aspect=\"equal\",\n",
    "    )\n",
    "    fig.axes.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f4ff18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "torch.Size([128, 13])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x3938.46 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'AltLuminarCNN' object has no attribute 'conv_layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m plt.show()\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode():\n\u001b[32m      8\u001b[39m     conv = (\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m         \u001b[43mclassifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv_layers\u001b[49m(features.T.unsqueeze(\u001b[32m0\u001b[39m).to(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     10\u001b[39m         .cpu()\n\u001b[32m     11\u001b[39m         .detach()[\u001b[32m0\u001b[39m].T\n\u001b[32m     12\u001b[39m     )\n\u001b[32m     13\u001b[39m     \u001b[38;5;28mprint\u001b[39m(conv.shape)\n\u001b[32m     14\u001b[39m     visualize_features(conv.clip(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m).numpy().T)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nvme/projects/PrismAI/PrismAI/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1940\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1938\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1939\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1941\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1942\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'AltLuminarCNN' object has no attribute 'conv_layers'"
     ]
    }
   ],
   "source": [
    "sample = datasets_matched[\"test\"][4]\n",
    "print(sample[\"labels\"])\n",
    "features = sample[\"features\"]\n",
    "print(features.shape)\n",
    "visualize_features(features.T)\n",
    "plt.show()\n",
    "with torch.inference_mode():\n",
    "    conv = (\n",
    "        classifier.conv_layers(features.T.unsqueeze(0).to(\"cuda\"))\n",
    "        .cpu()\n",
    "        .detach()[0].T\n",
    "    )\n",
    "    print(conv.shape)\n",
    "    visualize_features(conv.clip(0, 1).numpy().T)\n",
    "    plt.show()\n",
    "\n",
    "    ff = classifier.projection[:-1](conv.unsqueeze(0).to(\"cuda\")).cpu().detach()[0]\n",
    "    print(ff.shape)\n",
    "    visualize_features(ff.numpy().T)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3542678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = datasets_matched[\"test\"][-1]\n",
    "print(sample[\"labels\"])\n",
    "features = sample[\"features\"]\n",
    "print(features.shape)\n",
    "visualize_features(features.T)\n",
    "plt.show()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    conv = (\n",
    "        classifier.conv_layers[:-1](features.T.unsqueeze(0).to(\"cuda\"))\n",
    "        .cpu()\n",
    "        .detach()[0]\n",
    "        .T\n",
    "    )\n",
    "    print(conv.shape)\n",
    "    visualize_features(conv.clip(0, 1).numpy().T)\n",
    "    plt.show()\n",
    "\n",
    "    ff = classifier.projection[:-1](conv.unsqueeze(0).to(\"cuda\")).cpu().detach()[0]\n",
    "    print(ff.shape)\n",
    "    visualize_features(ff.numpy().T)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204bf89b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b95ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47c00fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise RuntimeError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc98970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(scores, indent=4))\n",
    "with open(\"../logs/luminar/gpt2_first_128-3_epochs.json\", \"w\") as f:\n",
    "    json.dump(scores, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d739a695",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for subset in [\n",
    "    \"blog_authorship_corpus\",\n",
    "    \"student_essays\",\n",
    "    \"cnn_news\",\n",
    "    \"euro_court_cases\",\n",
    "    \"house_of_commons\",\n",
    "    \"arxiv_papers\",\n",
    "    \"gutenberg_en\",\n",
    "    \"en\",\n",
    "    \"bundestag\",\n",
    "    \"spiegel_articles\",\n",
    "    \"gutenberg_de\",\n",
    "    \"de\",\n",
    "]:\n",
    "    datset_config_name = f\"{subset}-fulltext\"\n",
    "    datasets[datset_config_name] = load_dataset(\n",
    "        \"liberi-luminaris/PrismAI-encoded-gpt2\",\n",
    "        datset_config_name,\n",
    "        token=HF_TOKEN,\n",
    "        split=\"human+gpt_4o_mini\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531a62b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    \"liberi-luminaris/PrismAI-fulltext\", \"cnn_news\", split=\"human+gpt_4o_mini\"\n",
    ")\n",
    "dataset_human = dataset.filter(lambda sample: sample[\"agent\"] == \"human\")\n",
    "source_ids = set(\n",
    "    dataset_human.shuffle(seed=42).take(len(dataset_human) // 10 * 8)[\"id_source\"]\n",
    ")\n",
    "dataset_train = dataset.filter(lambda sample: sample[\"id_source\"] in source_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ec3e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_truncated = {}\n",
    "for datset_config_name, dataset in datasets.items():\n",
    "    datasets_truncated[datset_config_name] = dataset.with_format(\n",
    "        \"numpy\", columns=[\"features\"], output_all_columns=True\n",
    "    ).map(\n",
    "        lambda batch: {\"features\": batch[\"features\"][:, :256]},\n",
    "        batched=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18961af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_considered = {\n",
    "    key: value\n",
    "    for key, value in datasets_truncated.items()\n",
    "    if not key.startswith(\"de-\") and not key.startswith(\"en-\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2174dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "domains = [\n",
    "    \"Web Blogs\",\n",
    "    \"Essays\",\n",
    "    \"CNN\",\n",
    "    \"ECHR\",\n",
    "    \"HoC\",\n",
    "    \"arXiv\",\n",
    "    \"Gutenberg$_{en}$\",\n",
    "    \"Bundestag$_{de}$\",\n",
    "    \"Spiegel$_{de}$\",\n",
    "    \"Gutenberg$_{de}$\",\n",
    "    \"All$_{en}$\",\n",
    "    \"All$_{de}$\",\n",
    "]\n",
    "name_map = {\n",
    "    \"blog_authorship_corpus\": \"Web Blogs\",\n",
    "    \"student_essays\": \"Essays\",\n",
    "    \"cnn_news\": \"CNN\",\n",
    "    \"euro_court_cases\": \"ECHR\",\n",
    "    \"house_of_commons\": \"HoC\",\n",
    "    \"arxiv_papers\": \"arXiv\",\n",
    "    \"gutenberg_en\": \"Gutenberg$_{en}$\",\n",
    "    \"bundestag\": \"Bundestag$_{de}$\",\n",
    "    \"spiegel_articles\": \"Spiegel$_{de}$\",\n",
    "    \"gutenberg_de\": \"Gutenberg$_{de}$\",\n",
    "    \"en\": \"All$_{en}$\",\n",
    "    \"de\": \"All$_{de}$\",\n",
    "}\n",
    "\n",
    "results = [\n",
    "    {\"domain\": name_map[key.split(\"-\", 1)[0]]}\n",
    "    | {\n",
    "        \"f1\": value[\"f1\"],\n",
    "        \"acc\": value[\"accuracy\"],\n",
    "        \"auroc\": value[\"auroc\"],\n",
    "    }\n",
    "    for key, value in scores.items()\n",
    "]\n",
    "metric_df = (\n",
    "    pd.DataFrame(results)\n",
    "    .set_index(\"domain\")\n",
    "    .sort_index(key=lambda x: list(map(domains.index, x)))\n",
    ")\n",
    "print(metric_df.to_latex(float_format=\"%.3f\", index=True))\n",
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e71e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_detector(\n",
    "#     detector: DetectorABC, datasets: dict[str, DatasetDict]\n",
    "# ) -> dict[str, float]:\n",
    "#     scores = {}\n",
    "#     for config_name, ds in tqdm(datasets.items(), desc=\"Predicting on Datasets\"):\n",
    "#         dataset: Dataset = ds[\"test\"].map(\n",
    "#             detector.tokenize,\n",
    "#             input_columns=[\"text\"],\n",
    "#             batched=True,\n",
    "#             batch_size=1024,\n",
    "#             desc=\"Tokenizing\",\n",
    "#         )\n",
    "#         dataset = dataset.sort(\"length\")\n",
    "#         dataset = dataset.map(\n",
    "#             detector.process,\n",
    "#             batched=True,\n",
    "#             batch_size=128,\n",
    "#             desc=\"Predicting\",\n",
    "#         )\n",
    "\n",
    "#         dataset_np = dataset.select_columns([\"prediction\", \"label\"]).with_format(\n",
    "#             \"numpy\"\n",
    "#         )\n",
    "\n",
    "#         acc, f1, auroc = get_scores(dataset_np[\"label\"], dataset_np[\"prediction\"])\n",
    "#         scores[config_name] = {\"accuracy\": acc, \"f1\": f1, \"auroc\": auroc}\n",
    "\n",
    "#         acc, f1, auroc = get_scores(\n",
    "#             dataset_np[\"label\"],\n",
    "#             dataset_np[\"prediction\"],\n",
    "#             calibrated=True,\n",
    "#         )\n",
    "#         scores[config_name] |= {\n",
    "#             \"accuracy_calibrated\": acc,\n",
    "#             \"f1_calibrated\": f1,\n",
    "#             \"auroc_calibrated\": auroc,\n",
    "#         }\n",
    "#     return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7958c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(model: LuminarClassifier, datasets: dict[str, DatasetDict]) -> dict:\n",
    "#     scores = {}\n",
    "#     for config_name, dataset in tqdm(datasets.items(), desc=\"Evaluating\", leave=False):\n",
    "#         ds = (\n",
    "#             dataset[\"test\"]\n",
    "#             .with_format(\"torch\", [\"features\"])\n",
    "#             .map(model.process, batched=True, batch_size=32, desc=\"Predicting\")\n",
    "#         )\n",
    "#         dataset_np = ds.select_columns([\"prediction\", \"label\"]).with_format(\"numpy\")\n",
    "\n",
    "#         acc, f1, auroc = get_scores(dataset_np[\"label\"], dataset_np[\"prediction\"])\n",
    "#         scores[config_name] = {\n",
    "#             \"accuracy\": acc,\n",
    "#             \"f1\": f1,\n",
    "#             \"auroc\": auroc,\n",
    "#         }\n",
    "\n",
    "#         acc, f1, auroc = get_scores(\n",
    "#             dataset_np[\"label\"],\n",
    "#             dataset_np[\"prediction\"],\n",
    "#             calibrated=True,\n",
    "#         )\n",
    "#         scores[config_name] |= {\n",
    "#             \"accuracy_calibrated\": acc,\n",
    "#             \"f1_calibrated\": f1,\n",
    "#             \"auroc_calibrated\": auroc,\n",
    "#         }\n",
    "\n",
    "#     return scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
