{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-06T09:43:29.703864Z",
     "start_time": "2025-08-06T09:43:27.991370Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T09:43:29.845027Z",
     "start_time": "2025-08-06T09:43:29.769123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import torch\n",
    "import wandb\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, str(Path().resolve().parent))\n",
    "\n",
    "from luminar.utils import get_best_device\n",
    "from luminar.utils import LuminarSequenceTrainingConfig, ConvolutionalLayerSpec\n",
    "from luminar.sequence_trainer import LuminarSequenceTrainer\n",
    "from luminar.encoder import LuminarEncoder\n",
    "from data_hub.sequential_data_processor import SequentialDataProcessor\n",
    "from data_hub.hub import DataHub\n",
    "\n",
    "device = get_best_device()\n",
    "print(device)"
   ],
   "id": "75ba7872610f2cee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T09:43:39.410798Z",
     "start_time": "2025-08-06T09:43:30.032533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_hub = DataHub((Path.home() / \".hf_token\").read_text().strip())\n",
    "dataset = data_hub.get_splits(\"liberi-luminaris/MAGE-encoded-gpt2\")\n",
    "print(dataset)"
   ],
   "id": "5abe49e29123476a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b9218ee44f54975bbbc7118c1cb754f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad293bd15320474cb86efa3788c639f9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/24 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4a7afc6476764370a3f2f287919a557b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label ID mapping:\n",
      "0 → human\n",
      "1 → ai\n",
      "2 → fusion\n",
      "train distribution:\n",
      "  ai: 197276 (65.1%)\n",
      "  human: 105600 (34.9%)\n",
      "eval distribution:\n",
      "  ai: 28183 (65.1%)\n",
      "  human: 15086 (34.9%)\n",
      "test distribution:\n",
      "  human: 30172 (34.9%)\n",
      "  ai: 56365 (65.1%)\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'text', 'domain', 'date', 'source', 'lang', 'label', 'agent', 'type', 'length', 'features', 'feature_length'],\n",
      "        num_rows: 302876\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['id', 'text', 'domain', 'date', 'source', 'lang', 'label', 'agent', 'type', 'length', 'features', 'feature_length'],\n",
      "        num_rows: 43269\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'text', 'domain', 'date', 'source', 'lang', 'label', 'agent', 'type', 'length', 'features', 'feature_length'],\n",
      "        num_rows: 86537\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T09:58:20.395711Z",
     "start_time": "2025-08-06T09:43:39.489623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_processor = SequentialDataProcessor(dataset, LuminarEncoder(\"gpt2\", device=device))\n",
    "dataset = data_processor.process_for_sequential()\n",
    "print(dataset)"
   ],
   "id": "1f9edab86b25bf7e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/staff_homes/kboenisc/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tokenizing text and extracting offsets:   0%|          | 0/302876 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "48006b22bac9425cb9cd158326270e7c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tokenizing text and extracting offsets:   0%|          | 0/43269 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1649ba7a659b47bcb630ab0106c41ca2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tokenizing text and extracting offsets:   0%|          | 0/86537 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "11c2575e33d54f3fb57f86f736456cc8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Assigning sentence spans to tokenized text:   0%|          | 0/302876 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3007115f5aa949119360cba76aa302f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Assigning sentence spans to tokenized text:   0%|          | 0/43269 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7d5c8956f9504945af8021f7cbb06e0b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Assigning sentence spans to tokenized text:   0%|          | 0/86537 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "03961a9647c7456cb4697bac7aec8430"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Assigning labels to sentence spans:   0%|          | 0/302876 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7968dd2cf6a6411bb4f82579a6af6de6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Assigning labels to sentence spans:   0%|          | 0/43269 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ebf26b3ade2c49e68dd76809e7120dfe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Assigning labels to sentence spans:   0%|          | 0/86537 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ddc73b2ff0441c0a89e6e8608360aca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'text', 'domain', 'date', 'source', 'lang', 'label', 'agent', 'type', 'length', 'features', 'feature_length', 'tokenized_text', 'sentence_token_spans', 'span_labels'],\n",
      "        num_rows: 302876\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['id', 'text', 'domain', 'date', 'source', 'lang', 'label', 'agent', 'type', 'length', 'features', 'feature_length', 'tokenized_text', 'sentence_token_spans', 'span_labels'],\n",
      "        num_rows: 43269\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'text', 'domain', 'date', 'source', 'lang', 'label', 'agent', 'type', 'length', 'features', 'feature_length', 'tokenized_text', 'sentence_token_spans', 'span_labels'],\n",
      "        num_rows: 86537\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Sanity Checks**\n",
    "\n",
    "Are there any fusion labels (2)? We need to handle them for now."
   ],
   "id": "830c4818af15721a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T10:06:09.712717Z",
     "start_time": "2025-08-06T09:58:20.805644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "splits_to_check = [\"train\", \"eval\", \"test\"]\n",
    "\n",
    "total_invalid_label_count = 0\n",
    "total_length_mismatch_count = 0\n",
    "\n",
    "for split in splits_to_check:\n",
    "    if split not in dataset:\n",
    "        print(f\"Split '{split}' not found in dataset. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nChecking split: {split}\")\n",
    "    invalid_label_count = 0\n",
    "    length_mismatch_count = 0\n",
    "\n",
    "    for i, example in enumerate(dataset[split]):\n",
    "        labels = example[\"span_labels\"]\n",
    "        spans = example[\"sentence_token_spans\"]\n",
    "\n",
    "        # Check for invalid labels\n",
    "        if any(label not in (0, 1) for label in labels):\n",
    "            print(f\"Invalid labels at {split}[{i}]: {labels}\")\n",
    "            invalid_label_count += 1\n",
    "\n",
    "        # Check for length mismatch\n",
    "        if len(labels) != len(spans):\n",
    "            print(f\"Length mismatch at {split}[{i}]: {len(labels)} labels vs {len(spans)} spans\")\n",
    "            length_mismatch_count += 1\n",
    "\n",
    "    print(f\"✅ {split} summary: {invalid_label_count} invalid label entries, {length_mismatch_count} length mismatches\")\n",
    "\n",
    "    total_invalid_label_count += invalid_label_count\n",
    "    total_length_mismatch_count += length_mismatch_count\n",
    "\n",
    "# Overall summary\n",
    "print(\"\\nOverall Summary:\")\n",
    "print(f\"Total entries with invalid labels: {total_invalid_label_count}\")\n",
    "print(f\"Total entries with length mismatch: {total_length_mismatch_count}\")\n"
   ],
   "id": "fc551c33d51409f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking split: train\n",
      "✅ train summary: 0 invalid label entries, 0 length mismatches\n",
      "\n",
      "Checking split: eval\n",
      "✅ eval summary: 0 invalid label entries, 0 length mismatches\n",
      "\n",
      "Checking split: test\n",
      "✅ test summary: 0 invalid label entries, 0 length mismatches\n",
      "\n",
      "Overall Summary:\n",
      "Total entries with invalid labels: 0\n",
      "Total entries with length mismatch: 0\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T10:16:07.151351Z",
     "start_time": "2025-08-06T10:06:09.850851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset, test_dataset, test_loader = data_processor.dataset_to_luminar_sequence_dataset(dataset)\n",
    "print(train_dataset)"
   ],
   "id": "a7321f432b21431c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<luminar.utils.training.LuminarSequenceDataset object at 0x7ce53f2f1610>\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T10:16:08.912096Z",
     "start_time": "2025-08-06T10:16:07.317432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "falcon_config = LuminarSequenceTrainingConfig(**{\n",
    "    \"feature_len\": 512,\n",
    "    \"num_intermediate_likelihoods\": 33,\n",
    "    \"conv_layer_shapes\": (\n",
    "        ConvolutionalLayerSpec(128, 5),\n",
    "        ConvolutionalLayerSpec(256, 5),\n",
    "    ),\n",
    "    \"projection_dim\": 128,\n",
    "    \"lstm_hidden_dim\": 256,\n",
    "    \"lstm_layers\": 1,\n",
    "    \"apply_delta_augmentation\": False,\n",
    "    \"apply_product_augmentation\": True,\n",
    "    \"max_epochs\": 115,\n",
    "    \"kfold\": 3,\n",
    "    \"early_stopping_patience\": 8,\n",
    "    \"learning_rate\": 1.03e-3,\n",
    "    \"batch_size\": 128,\n",
    "    \"seed\": 42,\n",
    "    \"rescale_features\": False,\n",
    "    \"stack_spans\": 3\n",
    "})\n",
    "\n",
    "gpt2_config = LuminarSequenceTrainingConfig(**{\n",
    "    \"feature_len\": 512,\n",
    "    \"num_intermediate_likelihoods\": 13,\n",
    "    \"conv_layer_shapes\": (\n",
    "        ConvolutionalLayerSpec(128, 5),\n",
    "        ConvolutionalLayerSpec(256, 5),\n",
    "    ),\n",
    "    \"projection_dim\": 64,\n",
    "    \"lstm_hidden_dim\": 128,\n",
    "    \"lstm_layers\": 1,\n",
    "    \"apply_delta_augmentation\": False,\n",
    "    \"apply_product_augmentation\": True,\n",
    "    \"max_epochs\": 115,\n",
    "    \"kfold\": 3,\n",
    "    \"early_stopping_patience\": 8,\n",
    "    \"learning_rate\": 2.05e-3,\n",
    "    \"batch_size\": 128,\n",
    "    \"seed\": 42,\n",
    "    \"rescale_features\": False,\n",
    "    \"stack_spans\": 3\n",
    "})"
   ],
   "id": "6adf7e57b36d7725",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T10:16:10.914469Z",
     "start_time": "2025-08-06T10:16:08.961241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "log_to_wandb = False\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    with torch.cuda.device(torch.cuda.current_device()):\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()"
   ],
   "id": "efa9766bdf5aad3e",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T13:47:56.981244Z",
     "start_time": "2025-08-06T10:16:10.971114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = LuminarSequenceTrainer(train_dataset=train_dataset,\n",
    "                                 test_data_loader = test_loader,\n",
    "                                 collate_fn=data_processor.collate_fn,\n",
    "                                 log_to_wandb=log_to_wandb,\n",
    "                                 config=gpt2_config,\n",
    "                                 device=get_best_device(),\n",
    "                                 use_experimental_attention=False)\n",
    "\n",
    "metrics, best_model = trainer.train()\n",
    "avg_f1 = metrics.get(\"f1_score\", 0.0)"
   ],
   "id": "df8e1caa10c971db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Fold 1/3 ==========\n",
      "LuminarSequenceTrainingConfig(feature_len=512, num_intermediate_likelihoods=13, apply_delta_augmentation=False, apply_product_augmentation=True, conv_layer_shapes=((128, 5, 1), (256, 5, 1)), projection_dim=64, lstm_hidden_dim=128, lstm_layers=1, stack_spans=3, dataset_root_path='/storage/projects/stoeckel/prismai/encoded/fulltext/', models_root_path='/storage/projects/boenisch/PrismAI/models/luminar_sequence/', domain='student_essays', agent='gpt_4o_mini_gemma2_9b', feature_agent='gpt2_512', max_epochs=115, batch_size=128, early_stopping_patience=8, rescale_features=False, kfold=3, learning_rate=0.00205, seed=42)\n",
      "\n",
      "Epoch 1/115\n",
      "Train Loss: 0.4740 | Eval Loss: 0.4010\n",
      "\n",
      "Epoch 2/115\n",
      "Train Loss: 0.3743 | Eval Loss: 0.3491\n",
      "\n",
      "Epoch 3/115\n",
      "Train Loss: 0.3482 | Eval Loss: 0.3301\n",
      "\n",
      "Epoch 4/115\n",
      "Train Loss: 0.3320 | Eval Loss: 0.3102\n",
      "\n",
      "Epoch 5/115\n",
      "Train Loss: 0.3178 | Eval Loss: 0.3131\n",
      "\n",
      "Epoch 6/115\n",
      "Train Loss: 0.3059 | Eval Loss: 0.3017\n",
      "\n",
      "Epoch 7/115\n",
      "Train Loss: 0.2964 | Eval Loss: 0.3287\n",
      "\n",
      "Epoch 8/115\n",
      "Train Loss: 0.2856 | Eval Loss: 0.2912\n",
      "\n",
      "Epoch 9/115\n",
      "Train Loss: 0.2759 | Eval Loss: 0.3056\n",
      "\n",
      "Epoch 10/115\n",
      "Train Loss: 0.2682 | Eval Loss: 0.2883\n",
      "\n",
      "Epoch 11/115\n",
      "Train Loss: 0.2603 | Eval Loss: 0.2948\n",
      "\n",
      "Epoch 12/115\n",
      "Train Loss: 0.2511 | Eval Loss: 0.2927\n",
      "\n",
      "Epoch 13/115\n",
      "Train Loss: 0.2487 | Eval Loss: 0.3163\n",
      "\n",
      "Epoch 14/115\n",
      "Train Loss: 0.2379 | Eval Loss: 0.2862\n",
      "\n",
      "Epoch 15/115\n",
      "Train Loss: 0.2289 | Eval Loss: 0.2993\n",
      "\n",
      "Epoch 16/115\n",
      "Train Loss: 0.2253 | Eval Loss: 0.2925\n",
      "\n",
      "Epoch 17/115\n",
      "Train Loss: 0.2242 | Eval Loss: 0.2943\n",
      "\n",
      "Epoch 18/115\n",
      "Train Loss: 0.2216 | Eval Loss: 0.3078\n",
      "\n",
      "Epoch 19/115\n",
      "Train Loss: 0.2137 | Eval Loss: 0.2889\n",
      "\n",
      "Epoch 20/115\n",
      "Train Loss: 0.2122 | Eval Loss: 0.2996\n",
      "\n",
      "Epoch 21/115\n",
      "Train Loss: 0.2074 | Eval Loss: 0.2960\n",
      "\n",
      "Epoch 22/115\n",
      "Train Loss: 0.2077 | Eval Loss: 0.2993\n",
      "Early stopping after 22 epochs.\n",
      "\n",
      "Best Eval Loss: 0.2862 | Best Train Loss: 0.2379\n",
      "\n",
      "Fold 1 Metrics:\n",
      "  f1_score: 0.8773\n",
      "  precision: 0.8779\n",
      "  recall: 0.8769\n",
      "  accuracy: 0.8769\n",
      "  roc_auc: 0.9474\n",
      "  fpr: 0.1699\n",
      "  tpr: 0.9004\n",
      "  f1_human: 0.8185\n",
      "  f1_ai: 0.9068\n",
      "\n",
      "========== Fold 2/3 ==========\n",
      "LuminarSequenceTrainingConfig(feature_len=512, num_intermediate_likelihoods=13, apply_delta_augmentation=False, apply_product_augmentation=True, conv_layer_shapes=((128, 5, 1), (256, 5, 1)), projection_dim=64, lstm_hidden_dim=128, lstm_layers=1, stack_spans=3, dataset_root_path='/storage/projects/stoeckel/prismai/encoded/fulltext/', models_root_path='/storage/projects/boenisch/PrismAI/models/luminar_sequence/', domain='student_essays', agent='gpt_4o_mini_gemma2_9b', feature_agent='gpt2_512', max_epochs=115, batch_size=128, early_stopping_patience=8, rescale_features=False, kfold=3, learning_rate=0.00205, seed=42)\n",
      "\n",
      "Epoch 1/115\n",
      "Train Loss: 0.4705 | Eval Loss: 0.3852\n",
      "\n",
      "Epoch 2/115\n",
      "Train Loss: 0.3858 | Eval Loss: 0.3578\n",
      "\n",
      "Epoch 3/115\n",
      "Train Loss: 0.3554 | Eval Loss: 0.3337\n",
      "\n",
      "Epoch 4/115\n",
      "Train Loss: 0.3359 | Eval Loss: 0.3627\n",
      "\n",
      "Epoch 5/115\n",
      "Train Loss: 0.3208 | Eval Loss: 0.3190\n",
      "\n",
      "Epoch 6/115\n",
      "Train Loss: 0.3078 | Eval Loss: 0.3202\n",
      "\n",
      "Epoch 7/115\n",
      "Train Loss: 0.2991 | Eval Loss: 0.2937\n",
      "\n",
      "Epoch 8/115\n",
      "Train Loss: 0.2917 | Eval Loss: 0.2990\n",
      "\n",
      "Epoch 9/115\n",
      "Train Loss: 0.2823 | Eval Loss: 0.2935\n",
      "\n",
      "Epoch 10/115\n",
      "Train Loss: 0.2720 | Eval Loss: 0.2976\n",
      "\n",
      "Epoch 11/115\n",
      "Train Loss: 0.2607 | Eval Loss: 0.3038\n",
      "\n",
      "Epoch 12/115\n",
      "Train Loss: 0.2555 | Eval Loss: 0.2813\n",
      "\n",
      "Epoch 13/115\n",
      "Train Loss: 0.2446 | Eval Loss: 0.2908\n",
      "\n",
      "Epoch 14/115\n",
      "Train Loss: 0.2388 | Eval Loss: 0.2909\n",
      "\n",
      "Epoch 15/115\n",
      "Train Loss: 0.2378 | Eval Loss: 0.3097\n",
      "\n",
      "Epoch 16/115\n",
      "Train Loss: 0.2285 | Eval Loss: 0.3441\n",
      "\n",
      "Epoch 17/115\n",
      "Train Loss: 0.2290 | Eval Loss: 0.2892\n",
      "\n",
      "Epoch 18/115\n",
      "Train Loss: 0.2197 | Eval Loss: 0.2873\n",
      "\n",
      "Epoch 19/115\n",
      "Train Loss: 0.2171 | Eval Loss: 0.2886\n",
      "\n",
      "Epoch 20/115\n",
      "Train Loss: 0.2104 | Eval Loss: 0.3551\n",
      "Early stopping after 20 epochs.\n",
      "\n",
      "Best Eval Loss: 0.2813 | Best Train Loss: 0.2555\n",
      "\n",
      "Fold 2 Metrics:\n",
      "  f1_score: 0.8515\n",
      "  precision: 0.8635\n",
      "  recall: 0.8485\n",
      "  accuracy: 0.8485\n",
      "  roc_auc: 0.9382\n",
      "  fpr: 0.1185\n",
      "  tpr: 0.8319\n",
      "  f1_human: 0.7956\n",
      "  f1_ai: 0.8796\n",
      "\n",
      "========== Fold 3/3 ==========\n",
      "LuminarSequenceTrainingConfig(feature_len=512, num_intermediate_likelihoods=13, apply_delta_augmentation=False, apply_product_augmentation=True, conv_layer_shapes=((128, 5, 1), (256, 5, 1)), projection_dim=64, lstm_hidden_dim=128, lstm_layers=1, stack_spans=3, dataset_root_path='/storage/projects/stoeckel/prismai/encoded/fulltext/', models_root_path='/storage/projects/boenisch/PrismAI/models/luminar_sequence/', domain='student_essays', agent='gpt_4o_mini_gemma2_9b', feature_agent='gpt2_512', max_epochs=115, batch_size=128, early_stopping_patience=8, rescale_features=False, kfold=3, learning_rate=0.00205, seed=42)\n",
      "\n",
      "Epoch 1/115\n",
      "Train Loss: 0.4764 | Eval Loss: 0.3856\n",
      "\n",
      "Epoch 2/115\n",
      "Train Loss: 0.3844 | Eval Loss: 0.3905\n",
      "\n",
      "Epoch 3/115\n",
      "Train Loss: 0.3564 | Eval Loss: 0.3618\n",
      "\n",
      "Epoch 4/115\n",
      "Train Loss: 0.3370 | Eval Loss: 0.3118\n",
      "\n",
      "Epoch 5/115\n",
      "Train Loss: 0.3225 | Eval Loss: 0.3056\n",
      "\n",
      "Epoch 6/115\n",
      "Train Loss: 0.3078 | Eval Loss: 0.3190\n",
      "\n",
      "Epoch 7/115\n",
      "Train Loss: 0.2998 | Eval Loss: 0.2940\n",
      "\n",
      "Epoch 8/115\n",
      "Train Loss: 0.2859 | Eval Loss: 0.3157\n",
      "\n",
      "Epoch 9/115\n",
      "Train Loss: 0.2764 | Eval Loss: 0.2885\n",
      "\n",
      "Epoch 10/115\n",
      "Train Loss: 0.2678 | Eval Loss: 0.2963\n",
      "\n",
      "Epoch 11/115\n",
      "Train Loss: 0.2596 | Eval Loss: 0.3009\n",
      "\n",
      "Epoch 12/115\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[42]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      1\u001B[39m trainer = LuminarSequenceTrainer(train_dataset=train_dataset,\n\u001B[32m      2\u001B[39m                                  test_data_loader = test_loader,\n\u001B[32m      3\u001B[39m                                  collate_fn=data_processor.collate_fn,\n\u001B[32m   (...)\u001B[39m\u001B[32m      6\u001B[39m                                  device=get_best_device(),\n\u001B[32m      7\u001B[39m                                  use_experimental_attention=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m metrics, best_model = \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     10\u001B[39m avg_f1 = metrics.get(\u001B[33m\"\u001B[39m\u001B[33mf1_score\u001B[39m\u001B[33m\"\u001B[39m, \u001B[32m0.0\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/home/prismAI/PrismAI/src/luminar/sequence_trainer.py:72\u001B[39m, in \u001B[36mLuminarSequenceTrainer.train\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     68\u001B[39m     model = LuminarSequence(\u001B[38;5;28mself\u001B[39m.config).to(\u001B[38;5;28mself\u001B[39m.device)\n\u001B[32m     70\u001B[39m optimizer = torch.optim.Adam(model.parameters(), lr=\u001B[38;5;28mself\u001B[39m.config.learning_rate)\n\u001B[32m---> \u001B[39m\u001B[32m72\u001B[39m model = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_train_and_evaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     73\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmax_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfold\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mearly_stopping_patience\u001B[49m\n\u001B[32m     74\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     76\u001B[39m \u001B[38;5;66;03m# Evaluate and collect fold metrics\u001B[39;00m\n\u001B[32m     77\u001B[39m metrics = \u001B[38;5;28mself\u001B[39m._evaluate_test(model)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/home/prismAI/PrismAI/src/luminar/sequence_trainer.py:144\u001B[39m, in \u001B[36m_train_and_evaluate\u001B[39m\u001B[34m(self, model, train_loader, eval_loader, optimizer, epochs, fold, patience)\u001B[39m\n\u001B[32m    141\u001B[39m span_labels = batch[\u001B[33m\"\u001B[39m\u001B[33mspan_labels\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m    143\u001B[39m optimizer.zero_grad()\n\u001B[32m--> \u001B[39m\u001B[32m144\u001B[39m output = model(features, sentence_spans, span_labels=span_labels)\n\u001B[32m    145\u001B[39m loss = output.loss\n\u001B[32m    147\u001B[39m loss.backward()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/luminar/lib/python3.12/site-packages/torch/_tensor.py:648\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    638\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    639\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    640\u001B[39m         Tensor.backward,\n\u001B[32m    641\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    646\u001B[39m         inputs=inputs,\n\u001B[32m    647\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m648\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    649\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    650\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/luminar/lib/python3.12/site-packages/torch/autograd/__init__.py:353\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    348\u001B[39m     retain_graph = create_graph\n\u001B[32m    350\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    351\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    352\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m353\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    354\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    356\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    357\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    358\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    359\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    360\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    361\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/luminar/lib/python3.12/site-packages/torch/autograd/graph.py:824\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    822\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    823\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m824\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    825\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    826\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    827\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    828\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T13:47:54.432115800Z",
     "start_time": "2025-08-06T09:37:45.875765Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "97f594dc3078571",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
