{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from lightning.pytorch import Trainer, seed_everything\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import openai\n",
    "\n",
    "\n",
    "client = openai.OpenAI(api_key=(Path.home() / (\".openai-key\")).read_text().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nvme/projects/PrismAI/PrismAI/.venv/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.3.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/nvme/projects/PrismAI/PrismAI/.venv/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator _SigmoidCalibration from version 1.3.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/nvme/projects/PrismAI/PrismAI/.venv/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator CalibratedClassifierCV from version 1.3.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Trigram Model...\n",
      "Tokenizing corpus...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57340/57340 [00:02<00:00, 28387.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training n-gram model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1283106/1283106 [00:00<00:00, 1672909.03it/s]\n",
      "100%|██████████| 1283105/1283105 [00:01<00:00, 1100940.39it/s]\n",
      "100%|██████████| 1283104/1283104 [00:02<00:00, 517280.78it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dill as pickle\n",
    "import tiktoken\n",
    "\n",
    "from ghostbuster.utils.featurize import t_featurize_logprobs, score_ngram\n",
    "from ghostbuster.utils.symbolic import (\n",
    "    train_trigram,\n",
    "    get_words,\n",
    "    vec_functions,\n",
    "    scalar_functions,\n",
    ")\n",
    "\n",
    "\n",
    "MAX_TOKENS = 2047\n",
    "best_features = open(\"ghostbuster/model/features.txt\").read().strip().split(\"\\n\")\n",
    "\n",
    "# Load davinci tokenizer\n",
    "enc = tiktoken.encoding_for_model(\"davinci-002\")\n",
    "\n",
    "# Load model\n",
    "model = pickle.load(open(\"ghostbuster/model/model\", \"rb\"))\n",
    "mu = pickle.load(open(\"ghostbuster/model/mu\", \"rb\"))\n",
    "sigma = pickle.load(open(\"ghostbuster/model/sigma\", \"rb\"))\n",
    "\n",
    "# Train trigram\n",
    "print(\"Loading Trigram Model...\")\n",
    "\n",
    "trigram_model = train_trigram()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ghostbuster_pred(doc: str):\n",
    "    trigram = np.array(\n",
    "        score_ngram(doc, trigram_model, enc.encode, n=3, strip_first=False)\n",
    "    )\n",
    "    unigram = np.array(\n",
    "        score_ngram(doc, trigram_model.base, enc.encode, n=1, strip_first=False)\n",
    "    )\n",
    "\n",
    "    response = client.completions.create(\n",
    "        # model=\"ada\",  # DEPRECATED, replaced by babbage-002\n",
    "        model=\"babbage-002\",\n",
    "        prompt=\"<|endoftext|>\" + doc,\n",
    "        max_tokens=0,\n",
    "        echo=True,\n",
    "        logprobs=1,\n",
    "    ).to_dict()\n",
    "    ada = np.array(\n",
    "        list(\n",
    "            map(\n",
    "                lambda x: np.exp(x),\n",
    "                response[\"choices\"][0][\"logprobs\"][\"token_logprobs\"][1:],\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    response = client.completions.create(\n",
    "        # model=\"davinci\",  # DEPRECATED, replaced by davinci-002\n",
    "        model=\"davinci-002\",\n",
    "        prompt=\"<|endoftext|>\" + doc,\n",
    "        max_tokens=0,\n",
    "        echo=True,\n",
    "        logprobs=1,\n",
    "    ).to_dict()\n",
    "    davinci = np.array(\n",
    "        list(\n",
    "            map(\n",
    "                lambda x: np.exp(x),\n",
    "                response[\"choices\"][0][\"logprobs\"][\"token_logprobs\"][1:],\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    subwords = response[\"choices\"][0][\"logprobs\"][\"tokens\"][1:]\n",
    "    gpt2_map = {\"\\n\": \"Ċ\", \"\\t\": \"ĉ\", \" \": \"Ġ\"}\n",
    "    for i in range(len(subwords)):\n",
    "        for k, v in gpt2_map.items():\n",
    "            subwords[i] = subwords[i].replace(k, v)\n",
    "\n",
    "    t_features = t_featurize_logprobs(davinci, ada, subwords)\n",
    "\n",
    "    vector_map = {\n",
    "        \"davinci-logprobs\": davinci,\n",
    "        \"ada-logprobs\": ada,\n",
    "        \"trigram-logprobs\": trigram,\n",
    "        \"unigram-logprobs\": unigram,\n",
    "    }\n",
    "\n",
    "    exp_features = []\n",
    "    for exp in best_features:\n",
    "        exp_tokens = get_words(exp)\n",
    "        curr = vector_map[exp_tokens[0]]\n",
    "\n",
    "        for i in range(1, len(exp_tokens)):\n",
    "            if exp_tokens[i] in vec_functions:\n",
    "                next_vec = vector_map[exp_tokens[i + 1]]\n",
    "                curr = vec_functions[exp_tokens[i]](curr, next_vec)\n",
    "            elif exp_tokens[i] in scalar_functions:\n",
    "                exp_features.append(scalar_functions[exp_tokens[i]](curr))\n",
    "                break\n",
    "\n",
    "    data = (np.array(t_features + exp_features) - mu) / sigma\n",
    "    preds = model.predict_proba(data.reshape(-1, 1).T)[:, 1]\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ghostbuster_pred(\"Hello, world! This is a test. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Luminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from luminar.data import (\n",
    "    PaddingDataloader,\n",
    "    n_way_split,\n",
    ")\n",
    "from luminar.model import CNNDocumentClassficationModel\n",
    "from luminar.mongo import MongoPipelineDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = {\n",
    "    \"Blog Authorship\": {\"domain\": \"blog_authorship_corpus\"},\n",
    "    \"Student Essays\": {\"domain\": \"student_essays\"},\n",
    "    \"CNN News\": {\"domain\": \"cnn_news\"},\n",
    "    \"Euro Court Cases\": {\"domain\": \"euro_court_cases\"},\n",
    "    \"House of Commons\": {\"domain\": \"house_of_commons\"},\n",
    "    \"ArXiv Papers\": {\"domain\": \"arxiv_papers\"},\n",
    "    # \"Gutenberg [EN]\": {\"domain\": \"gutenberg\", \"lang\": \"en-EN\", \"name\": \"gutenberg_en\"},\n",
    "    # \"Gutenberg [DE]\": {\"domain\": \"gutenberg\", \"lang\": \"de-DE\", \"name\": \"gutenberg_de\"},\n",
    "    \"Bundestag\": {\"domain\": \"bundestag\"},\n",
    "    \"Spiegel\": {\"domain\": \"spiegel_articles\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"eval_split\": 0.1,\n",
    "    \"test_split\": 0.2,\n",
    "    \"synth_agent\": \"gpt-4o-mini\",\n",
    "    \"document_type\": \"fulltext\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeca268a129546b8af9e90b9149b7100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Domains:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config[\"seed\"] = 42\n",
    "\n",
    "sizes = [0.1] * 10\n",
    "subsets = {}\n",
    "for domain, kwargs in tqdm(domains.items(), desc=\"Domains\", position=0):\n",
    "    domain_name = kwargs.pop(\"name\", kwargs[\"domain\"])\n",
    "    seed_everything(config[\"seed\"], verbose=False)\n",
    "    subsets[domain] = n_way_split(\n",
    "        MongoPipelineDataset(\n",
    "            mongo_db_connection=os.getenv(\"MONGO_DB_CONNECTION\"),\n",
    "            pipeline=[\n",
    "                {\n",
    "                    \"$match\": {\n",
    "                        \"type\": config[\"document_type\"],\n",
    "                        # \"type\": \"fulltext\",\n",
    "                        \"agent\": {\"$in\": [\"human\", config[\"synth_agent\"]]},\n",
    "                        # \"agent\": {\"$in\": [\"human\", \"gpt-4o-mini\"]},\n",
    "                        **kwargs,\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"$project\": {\n",
    "                        \"text\": 1,\n",
    "                        \"agent\": 1,\n",
    "                        \"label_str\": \"$label\",\n",
    "                        \"label\": {\n",
    "                            \"$cond\": {\n",
    "                                \"if\": {\"$eq\": [\"$agent\", \"human\"]},\n",
    "                                \"then\": 0,\n",
    "                                \"else\": 1,\n",
    "                            }\n",
    "                        },\n",
    "                        \"id\": {\n",
    "                            \"$cond\": {\n",
    "                                \"if\": {\"$eq\": [\"$agent\", \"human\"]},\n",
    "                                \"then\": \"$id\",\n",
    "                                \"else\": \"$source\",\n",
    "                            }\n",
    "                        },\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"$group\": {\n",
    "                        \"_id\": \"$id\",\n",
    "                        \"samples\": {\n",
    "                            \"$push\": {\n",
    "                                \"text\": \"$text\",\n",
    "                                \"agent\": \"$agent\",\n",
    "                                \"label_str\": \"$label_str\",\n",
    "                                \"label\": \"$label\",\n",
    "                            }\n",
    "                        },\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"$match\": {\n",
    "                        \"samples.1\": {\"$exists\": True},\n",
    "                    }\n",
    "                },\n",
    "            ],\n",
    "            database=\"prismai\",\n",
    "            collection=\"dataset_PrismAI\",\n",
    "            # update_cache=True,\n",
    "        ).load(verbose=False)[:1500],\n",
    "        *sizes,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '011b4eb0-2b82-441e-a0ff-1792ef9f036a',\n",
       " 'samples': [{'text': 'Bundesverkehrsminister Andreas Scheuer (CSU) tut dieser Tage so, als sei er stets der größte Freund von Nachrüstung älterer Diesel-Fahrzeugen mit Stickoxidkatalysatoren gewesen. Er habe die Vorschriften für den Umbau erlassen, die Hersteller hätten ihm zugesagt, erste Systeme im ersten Halbjahr 2019 fertigzustellen. \"Ich gehe davon aus, dass der Zeitplan von allen eingehalten wird\", sagte er kürzlich der \"Hannoverschen Allgemeinen Zeitung\" - so als könne ihm alles nicht schnell genug gehen. Dabei hatte er die Hardwarenachrüstung lange Zeit bekämpft.\\nDie Pionierarbeit erledigten andere, etwa der ADAC. Der Automobilverband begann vor einem Jahr damit, Hardwarenachrüstsets zu testen. Spezialisten fuhren Zehntausende Kilometer mit einem\\nVW T5, ausgestattet mit einem Katalysator des Herstellers Oberland-Mangold, \\neinem Opel Astra (Abgasreinigung von Twintec) \\nund einem Fiat Ducato (Katalysator von HJS). \\nDer Fiat erlitt allerdings nach rund 30.000 Kilometern einen irreparablen Unfall. Zudem untersuchte der ADAC die Autos auf dem Prüfstand.\\nAm Montag hat der ADAC die Ergebnisse vorgestellt - und die fallen gemischt aus: Zwar gehen die Stickoxidemissionen der untersuchten Fahrzeuge dank der neuen Abgasreinigung deutlich zurück. Doch das reicht vielfach nicht, um die offiziellen Grenzwerte einzuhalten. Zudem schlucken die Autos teils viel mehr Diesel.\\nInsbesondere im Winter steigt der Energiebedarf, weil die Katalysatoren auf eine Betriebstemperatur von mehr als 200 Grad aufgewärmt werden müssen. Dazu bedarf es Strom, der mit Diesel erzeugt wird. Alle getesteten Modelle verbrauchen daher mehr Sprit. \"Während das System von Oberland-Mangold im VW T5 mit einem Mehrverbrauch von 7 Prozent auskommt und nahe am zulässigen Mehrverbrauch liegt, liegen der Wert des Fiat Ducato und des Opel Astra mit 12 bis 13 Prozent deutlich darüber\", halten die ADAC-Prüfer fest.\\nGeräte lassen sich noch optimieren\\nDamit schafft keines der vom ADAC getesteten Fahrzeuge die offiziellen Vorgaben des Bundesverkehrsministeriums. Laut neu erlassener Richtlinien aus der Scheuer-Behörde dürfen umgerüstete Autos nur sechs Prozent mehr verbrauchen.\\nDen Fachleuten zufolge muss dies aber nicht bedeuten, dass Hardwarenachrüstungen generell einen hohen Mehrverbrauch bedeuten. Vielmehr seien die Anbieter noch am Anfang der Entwicklung, die Geräte ließen sich noch optimieren. Vor allem müsse das Energiemanagement verfeinert werden.\\nDer Mehrverbrauch dürfte auch bei Fahrzeugen geringer ausfallen, bei denen sich der SCR-Katalysator näher am Motor anbringen lässt. Dort heizen ihn die Abgase schneller auf. Nachrüster könnten sich zunächst auf Dieselmodelle konzentrieren, bei denen baubedingt ein kürzerer Abstand des SCR-Katalysators zum Motor möglich ist.\\nWeiterer Entwicklungsaufwand könnte sich lohnen, denn ihre eigentliche Aufgabe erfüllen die Systeme schon recht gut. Die Systeme reduzieren die Stickoxidemissionen der Untersuchung zufolge um bis zu 70 Prozent.\\n\"Die prinzipielle Leistungsfähigkeit der SCR-Katalysatoren hat auch nach 50.000 km nicht nachgelassen\", schreiben die Prüfer um ADAC-Technikchef Reinhard Kolke. Die besten Ergebnisse erzielten Fahrzeuge, die - wie der VW T5 - von den Herstellern für den Einbau eines SCR-Systems vorgerüstet worden waren - etwa für den Export in die USA.\\nAuch beim Fiat Ducato war ausreichend Platz vorhanden, der es den Nachrüstern erlaubt, SCR-Katalysator, Tank und Steuereinheit gut zu verbauen. Am kniffligsten war der Opel Astra umzurüsten: Bei ihm musste Umrüster Twintec herumtricksen, um alle Komponenten unterzubringen. Als Folge litt der Astra am häufigsten unter technischen Störungen.\\nSysteme erfüllen gesetzliche Vorgaben (noch) nicht\\nDie größte Herausforderung für die Nachrüstungshersteller war allerdings der hohe Stickoxidausstoß, den die Fahrzeuge vor dem Umbau aufwiesen. Bis zu 2000 Milligramm Stickoxide pro gefahrenem Kilometer registrierten die Sensoren, bevor die Abgase in den nachgerüsteten SCR-Kat einströmten. Der Grenzwert für Euro-5-Fahrzeuge liegt bei 180 Milligramm, gemessen nach offiziellem Verfahren auf dem Prüfstand.\\nBereits bei herbstlichen Temperaturen zwischen 5 und 13 Grad Celsius schaltete die Software die Abgasreinigung weitgehend ab. \"Die sehr hohen Serienemissionen bekommen dann selbst wirkungsvolle Nachrüstsysteme nicht mehr ausreichend in den Griff, auch wenn die Stickoxide [...] um bis zu 1400 mg/km reduziert werden können\", schreiben die ADAC-Experten.\\nSelbst eine derart hohe Reduktion reicht nicht, um die technischen Richtlinien für den nachträglichen SCR-Einbau einzuhalten. Diese erlauben maximal 270 Milligramm pro Kilometer und 540 Milligramm bei Temperaturen unter 5 Grad Celsius. Erst unterhalb dieser Werte bekommen nachgerüstete Diesel eine Genehmigung, um in Städte mit Fahrverboten für Euro-5-Diesel einzufahren.\\nADAC fordert Garantien\\nBei sommerlichen Temperaturen halten die umgerüsteten Fiat, Opel und VW die Grenzwerte mit dem nachgerüsteten Katalysator ein. Bei herbstlichen Temperaturen jedoch reißt die Reinigungsanlage der drei Autos die 270 Milligramm-Marke mitunter um das Doppelte. Im Winter liegt die zusätzliche Reinigungsleistung der Systeme zwar immer noch zwischen 38 und 53 Prozent. Doch damit verfehlen die Wagen den Winter-Grenzwert von 540 Milligramm immer noch deutlich.\\nAus Sicht der Kunden lasse der Test manche Frage offen, schlussfolgert der ADAC. \"Der Autofahrer muss sich darauf verlassen können, ein zuverlässiges und dauerhaltbares Produkt zu erwerben, das ohne Sorge vor Folgekosten die Mobilität in den kommenden Jahren sichert.\" Der Verkehrsklub fordert technische Verbesserungen und Garantien für Halter von den Nachrüstfirmen.\\nIn der Politik wird die Forderung lauter, den Unternehmen dabei zu helfen. Die Bunderegierung solle ihnen finanziell entgegenkommen, schlägt die SPD vor. Für die Nachrüster sei es nicht einfach, Kredite zu bekommen. Zu unsicher scheint den Geldhäusern der künftige Markt, der stark davon abhängt, in wie vielen Städten es am Ende Fahrverbote geben wird.',\n",
       "   'agent': 'human',\n",
       "   'label_str': 'human',\n",
       "   'label': 0},\n",
       "  {'text': 'Die Diskussion um die Nachrüstung älterer Diesel-Fahrzeuge in Deutschland hat in den letzten Jahren zunehmend an Bedeutung gewonnen. Angesichts der strengen Umweltauflagen und der öffentlichen Besorgnis über die Luftqualität hat die Bundesregierung Maßnahmen ergriffen, um die Emissionen von Stickoxiden (NOx) zu reduzieren. Ein zentrales Element dieser Strategie ist die Nachrüstung von Diesel-Fahrzeugen mit Katalysatoren zur Reduzierung von Stickoxiden. Doch wie effektiv sind diese Maßnahmen wirklich, und welche Herausforderungen bestehen bei der Umsetzung?\\n\\nZunächst einmal ist es wichtig, die regulatorischen Rahmenbedingungen zu betrachten, die diese Nachrüstungen ermöglichen. Im Jahr 2017 wurde das sogenannte \"Diesel-Gipfel\" ins Leben gerufen, bei dem die Bundesregierung, Automobilhersteller und Städte zusammenkamen, um Lösungen zur Reduzierung von Diesel-Emissionen zu finden. Ein Ergebnis dieser Gespräche war die Förderung von Nachrüstungen für ältere Diesel-Fahrzeuge, die nicht die neuesten Abgasnormen erfüllen. Die Bundesregierung stellte Fördermittel zur Verfügung, um die finanziellen Belastungen für Fahrzeughalter zu minimieren. Allerdings bleibt die Frage, ob diese finanziellen Anreize ausreichen, um eine breite Akzeptanz der Nachrüstungen zu erreichen.\\n\\nTechnisch gesehen sind die Nachrüstungen mit NOx-Katalysatoren durchaus vielversprechend. Experten berichten von signifikanten Emissionsreduktionen, die durch den Einbau dieser Systeme erzielt werden können. Eine Studie des Deutschen Instituts für Normung (DIN) zeigt, dass bei korrekt nachgerüsteten Fahrzeugen die NOx-Emissionen um bis zu 80 Prozent gesenkt werden können. Diese Zahlen sind ermutigend, doch die Realität sieht oft anders aus. Viele Fahrzeughalter sind skeptisch gegenüber der Effektivität der Nachrüstungen, da sie sich über die tatsächlichen Kosten und den Aufwand der Installation informieren müssen. Zudem gibt es Bedenken hinsichtlich der langfristigen Zuverlässigkeit der nachgerüsteten Systeme.\\n\\nEin weiteres Problem ist die Verfügbarkeit geeigneter Nachrüstlösungen. Nicht alle Diesel-Fahrzeuge sind für eine Nachrüstung geeignet, und die Hersteller müssen spezifische Lösungen für verschiedene Modelle entwickeln. Dies führt zu einer Fragmentierung des Marktes und kann dazu führen, dass einige Fahrzeughalter keine adäquate Lösung finden. Darüber hinaus ist die technische Komplexität der Nachrüstungen nicht zu unterschätzen. Viele Werkstätten sind nicht ausreichend geschult, um diese Systeme fachgerecht zu installieren, was das Risiko von Fehlinstallationen erhöht und die Effektivität der Nachrüstungen beeinträchtigen kann.\\n\\nDie Umweltwirkungen der Nachrüstungen sind ebenfalls ein kritischer Punkt. Während die Reduzierung von NOx-Emissionen von großer Bedeutung ist, muss auch die gesamte Umweltbilanz der Fahrzeuge betrachtet werden. Einige Experten warnen davor, dass die Nachrüstung von Diesel-Fahrzeugen lediglich ein kurzfristiger Lösungsansatz ist, der die grundlegenden Probleme der Luftverschmutzung nicht adressiert. Die Förderung von Elektrofahrzeugen und anderen umweltfreundlicheren Alternativen wird oft als nachhaltigere Lösung angesehen. Der deutsche Minister für Verkehr, Volker Wissing, hat in der Vergangenheit betont, dass die Nachrüstung ein Teil eines umfassenderen Plans zur Verbesserung der Luftqualität sein muss. Kritiker argumentieren jedoch, dass diese Maßnahmen nicht ausreichen, um die dringend benötigten Fortschritte zu erzielen.\\n\\nEin weiterer Aspekt, der nicht außer Acht gelassen werden sollte, ist die soziale Dimension der Nachrüstungen. Viele Fahrzeughalter sind finanziell nicht in der Lage, die Kosten für die Nachrüstung zu tragen, selbst mit staatlicher Förderung. Dies führt zu einer Ungleichheit, bei der vor allem einkommensschwächere Haushalte von den Maßnahmen ausgeschlossen werden. Der Minister hat angekündigt, dass weitere Unterstützungsmaßnahmen geprüft werden, doch die Umsetzung bleibt ungewiss.\\n\\nZusammenfassend lässt sich sagen, dass die Nachrüstung älterer Diesel-Fahrzeuge in Deutschland sowohl Chancen als auch Herausforderungen mit sich bringt. Während die technischen Möglichkeiten zur Reduzierung von NOx-Emissionen vorhanden sind, stehen die Maßnahmen unter dem Druck der öffentlichen Meinung und der politischen Rahmenbedingungen. Die Bundesregierung muss sicherstellen, dass die Nachrüstungen nicht nur technisch machbar, sondern auch sozial gerecht und ökologisch sinnvoll sind. Nur so kann ein nachhaltiger Beitrag zur Verbesserung der Luftqualität in deutschen Städten geleistet werden. Es bleibt abzuwarten, wie sich die Situation entwickeln wird und ob die gesetzten Ziele erreicht werden können.',\n",
       "   'agent': 'gpt-4o-mini',\n",
       "   'label_str': 'ai',\n",
       "   'label': 1}]}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsets[domain][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {}\n",
    "\n",
    "for domain, subset in tqdm(subsets.items(), desc=\"Subsets\", position=0):\n",
    "    splits[domain] = [\n",
    "        [\n",
    "            {\n",
    "                # Actually just the truncated text\n",
    "                \"features\": enc.decode(\n",
    "                    enc.encode(sample[\"text\"].replace(\"<|endoftext|>\", \"\"))[:MAX_TOKENS]\n",
    "                ).strip(),\n",
    "                \"label\": sample[\"label\"],\n",
    "            }\n",
    "            for doc in tqdm(split, desc=\"Samples\", position=2, leave=False)\n",
    "            for sample in doc[\"samples\"]\n",
    "        ]\n",
    "        for split in tqdm(subset, desc=\"Splits\", position=1, leave=False)\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features': 'Bundesverkehrsminister Andreas Scheuer (CSU) tut dieser Tage so, als sei er stets der größte Freund von Nachrüstung älterer Diesel-Fahrzeugen mit Stickoxidkatalysatoren gewesen. Er habe die Vorschriften für den Umbau erlassen, die Hersteller hätten ihm zugesagt, erste Systeme im ersten Halbjahr 2019 fertigzustellen. \"Ich gehe davon aus, dass der Zeitplan von allen eingehalten wird\", sagte er kürzlich der \"Hannoverschen Allgemeinen Zeitung\" - so als könne ihm alles nicht schnell genug gehen. Dabei hatte er die Hardwarenachrüstung lange Zeit bekämpft.\\nDie Pionierarbeit erledigten andere, etwa der ADAC. Der Automobilverband begann vor einem Jahr damit, Hardwarenachrüstsets zu testen. Spezialisten fuhren Zehntausende Kilometer mit einem\\nVW T5, ausgestattet mit einem Katalysator des Herstellers Oberland-Mangold, \\neinem Opel Astra (Abgasreinigung von Twintec) \\nund einem Fiat Ducato (Katalysator von HJS). \\nDer Fiat erlitt allerdings nach rund 30.000 Kilometern einen irreparablen Unfall. Zudem untersuchte der ADAC die Autos auf dem Prüfstand.\\nAm Montag hat der ADAC die Ergebnisse vorgestellt - und die fallen gemischt aus: Zwar gehen die Stickoxidemissionen der untersuchten Fahrzeuge dank der neuen Abgasreinigung deutlich zurück. Doch das reicht vielfach nicht, um die offiziellen Grenzwerte einzuhalten. Zudem schlucken die Autos teils viel mehr Diesel.\\nInsbesondere im Winter steigt der Energiebedarf, weil die Katalysatoren auf eine Betriebstemperatur von mehr als 200 Grad aufgewärmt werden müssen. Dazu bedarf es Strom, der mit Diesel erzeugt wird. Alle getesteten Modelle verbrauchen daher mehr Sprit. \"Während das System von Oberland-Mangold im VW T5 mit einem Mehrverbrauch von 7 Prozent auskommt und nahe am zulässigen Mehrverbrauch liegt, liegen der Wert des Fiat Ducato und des Opel Astra mit 12 bis 13 Prozent deutlich darüber\", halten die ADAC-Prüfer fest.\\nGeräte lassen sich noch optimieren\\nDamit schafft keines der vom ADAC getesteten Fahrzeuge die offiziellen Vorgaben des Bundesverkehrsministeriums. Laut neu erlassener Richtlinien aus der Scheuer-Behörde dürfen umgerüstete Autos nur sechs Prozent mehr verbrauchen.\\nDen Fachleuten zufolge muss dies aber nicht bedeuten, dass Hardwarenachrüstungen generell einen hohen Mehrverbrauch bedeuten. Vielmehr seien die Anbieter noch am Anfang der Entwicklung, die Geräte ließen sich noch optimieren. Vor allem müsse das Energiemanagement verfeinert werden.\\nDer Mehrverbrauch dürfte auch bei Fahrzeugen geringer ausfallen, bei denen sich der SCR-Katalysator näher am Motor anbringen lässt. Dort heizen ihn die Abgase schneller auf. Nachrüster könnten sich zunächst auf Dieselmodelle konzentrieren, bei denen baubedingt ein kürzerer Abstand des SCR-Katalysators zum Motor möglich ist.\\nWeiterer Entwicklungsaufwand könnte sich lohnen, denn ihre eigentliche Aufgabe erfüllen die Systeme schon recht gut. Die Systeme reduzieren die Stickoxidemissionen der Untersuchung zufolge um bis zu 70 Prozent.\\n\"Die prinzipielle Leistungsfähigkeit der SCR-Katalysatoren hat auch nach 50.000 km nicht nachgelassen\", schreiben die Prüfer um ADAC-Technikchef Reinhard Kolke. Die besten Ergebnisse erzielten Fahrzeuge, die - wie der VW T5 - von den Herstellern für den Einbau eines SCR-Systems vorgerüstet worden waren - etwa für den Export in die USA.\\nAuch beim Fiat Ducato war ausreichend Platz vorhanden, der es den Nachrüstern erlaubt, SCR-Katalysator, Tank und Steuereinheit gut zu verbauen. Am kniffligsten war der Opel Astra umzurüsten: Bei ihm musste Umrüster Twintec herumtricksen, um alle Komponenten unterzubringen. Als Folge litt der Astra am häufigsten unter technischen Störungen.\\nSysteme erfüllen gesetzliche Vorgaben (noch) nicht\\nDie größte Herausforderung für die Nachrüstungshersteller war allerdings der hohe Stickoxidausstoß, den die Fahrzeuge vor dem Umbau aufwiesen. Bis zu 2000 Milligramm Stickoxide pro gefahrenem Kilometer registrierten die Sensoren, bevor die Abgase in den nachgerüsteten SCR-Kat einströmten. Der Grenzwert für Euro-5-Fahrzeuge liegt bei 180 Milligramm, gemessen nach offiziellem Verfahren auf dem Prüfstand.\\nBereits bei herbstlichen Temperaturen zwischen 5 und 13 Grad Celsius schaltete die Software die Abgasreinigung weitgehend ab. \"Die sehr hohen Serienemissionen bekommen dann selbst wirkungsvolle Nachrüstsysteme nicht mehr ausreichend in den Griff, auch wenn die Stickoxide [...] um bis zu 1400 mg/km reduziert werden können\", schreiben die ADAC-Experten.\\nSelbst eine derart hohe Reduktion reicht nicht, um die technischen Richtlinien für den nachträglichen SCR-Einbau einzuhalten. Diese erlauben maximal 270 Milligramm pro Kilometer und 540 Milligramm bei Temperaturen unter 5 Grad Celsius. Erst unterhalb dieser Werte bekommen nachgerüstete Diesel eine Genehmigung, um in Städte mit Fahrverboten für Euro-5-Diesel einzufahren.\\nADAC fordert Garantien\\nBei sommerlichen Temperaturen halten die umgerüsteten Fiat, Opel und VW die Grenzwerte mit dem nachgerüsteten Katalysator ein. Bei herbstlichen Temperaturen jedoch reißt die Reinigungsanlage der drei Autos die 270 Milligramm-Marke mitunter um das Doppelte. Im Winter liegt die zusätzliche Reinigungsleistung der Systeme zwar immer noch zwischen 38 und 53 Prozent. Doch damit verfehlen die Wagen den Winter-Grenzwert von 540 Milligramm immer noch deutlich.\\nAus Sicht der Kunden lasse der Test manche Frage offen, schlussfolgert der ADAC. \"Der Autofahrer muss sich darauf verlassen können, ein zuverlässiges und dauerhaltbares Produkt zu erwerben, das ohne Sorge vor Folgekosten die Mobilität in den kommenden Jahren sichert.\" Der Verkehrsklub fordert technische Verbesserungen und Garantien für Halter von den Nachrüstfirmen.\\nIn der Politik wird die Forderung lauter, den Unternehmen dabei zu helfen. Die Bunderegierung solle ihnen finanziell entgegenkommen, schlägt die SPD vor. Für die Nachrüster sei es nicht einfach, Kredite zu bekommen. Zu unsicher scheint den Geldhäusern der künftige Markt, der stark davon abhängt, in wie vielen Städten es am Ende Fahrverbote geben wird.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[domain][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4fd034727143ae9492e95597e7d33f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "24000"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len(samples) for split in tqdm(splits.values()) for samples in split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333911ad230940d9bee64716751c38af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "21009717"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tokens = sum(\n",
    "    sum(\n",
    "        sum(\n",
    "            1 + len(enc.encode(sample[\"features\"]))\n",
    "            for sample in samples  #\n",
    "        )\n",
    "        for samples in split\n",
    "    )\n",
    "    for split in tqdm(splits.values())\n",
    ")\n",
    "n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.42332079999999"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tokens / 1_000_000 * 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c26c781d3cf4806a0d1458c03a528c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1482474"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tokens_sub = sum(\n",
    "    sum(\n",
    "        sum(\n",
    "            1 + len(enc.encode(sample[\"features\"])[:MAX_TOKENS])\n",
    "            for sample in samples[2700:3000]  #\n",
    "        )\n",
    "        for samples in split\n",
    "    )\n",
    "    for split in tqdm(splits.values())\n",
    ")\n",
    "n_tokens_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5579376000000003"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tokens_sub / 1_000_000 * 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95455812])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ghostbuster_pred(splits[domain][0][0][\"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config |= {\n",
    "    \"projection_dim\": 32,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"warmup_steps\": 66,\n",
    "    \"max_epochs\": 25,\n",
    "    \"gradient_clip_val\": 1.0,\n",
    "    \"batch_size\": 32,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "\n",
    "# capturing config from \"closure\"\n",
    "def get_dataloader(*dataset, **kwargs) -> PaddingDataloader:\n",
    "    if len(dataset) == 1:\n",
    "        dataset = dataset[0]\n",
    "    else:\n",
    "        dataset = ConcatDataset(dataset)\n",
    "    return PaddingDataloader(\n",
    "        dataset,\n",
    "        feature_dim=config[\"feature_dim\"],\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        **kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-Domain Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028da2f2b0474c0eacb0b0598cef6d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6501c7730fe4ff5b8c0ad5d125825fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Blog Authorship:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3dbe4e2b27c4d1abae297c78f528147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Student Essays:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbfebd657a4a4cefa7e205f9b2f6c4d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CNN News:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341d130ca5c0478686a53da858f7ec9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Euro Court Cases:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02769155369546f0907cb2b808eac72e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "House of Commons:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bcd297ba325466dbfeb7687f54af3df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ArXiv Papers:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7198fe3bbc784d8f8edad814d424ef14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Gutenberg:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c2402572cfb40c7a50b5046a2e6bbb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Bundestag:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f39194654543a2b20b579a9c5b258d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Spiegel:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | In sizes    | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | conv_layers | Sequential        | 152 K  | train | ?           | ?        \n",
      "1 | projection  | Sequential        | 524 K  | train | [32, 16384] | [32, 32] \n",
      "2 | classifier  | Linear            | 33     | train | [32, 32]    | [32, 1]  \n",
      "3 | criterion   | BCEWithLogitsLoss | 0      | train | ?           | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "676 K     Trainable params\n",
      "0         Non-trainable params\n",
      "676 K     Total params\n",
      "2.706     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "metrics_in_domain = defaultdict(list)\n",
    "for domain, subsets in tqdm(splits.items()):\n",
    "    for _ in trange(5, desc=domain, position=1):\n",
    "        seed_everything(config[\"seed\"], verbose=False)\n",
    "        # cycle through splits for cross-validation\n",
    "        eval_dataset = subsets.pop(0)\n",
    "        test_dataloader = get_dataloader(*subsets[:2])\n",
    "        train_dataloader = get_dataloader(*subsets[2:], shuffle=True)\n",
    "        eval_dataloader = get_dataloader(eval_dataset)\n",
    "        subsets.append(eval_dataset)\n",
    "\n",
    "        model = CNNDocumentClassficationModel(**config)\n",
    "        trainer = Trainer(\n",
    "            max_epochs=config[\"max_epochs\"],\n",
    "            logger=pl_loggers.TensorBoardLogger(\n",
    "                save_dir=f\"logs/in_domain/{type(featurizer).__name__}\",\n",
    "                name=domain,\n",
    "            ),\n",
    "            gradient_clip_val=config[\"gradient_clip_val\"],\n",
    "            callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=3)],\n",
    "            deterministic=True,\n",
    "        )\n",
    "        trainer.progress_bar_callback.disable()\n",
    "\n",
    "        trainer.fit(\n",
    "            model,\n",
    "            train_dataloaders=train_dataloader,\n",
    "            val_dataloaders=eval_dataloader,\n",
    "        )\n",
    "        (metrics,) = trainer.test(model, test_dataloader, verbose=False)\n",
    "        metrics_in_domain[domain].append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_split': 0.1,\n",
       " 'test_split': 0.2,\n",
       " 'feature_model': 'gpt2',\n",
       " 'synth_agent': 'gpt-4o-mini',\n",
       " 'document_type': 'fulltext',\n",
       " 'second_dim_as_channels': True,\n",
       " 'feature_dim': TwoDimFeatures(width=256, height=13),\n",
       " 'featurizer': 'IntermediateLikelihood(last_n=13)',\n",
       " 'slicer': 'SliceRandomMultiple(size=64, multiple=4, stride=16, sort=False)',\n",
       " 'num_samples': 1,\n",
       " 'seed': 42,\n",
       " 'projection_dim': 32,\n",
       " 'learning_rate': 0.0001,\n",
       " 'warmup_steps': 66,\n",
       " 'max_epochs': 25,\n",
       " 'gradient_clip_val': 1.0,\n",
       " 'batch_size': 32,\n",
       " 'conv_layer_shapes': [(64, 5, 1),\n",
       "  (128, 3, 1),\n",
       "  (128, 3, 1),\n",
       "  (128, 3, 1),\n",
       "  (64, 3, 1)]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rr}\n",
      "\\toprule\n",
      "test_auroc & test_f1@0.5 \\\\\n",
      "\\midrule\n",
      "0.982 & 0.906 \\\\\n",
      "0.976 & 0.912 \\\\\n",
      "0.972 & 0.916 \\\\\n",
      "0.990 & 0.937 \\\\\n",
      "0.976 & 0.914 \\\\\n",
      "0.987 & 0.925 \\\\\n",
      "0.964 & 0.883 \\\\\n",
      "0.943 & 0.865 \\\\\n",
      "0.928 & 0.855 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "domain",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "test_auroc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_f1@0.5",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "909c0e5e-a26a-4ea7-90f9-85b4869b14d7",
       "rows": [
        [
         "Blog Authorship",
         "0.9821679949760437",
         "0.9056885123252869"
        ],
        [
         "Student Essays",
         "0.9755688905715942",
         "0.9121661305427551"
        ],
        [
         "CNN News",
         "0.9722288846969604",
         "0.9157830595970153"
        ],
        [
         "Euro Court Cases",
         "0.9898062467575073",
         "0.9369313478469848"
        ],
        [
         "House of Commons",
         "0.9759865641593933",
         "0.914005982875824"
        ],
        [
         "ArXiv Papers",
         "0.9868142485618592",
         "0.9249056816101074"
        ],
        [
         "Gutenberg",
         "0.9635680794715882",
         "0.8833729505538941"
        ],
        [
         "Bundestag",
         "0.9430484056472779",
         "0.8653730511665344"
        ],
        [
         "Spiegel",
         "0.9283736824989319",
         "0.8549659729003907"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 9
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_auroc</th>\n",
       "      <th>test_f1@0.5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>domain</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Blog Authorship</th>\n",
       "      <td>0.982168</td>\n",
       "      <td>0.905689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student Essays</th>\n",
       "      <td>0.975569</td>\n",
       "      <td>0.912166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN News</th>\n",
       "      <td>0.972229</td>\n",
       "      <td>0.915783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Euro Court Cases</th>\n",
       "      <td>0.989806</td>\n",
       "      <td>0.936931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>House of Commons</th>\n",
       "      <td>0.975987</td>\n",
       "      <td>0.914006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ArXiv Papers</th>\n",
       "      <td>0.986814</td>\n",
       "      <td>0.924906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gutenberg</th>\n",
       "      <td>0.963568</td>\n",
       "      <td>0.883373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bundestag</th>\n",
       "      <td>0.943048</td>\n",
       "      <td>0.865373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spiegel</th>\n",
       "      <td>0.928374</td>\n",
       "      <td>0.854966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  test_auroc  test_f1@0.5\n",
       "domain                                   \n",
       "Blog Authorship     0.982168     0.905689\n",
       "Student Essays      0.975569     0.912166\n",
       "CNN News            0.972229     0.915783\n",
       "Euro Court Cases    0.989806     0.936931\n",
       "House of Commons    0.975987     0.914006\n",
       "ArXiv Papers        0.986814     0.924906\n",
       "Gutenberg           0.963568     0.883373\n",
       "Bundestag           0.943048     0.865373\n",
       "Spiegel             0.928374     0.854966"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"domain\": domain,\n",
    "            **{\n",
    "                \"test_auroc\": metric[\"test_auroc\"],\n",
    "                \"test_f1@0.5\": metric[\"test_f1@0.5\"],\n",
    "            },\n",
    "        }\n",
    "        for domain in domains\n",
    "        for metric in metrics_in_domain[domain]\n",
    "    ]\n",
    ")\n",
    "df = (\n",
    "    df.groupby(\"domain\")\n",
    "    .mean()\n",
    "    .sort_index(key=lambda i: list(map(list(domains.keys()).index, i)))\n",
    ")\n",
    "print(\n",
    "    df.to_latex(\n",
    "        float_format=\"%.3f\",\n",
    "        index=False,\n",
    "    )\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "metrics_out_of_domain = defaultdict(list)\n",
    "for domain in tqdm(splits.keys()):\n",
    "    for _ in trange(5, desc=domain, position=1):\n",
    "        seed_everything(config[\"seed\"], verbose=False)\n",
    "        train_subsets = []\n",
    "        eval_subsets = []\n",
    "        for other, subsets in splits.items():\n",
    "            if other == domain:\n",
    "                subsets.append(subsets.pop(0))\n",
    "                test_dataset = subsets[:2]\n",
    "            else:\n",
    "                eval_dataset = subsets.pop(0)\n",
    "                eval_subsets.append(eval_dataset)\n",
    "                train_subsets.extend(subsets[2:])\n",
    "                subsets.append(eval_dataset)\n",
    "\n",
    "        train_dataloader = get_dataloader(*train_subsets, shuffle=True)\n",
    "        eval_dataloader = get_dataloader(*eval_subsets)\n",
    "        test_dataloader = get_dataloader(*test_dataset)\n",
    "\n",
    "        model = CNNDocumentClassficationModel(**config)\n",
    "        trainer = Trainer(\n",
    "            max_epochs=config[\"max_epochs\"],\n",
    "            logger=pl_loggers.TensorBoardLogger(\n",
    "                save_dir=f\"logs/in_domain/{type(featurizer).__name__}\",\n",
    "                name=domain,\n",
    "            ),\n",
    "            gradient_clip_val=config[\"gradient_clip_val\"],\n",
    "            callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=3)],\n",
    "            deterministic=True,\n",
    "        )\n",
    "        trainer.progress_bar_callback.disable()\n",
    "\n",
    "        trainer.fit(\n",
    "            model,\n",
    "            train_dataloaders=train_dataloader,\n",
    "            val_dataloaders=eval_dataloader,\n",
    "        )\n",
    "        (metrics,) = trainer.test(model, test_dataloader, verbose=False)\n",
    "        metrics_out_of_domain[domain].append(metrics)\n",
    "\n",
    "        print(domain, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rr}\n",
      "\\toprule\n",
      "test_auroc & test_f1@0.5 \\\\\n",
      "\\midrule\n",
      "0.529 & 0.564 \\\\\n",
      "0.750 & 0.730 \\\\\n",
      "0.974 & 0.905 \\\\\n",
      "0.941 & 0.846 \\\\\n",
      "0.961 & 0.924 \\\\\n",
      "0.985 & 0.941 \\\\\n",
      "0.958 & 0.881 \\\\\n",
      "0.769 & 0.715 \\\\\n",
      "0.819 & 0.718 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "domain",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "test_auroc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_f1@0.5",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "cb60d593-e0e5-466d-a8fe-15b3ad645729",
       "rows": [
        [
         "Blog Authorship",
         "0.5287861883640289",
         "0.5642710506916047"
        ],
        [
         "Student Essays",
         "0.7496144413948059",
         "0.72968829870224"
        ],
        [
         "CNN News",
         "0.9735177636146546",
         "0.9052268981933593"
        ],
        [
         "Euro Court Cases",
         "0.9414797902107239",
         "0.8456860542297363"
        ],
        [
         "House of Commons",
         "0.9612245321273803",
         "0.9238682508468627"
        ],
        [
         "ArXiv Papers",
         "0.9852698922157288",
         "0.9405964970588684"
        ],
        [
         "Gutenberg",
         "0.958419394493103",
         "0.8809419870376587"
        ],
        [
         "Bundestag",
         "0.7688287258148193",
         "0.7152183294296265"
        ],
        [
         "Spiegel",
         "0.8187309384346009",
         "0.7182690143585205"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 9
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_auroc</th>\n",
       "      <th>test_f1@0.5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>domain</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Blog Authorship</th>\n",
       "      <td>0.528786</td>\n",
       "      <td>0.564271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student Essays</th>\n",
       "      <td>0.749614</td>\n",
       "      <td>0.729688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN News</th>\n",
       "      <td>0.973518</td>\n",
       "      <td>0.905227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Euro Court Cases</th>\n",
       "      <td>0.941480</td>\n",
       "      <td>0.845686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>House of Commons</th>\n",
       "      <td>0.961225</td>\n",
       "      <td>0.923868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ArXiv Papers</th>\n",
       "      <td>0.985270</td>\n",
       "      <td>0.940596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gutenberg</th>\n",
       "      <td>0.958419</td>\n",
       "      <td>0.880942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bundestag</th>\n",
       "      <td>0.768829</td>\n",
       "      <td>0.715218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spiegel</th>\n",
       "      <td>0.818731</td>\n",
       "      <td>0.718269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  test_auroc  test_f1@0.5\n",
       "domain                                   \n",
       "Blog Authorship     0.528786     0.564271\n",
       "Student Essays      0.749614     0.729688\n",
       "CNN News            0.973518     0.905227\n",
       "Euro Court Cases    0.941480     0.845686\n",
       "House of Commons    0.961225     0.923868\n",
       "ArXiv Papers        0.985270     0.940596\n",
       "Gutenberg           0.958419     0.880942\n",
       "Bundestag           0.768829     0.715218\n",
       "Spiegel             0.818731     0.718269"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"domain\": domain,\n",
    "            **{\n",
    "                \"test_auroc\": metric[\"test_auroc\"],\n",
    "                \"test_f1@0.5\": metric[\"test_f1@0.5\"],\n",
    "            },\n",
    "        }\n",
    "        for domain in domains\n",
    "        for metric in metrics_out_of_domain[domain]\n",
    "    ]\n",
    ")\n",
    "df = (\n",
    "    df.groupby(\"domain\")\n",
    "    .mean()\n",
    "    .sort_index(key=lambda i: list(map(list(domains.keys()).index, i)))\n",
    ")\n",
    "print(\n",
    "    df.to_latex(\n",
    "        float_format=\"%.3f\",\n",
    "        index=False,\n",
    "    )\n",
    ")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
