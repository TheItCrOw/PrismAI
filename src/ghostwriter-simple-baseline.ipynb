{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3c0300d",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "Simple baselines for GhostWriter dataset (e.g. linear regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "2a8cb4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "84320c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages (3.0.5)\n",
      "Requirement already satisfied: lightgbm in /home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages (4.6.0)\n",
      "Collecting tabulate\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: numpy in /home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages (from xgboost) (2.2.6)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages (from xgboost) (2.26.2)\n",
      "Requirement already satisfied: scipy in /home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages (from xgboost) (1.16.0)\n",
      "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost lightgbm tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "50487020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, math, string, numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from IPython.display import display, Markdown\n",
    "from datasets import DatasetDict, load_dataset\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "rng = check_random_state(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "dad88cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "_punct_tbl = str.maketrans(\"\", \"\", \"\")\n",
    "punct_set = set(string.punctuation)\n",
    "url_pat = re.compile(r\"(https?://\\S+|www\\.\\S+)\", re.IGNORECASE)\n",
    "sent_pat = re.compile(r\"[.!?]\")\n",
    "nonspace_pat = re.compile(r\"\\S\")\n",
    "alnum_pat = re.compile(r\"[A-Za-z0-9]\")\n",
    "\n",
    "def safe_div(a, b):\n",
    "    return a / b if b else 0.0\n",
    "\n",
    "def tokenize_whitespace_strip_punct(text):\n",
    "    toks = []\n",
    "    for tok in text.split():\n",
    "        # strip leading/trailing punctuation\n",
    "        tok = tok.strip(string.punctuation)\n",
    "        if tok and alnum_pat.search(tok):\n",
    "            toks.append(tok)\n",
    "    return toks\n",
    "\n",
    "def extract_metrics_batch(batch):\n",
    "    texts = batch[\"text\"]\n",
    "    out = {\n",
    "        \"n_chars\": [],\n",
    "        \"n_chars_nospace\": [],\n",
    "        \"n_words\": [],\n",
    "        \"avg_word_len\": [],\n",
    "        \"n_sents\": [],\n",
    "        \"n_punct\": [],\n",
    "        \"punct_ratio\": [],\n",
    "        \"upper_ratio\": [],\n",
    "        \"digit_ratio\": [],\n",
    "        \"url_count\": [],\n",
    "        \"type_token_ratio\": [],\n",
    "        \"hapax_ratio\": [],\n",
    "    }\n",
    "    for t in texts:\n",
    "        t = t if isinstance(t, str) else \"\"\n",
    "        n_chars = len(t)\n",
    "        n_chars_nospace = len(re.findall(r\"\\S\", t))\n",
    "        n_punct = sum(1 for ch in t if (not ch.isalnum()) and (not ch.isspace()))\n",
    "        n_upper = sum(1 for ch in t if ch.isupper())\n",
    "        n_digit = sum(1 for ch in t if ch.isdigit())\n",
    "        url_count = len(url_pat.findall(t))\n",
    "\n",
    "        # sentence count (min 1 for non-empty text)\n",
    "        sent_splits = [s for s in sent_pat.split(t) if s.strip()]\n",
    "        n_sents = max(1, len(sent_splits)) if t.strip() else 0\n",
    "\n",
    "        toks = tokenize_whitespace_strip_punct(t)\n",
    "        n_words = len(toks)\n",
    "        avg_word_len = safe_div(sum(len(w) for w in toks), n_words)\n",
    "\n",
    "        # lexical diversity\n",
    "        toks_lower = [w.lower() for w in toks]\n",
    "        vocab = set(toks_lower)\n",
    "        type_token_ratio = safe_div(len(vocab), n_words)\n",
    "\n",
    "        # hapax legomena ratio\n",
    "        from collections import Counter\n",
    "        cnt = Counter(toks_lower)\n",
    "        hapax_ratio = safe_div(sum(1 for w, c in cnt.items() if c == 1), n_words)\n",
    "\n",
    "        punct_ratio = safe_div(n_punct, n_chars_nospace)\n",
    "        upper_ratio = safe_div(n_upper, n_chars_nospace)\n",
    "        digit_ratio = safe_div(n_digit, n_chars_nospace)\n",
    "\n",
    "        out[\"n_chars\"].append(n_chars)\n",
    "        out[\"n_chars_nospace\"].append(n_chars_nospace)\n",
    "        out[\"n_words\"].append(n_words)\n",
    "        out[\"avg_word_len\"].append(avg_word_len)\n",
    "        out[\"n_sents\"].append(n_sents)\n",
    "        out[\"n_punct\"].append(n_punct)\n",
    "        out[\"punct_ratio\"].append(punct_ratio)\n",
    "        out[\"upper_ratio\"].append(upper_ratio)\n",
    "        out[\"digit_ratio\"].append(digit_ratio)\n",
    "        out[\"url_count\"].append(url_count)\n",
    "        out[\"type_token_ratio\"].append(type_token_ratio)\n",
    "        out[\"hapax_ratio\"].append(hapax_ratio)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "01f81aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "    \"n_chars\",\"n_chars_nospace\",\"n_words\",\"avg_word_len\",\"n_sents\",\"n_punct\",\n",
    "    \"punct_ratio\",\"upper_ratio\",\"digit_ratio\",\"url_count\",\"type_token_ratio\",\"hapax_ratio\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abea4fc0",
   "metadata": {},
   "source": [
    "## Dataset & Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "859a167f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d326e1085aa84b6dbdcb11e1423e036b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/846 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352d13c93958490cbc01b91517eaf7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00005.parquet:   0%|          | 0.00/272M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e857d67bf9124b91a4b622b3a6be18aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00001-of-00005.parquet:   0%|          | 0.00/271M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac0aebeb0094d84947ce16035da9f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00002-of-00005.parquet:   0%|          | 0.00/273M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b0c0ffa8c34e358cebcd421f57d15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00003-of-00005.parquet:   0%|          | 0.00/270M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb272ddf3da4ce4877d9b9820cd8f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00004-of-00005.parquet:   0%|          | 0.00/274M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f4e6358722149169837301a1e059e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/eval-00000-of-00001.parquet:   0%|          | 0.00/193M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72e58186e5e40ee8d8a03d769d9921d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00002.parquet:   0%|          | 0.00/197M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb06b877791a470bb305a6264eb22599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00001-of-00002.parquet:   0%|          | 0.00/195M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add5cc97cb894171a41d207dc8128b5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/382535 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc0c9b8b50c54f0b8d20af9f9bc76179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating eval split:   0%|          | 0/54648 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540b73bde4304b19a6965495c2d0bde1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/109296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"TheItCrOw/GhostWriter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "1198afc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text', 'domain', 'date', 'source', 'lang', 'label', 'agent', 'type'],\n",
       "        num_rows: 382535\n",
       "    })\n",
       "    eval: Dataset({\n",
       "        features: ['id', 'text', 'domain', 'date', 'source', 'lang', 'label', 'agent', 'type'],\n",
       "        num_rows: 54648\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'text', 'domain', 'date', 'source', 'lang', 'label', 'agent', 'type'],\n",
       "        num_rows: 109296\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2f2f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae1491efca44e748478a3de48320288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/382535 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc429c09f234873ac9a826779b953de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/54648 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87112bbd35c3491aa13fbff38d37f479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/109296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a7dfa9c93e43de94c97fc23be7bf11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/382520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52bcb767bed465c8198c9f433de8374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/54647 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81894b6ba2340e1a7e9016e7fdff665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/109292 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove empty texts\n",
    "dataset01 = DatasetDict({\n",
    "    split: ds.filter(lambda ex: isinstance(ex[\"text\"], str) and ex[\"text\"].strip() != \"\")\n",
    "    for split, ds in dataset.items()\n",
    "})\n",
    "\n",
    "def clean(batch):\n",
    "    cleaned = []\n",
    "    for t in batch[\"text\"]:\n",
    "        # Collapse multiple spaces and trim\n",
    "        t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "        cleaned.append(t)\n",
    "    return {\"text\": cleaned}\n",
    "\n",
    "dataset01 = DatasetDict({\n",
    "    split: ds.map(clean, batched=True, num_proc=32)\n",
    "    for split, ds in dataset01.items()\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ab8d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b82bf51ef84a11a63f120b148997b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/382520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d0883ba10641d2a1aab513a77ca0ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/54647 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0368baf80df40b5a90e7e22e042e2ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/109292 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': '41a1cb62-9edd-4aa2-8083-e26165fcc9c2',\n",
       " 'text': 'In today’s world, technology has woven itself into the very fabric of our daily lives, and its impact on understanding human emotions is both fascinating and concerning. As someone who has grown up with smartphones and social media, I can’t help but wonder how this tech shapes our ability to recognize genuine feelings, especially in educational settings. For instance, tools that analyze facial expressions or tone of voice can be incredibly useful for teachers trying to gauge student engagement. However, I often feel that relying too heavily on these technologies can lead to misunderstandings. Emotions are complex and nuanced; a smile doesn’t always mean happiness, and a frown doesn’t always signify sadness. By placing too much trust in algorithms, we risk oversimplifying the rich tapestry of human emotion. I believe that while technology can aid our understanding, it shouldn’t replace our instinctual ability to connect with others. After all, the most profound insights into feelings often come from genuine human interaction, not just data points on a screen. Balancing tech with empathy is key in nurturing emotional intelligence in our schools.',\n",
       " 'domain': 'student_essays',\n",
       " 'date': '2025',\n",
       " 'source': '9edd7547-57c4-4ef0-b33e-6a0f82d35499',\n",
       " 'lang': 'en-EN',\n",
       " 'label': 1,\n",
       " 'agent': 'gpt-4o-mini',\n",
       " 'type': 'fulltext',\n",
       " 'n_chars': 1161,\n",
       " 'n_chars_nospace': 981,\n",
       " 'n_words': 181,\n",
       " 'avg_word_len': 5.303867403314917,\n",
       " 'n_sents': 9,\n",
       " 'n_punct': 26,\n",
       " 'punct_ratio': 0.026503567787971458,\n",
       " 'upper_ratio': 0.011213047910295617,\n",
       " 'digit_ratio': 0.0,\n",
       " 'url_count': 0,\n",
       " 'type_token_ratio': 0.7348066298342542,\n",
       " 'hapax_ratio': 0.580110497237569}"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature extraction \n",
    "dataset_feats = DatasetDict({\n",
    "    split: ds.map(extract_metrics_batch, batched=True, num_proc=32)\n",
    "    for split, ds in dataset01.items()\n",
    "})\n",
    "dataset_feats['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915de6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare arrays\n",
    "def to_xy(ds):\n",
    "    X = np.column_stack([np.array(ds[f], dtype=np.float32) for f in FEATURES])\n",
    "    y = np.array(ds[\"label\"], dtype=np.int64)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "24eb9c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (382520, 12)  Test size: (109292, 12)\n",
      "Class balance (train): {0: 104303, 1: 151962}\n",
      "Class balance (test): {0: 29801, 1: 43418}\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = to_xy(dataset_feats[\"train\"])\n",
    "X_test,  y_test  = to_xy(dataset_feats[\"test\"])\n",
    "\n",
    "print(\"Train size:\", X_train.shape, \" Test size:\", X_test.shape)\n",
    "print(\"Class balance (train):\", {c:int((y_train==c).sum()) for c in [0,1]})\n",
    "print(\"Class balance (test):\",  {c:int((y_test==c).sum()) for c in [0,1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120e3510",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "721a089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 3\n",
    "LABELS = [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e7484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_tpr_fpr(cm):\n",
    "    # We'll compute FPR_i via positives predicted for class i vs true negatives.\n",
    "    tp = np.diag(cm).astype(float)\n",
    "    row_sum = cm.sum(axis=1).astype(float)\n",
    "    col_sum = cm.sum(axis=0).astype(float)\n",
    "    total = cm.sum().astype(float)\n",
    "\n",
    "    tpr = np.divide(tp, np.maximum(row_sum, 1), out=np.zeros_like(tp), where=row_sum>0)\n",
    "\n",
    "    fp = col_sum - tp\n",
    "    tn = total - row_sum - col_sum + tp\n",
    "    denom = fp + tn\n",
    "    fpr = np.divide(fp, np.maximum(denom, 1), out=np.zeros_like(fp), where=denom>0)\n",
    "\n",
    "    return tpr, fpr\n",
    "\n",
    "def compute_metrics_multiclass(y_true, y_pred, y_proba):\n",
    "    \"\"\"\n",
    "    Computes macro F1, macro AUROC, per-class TPR/FPR, and macro TPR/FPR averages.\n",
    "    \"\"\"\n",
    "    f1_macro = f1_score(y_true, y_pred, labels=LABELS, average='macro', zero_division=0)\n",
    "\n",
    "    # AUROC (macro one-vs-rest)\n",
    "    uniq = np.unique(y_true)\n",
    "    if len(uniq) >= 2:\n",
    "        y_true_bin = label_binarize(y_true, classes=LABELS)\n",
    "        auroc_macro = roc_auc_score(y_true_bin, y_proba, average='macro', multi_class='ovr')\n",
    "    else:\n",
    "        auroc_macro = float('nan')\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=LABELS)\n",
    "    tpr, fpr = _safe_tpr_fpr(cm)\n",
    "\n",
    "    # Macro-averaged TPR/FPR\n",
    "    tpr_macro = float(np.mean(tpr))\n",
    "    fpr_macro = float(np.mean(fpr))\n",
    "\n",
    "    # Flatten per-class metrics into a dict\n",
    "    per_class = {}\n",
    "    for i, lab in enumerate(LABELS):\n",
    "        per_class[f\"TPR_{lab}\"] = float(tpr[i])\n",
    "        per_class[f\"FPR_{lab}\"] = float(fpr[i])\n",
    "\n",
    "    out = {\n",
    "        \"F1_macro\": float(f1_macro),\n",
    "        \"AUROC_macro\": float(auroc_macro),\n",
    "        \"TPR_macro\": tpr_macro,\n",
    "        \"FPR_macro\": fpr_macro,\n",
    "    }\n",
    "    out.update(per_class)\n",
    "    return out\n",
    "\n",
    "def evaluate_by_group(y_true, y_pred, y_proba, group_values, min_samples=50):\n",
    "    \"\"\"\n",
    "    Returns a pandas DataFrame with metrics per group.\n",
    "    - Skips AUROC for groups that contain <2 classes (sets AUROC_macro=nan)\n",
    "    - Drops groups with < min_samples rows\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    y_proba = np.asarray(y_proba)\n",
    "    group_values = np.asarray(group_values)\n",
    "\n",
    "    rows = []\n",
    "    for g in np.unique(group_values):\n",
    "        idx = np.where(group_values == g)[0]\n",
    "        if idx.size < min_samples:\n",
    "            continue\n",
    "\n",
    "        yt = y_true[idx]\n",
    "        yp = y_pred[idx]\n",
    "        probs = y_proba[idx]\n",
    "\n",
    "        metrics = compute_metrics_multiclass(yt, yp, probs)\n",
    "        # Also include size and per-class counts for context\n",
    "        counts = {f\"count_label_{lab}\": int((yt == lab).sum()) for lab in LABELS}\n",
    "        row = {\"group\": g, \"n\": int(idx.size)}\n",
    "        row.update(counts)\n",
    "        row.update(metrics)\n",
    "        rows.append(row)\n",
    "\n",
    "    if not rows:\n",
    "        return pd.DataFrame(columns=[\"group\", \"n\"] + [f\"count_label_{l}\" for l in LABELS]\n",
    "                                      + [\"F1_macro\", \"AUROC_macro\"]\n",
    "                                      + [f\"TPR_{l}\" for l in LABELS] + [f\"FPR_{l}\" for l in LABELS])\n",
    "    df = pd.DataFrame(rows).sort_values(\"n\", ascending=False).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "d7d14cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_domains = np.array(dataset01[\"test\"][\"domain\"])\n",
    "test_agents  = np.array(dataset01[\"test\"][\"agent\"])\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "ba551f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression (multinomial)\n",
    "logreg = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lr\", LogisticRegression(max_iter=1000, multi_class=\"multinomial\"))\n",
    "])\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_pred  = logreg.predict(X_test)\n",
    "logreg_proba = logreg.predict_proba(X_test)\n",
    "results[\"LogReg_overall\"] = compute_metrics_multiclass(y_test, logreg_pred, logreg_proba)\n",
    "logreg_by_domain = evaluate_by_group(y_test, logreg_pred, logreg_proba, test_domains, min_samples=50)\n",
    "logreg_by_agent  = evaluate_by_group(y_test, logreg_pred, logreg_proba, test_agents,  min_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "2ca5d6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# XGBoost (softmax)\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=NUM_CLASSES,\n",
    "    eval_metric=\"mlogloss\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_proba = xgb.predict_proba(X_test)\n",
    "xgb_pred  = np.argmax(xgb_proba, axis=1)\n",
    "results[\"XGBoost_overall\"] = compute_metrics_multiclass(y_test, xgb_pred, xgb_proba)\n",
    "xgb_by_domain = evaluate_by_group(y_test, xgb_pred, xgb_proba, test_domains, min_samples=50)\n",
    "xgb_by_agent  = evaluate_by_group(y_test, xgb_pred, xgb_proba, test_agents,  min_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "e4e57e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2857\n",
      "[LightGBM] [Info] Number of data points in the train set: 382520, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.299481\n",
      "[LightGBM] [Info] Start training from score -0.923150\n",
      "[LightGBM] [Info] Start training from score -1.108477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/staff_homes/kboenisc/miniconda3/envs/luminar/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# LightGBM (multiclass)\n",
    "lgbm = LGBMClassifier(\n",
    "    n_estimators=600,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=63,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    objective=\"multiclass\",\n",
    "    num_class=NUM_CLASSES,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "lgbm.fit(X_train, y_train)\n",
    "lgbm_proba = lgbm.predict_proba(X_test)\n",
    "lgbm_pred  = np.argmax(lgbm_proba, axis=1)\n",
    "results[\"LightGBM_overall\"] = compute_metrics_multiclass(y_test, lgbm_pred, lgbm_proba)\n",
    "lgbm_by_domain = evaluate_by_group(y_test, lgbm_pred, lgbm_proba, test_domains, min_samples=50)\n",
    "lgbm_by_agent  = evaluate_by_group(y_test, lgbm_pred, lgbm_proba, test_agents,  min_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45e061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def df_to_markdown(df, title=None, max_rows=15, floatfmt=\".3f\"):\n",
    "    \"\"\"Render a Pandas DataFrame as a Markdown table.\"\"\"\n",
    "    df_ = df.copy()\n",
    "    # Round floats\n",
    "    for col in df_.select_dtypes(include=[float]).columns:\n",
    "        df_[col] = df_[col].map(lambda x: f\"{x:{floatfmt}}\" if pd.notnull(x) else \"\")\n",
    "    md = df_.head(max_rows).to_markdown(index=False)\n",
    "    if title:\n",
    "        display(Markdown(f\"### {title}\\n\\n{md}\"))\n",
    "    else:\n",
    "        display(Markdown(md))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "bc665748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Overall Model Results"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Overall Results\n",
       "\n",
       "| Model            |   F1_macro |   AUROC_macro |   TPR_macro |   FPR_macro |   TPR_0 |   FPR_0 |   TPR_1 |   FPR_1 |   TPR_2 |   FPR_2 |\n",
       "|:-----------------|-----------:|--------------:|------------:|------------:|--------:|--------:|--------:|--------:|--------:|--------:|\n",
       "| LogReg_overall   |      0.571 |         0.772 |       0.577 |       0.204 |   0.463 |   0.121 |   0.873 |   0.311 |   0.395 |   0.182 |\n",
       "| XGBoost_overall  |      0.691 |         0.881 |       0.691 |       0.145 |   0.576 |   0.118 |   0.89  |   0.13  |   0.606 |   0.187 |\n",
       "| LightGBM_overall |      0.706 |         0.892 |       0.705 |       0.138 |   0.601 |   0.118 |   0.895 |   0.118 |   0.62  |   0.177 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Per-Domain Results"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Logistic Regression — Per Domain\n",
       "\n",
       "| group                  |     n |   count_label_0 |   count_label_1 |   count_label_2 |   F1_macro |   AUROC_macro |   TPR_macro |   FPR_macro |   TPR_0 |   FPR_0 |   TPR_1 |   FPR_1 |   TPR_2 |   FPR_2 |\n",
       "|:-----------------------|------:|----------------:|----------------:|----------------:|-----------:|--------------:|------------:|------------:|--------:|--------:|--------:|--------:|--------:|--------:|\n",
       "| student_essays         | 29044 |            8451 |           10736 |            9857 |      0.567 |         0.772 |       0.605 |       0.2   |   0.745 |   0.167 |   0.859 |   0.35  |   0.211 |   0.083 |\n",
       "| spiegel_articles       | 14164 |            3294 |            5579 |            5291 |      0.418 |         0.682 |       0.448 |       0.265 |   0.085 |   0.039 |   0.771 |   0.412 |   0.488 |   0.343 |\n",
       "| bundestag              | 13117 |            3726 |            5012 |            4379 |      0.335 |         0.678 |       0.406 |       0.292 |   0.063 |   0.016 |   0.939 |   0.692 |   0.215 |   0.169 |\n",
       "| cnn_news               | 12362 |            3773 |            5485 |            3104 |      0.663 |         0.858 |       0.664 |       0.142 |   0.668 |   0.147 |   0.913 |   0.121 |   0.412 |   0.157 |\n",
       "| blog_authorship_corpus | 12270 |            4032 |            4754 |            3484 |      0.457 |         0.654 |       0.479 |       0.251 |   0.418 |   0.21  |   0.829 |   0.413 |   0.189 |   0.131 |\n",
       "| house_of_commons       | 10001 |            2590 |            4052 |            3359 |      0.644 |         0.848 |       0.647 |       0.158 |   0.39  |   0.085 |   0.951 |   0.143 |   0.6   |   0.247 |\n",
       "| arxiv_papers           |  7844 |            1628 |            3113 |            3103 |      0.673 |         0.862 |       0.671 |       0.136 |   0.389 |   0.152 |   0.94  |   0.011 |   0.684 |   0.247 |\n",
       "| euro_court_cases       |  7435 |            1829 |            2811 |            2795 |      0.704 |         0.88  |       0.697 |       0.14  |   0.513 |   0.123 |   0.815 |   0.01  |   0.763 |   0.287 |\n",
       "| gutenberg              |  3055 |             478 |            1876 |             701 |      0.628 |         0.897 |       0.639 |       0.109 |   0.416 |   0.122 |   0.874 |   0.016 |   0.626 |   0.189 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### XGBoost — Per Domain\n",
       "\n",
       "| group                  |     n |   count_label_0 |   count_label_1 |   count_label_2 |   F1_macro |   AUROC_macro |   TPR_macro |   FPR_macro |   TPR_0 |   FPR_0 |   TPR_1 |   FPR_1 |   TPR_2 |   FPR_2 |\n",
       "|:-----------------------|------:|----------------:|----------------:|----------------:|-----------:|--------------:|------------:|------------:|--------:|--------:|--------:|--------:|--------:|--------:|\n",
       "| student_essays         | 29044 |            8451 |           10736 |            9857 |      0.782 |         0.928 |       0.787 |       0.105 |   0.821 |   0.123 |   0.907 |   0.082 |   0.632 |   0.11  |\n",
       "| spiegel_articles       | 14164 |            3294 |            5579 |            5291 |      0.552 |         0.778 |       0.55  |       0.214 |   0.33  |   0.112 |   0.731 |   0.182 |   0.59  |   0.35  |\n",
       "| bundestag              | 13117 |            3726 |            5012 |            4379 |      0.569 |         0.815 |       0.587 |       0.195 |   0.265 |   0.065 |   0.911 |   0.257 |   0.585 |   0.264 |\n",
       "| cnn_news               | 12362 |            3773 |            5485 |            3104 |      0.675 |         0.876 |       0.682 |       0.133 |   0.767 |   0.175 |   0.917 |   0.111 |   0.361 |   0.114 |\n",
       "| blog_authorship_corpus | 12270 |            4032 |            4754 |            3484 |      0.568 |         0.799 |       0.576 |       0.202 |   0.531 |   0.185 |   0.857 |   0.284 |   0.341 |   0.138 |\n",
       "| house_of_commons       | 10001 |            2590 |            4052 |            3359 |      0.726 |         0.899 |       0.724 |       0.124 |   0.561 |   0.101 |   0.922 |   0.064 |   0.689 |   0.206 |\n",
       "| arxiv_papers           |  7844 |            1628 |            3113 |            3103 |      0.721 |         0.916 |       0.721 |       0.104 |   0.319 |   0.07  |   0.987 |   0.003 |   0.858 |   0.24  |\n",
       "| euro_court_cases       |  7435 |            1829 |            2811 |            2795 |      0.751 |         0.912 |       0.749 |       0.113 |   0.587 |   0.132 |   0.932 |   0.019 |   0.729 |   0.189 |\n",
       "| gutenberg              |  3055 |             478 |            1876 |             701 |      0.613 |         0.912 |       0.649 |       0.09  |   0.136 |   0.048 |   0.93  |   0.019 |   0.882 |   0.204 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### LightGBM — Per Domain\n",
       "\n",
       "| group                  |     n |   count_label_0 |   count_label_1 |   count_label_2 |   F1_macro |   AUROC_macro |   TPR_macro |   FPR_macro |   TPR_0 |   FPR_0 |   TPR_1 |   FPR_1 |   TPR_2 |   FPR_2 |\n",
       "|:-----------------------|------:|----------------:|----------------:|----------------:|-----------:|--------------:|------------:|------------:|--------:|--------:|--------:|--------:|--------:|--------:|\n",
       "| student_essays         | 29044 |            8451 |           10736 |            9857 |      0.813 |         0.946 |       0.817 |       0.09  |   0.852 |   0.11  |   0.923 |   0.068 |   0.675 |   0.092 |\n",
       "| spiegel_articles       | 14164 |            3294 |            5579 |            5291 |      0.564 |         0.788 |       0.562 |       0.209 |   0.365 |   0.121 |   0.75  |   0.18  |   0.571 |   0.327 |\n",
       "| bundestag              | 13117 |            3726 |            5012 |            4379 |      0.588 |         0.824 |       0.601 |       0.188 |   0.299 |   0.074 |   0.902 |   0.226 |   0.604 |   0.264 |\n",
       "| cnn_news               | 12362 |            3773 |            5485 |            3104 |      0.681 |         0.879 |       0.688 |       0.13  |   0.779 |   0.178 |   0.915 |   0.103 |   0.369 |   0.11  |\n",
       "| blog_authorship_corpus | 12270 |            4032 |            4754 |            3484 |      0.578 |         0.806 |       0.585 |       0.198 |   0.54  |   0.188 |   0.849 |   0.261 |   0.366 |   0.145 |\n",
       "| house_of_commons       | 10001 |            2590 |            4052 |            3359 |      0.731 |         0.903 |       0.729 |       0.122 |   0.573 |   0.101 |   0.917 |   0.06  |   0.697 |   0.204 |\n",
       "| arxiv_papers           |  7844 |            1628 |            3113 |            3103 |      0.734 |         0.918 |       0.732 |       0.101 |   0.351 |   0.07  |   0.989 |   0.003 |   0.857 |   0.229 |\n",
       "| euro_court_cases       |  7435 |            1829 |            2811 |            2795 |      0.764 |         0.918 |       0.763 |       0.107 |   0.613 |   0.131 |   0.943 |   0.017 |   0.732 |   0.174 |\n",
       "| gutenberg              |  3055 |             478 |            1876 |             701 |      0.639 |         0.914 |       0.661 |       0.088 |   0.213 |   0.059 |   0.936 |   0.018 |   0.833 |   0.187 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Per-Agent Results"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Logistic Regression — Per Agent\n",
       "\n",
       "| group            |     n |   count_label_0 |   count_label_1 |   count_label_2 |   F1_macro | AUROC_macro   |   TPR_macro |   FPR_macro |   TPR_0 |   FPR_0 |   TPR_1 |   FPR_1 |   TPR_2 |   FPR_2 |\n",
       "|:-----------------|------:|----------------:|----------------:|----------------:|-----------:|:--------------|------------:|------------:|--------:|--------:|--------:|--------:|--------:|--------:|\n",
       "| gemma2:9b        | 40289 |               0 |           21645 |           18644 |      0.458 |               |       0.437 |       0.18  |   0     |   0.132 |   0.893 |   0.339 |   0.418 |   0.07  |\n",
       "| gpt-4o-mini      | 33489 |               0 |           18627 |           14862 |      0.42  |               |       0.407 |       0.22  |   0     |   0.106 |   0.856 |   0.46  |   0.364 |   0.095 |\n",
       "| human            | 29801 |           29801 |               0 |               0 |      0.211 |               |       0.154 |       0.179 |   0.463 |   0     |   0     |   0.214 |   0     |   0.323 |\n",
       "| phi3:3.8b        |  2601 |               0 |            1402 |            1199 |      0.42  |               |       0.405 |       0.217 |   0     |   0.118 |   0.837 |   0.401 |   0.378 |   0.133 |\n",
       "| nemotron         |   920 |               0 |             560 |             360 |      0.395 |               |       0.36  |       0.237 |   0     |   0.177 |   0.657 |   0.311 |   0.422 |   0.223 |\n",
       "| deepseek-r1:1.5b |   899 |               0 |             500 |             399 |      0.477 |               |       0.442 |       0.159 |   0     |   0.165 |   0.87  |   0.213 |   0.456 |   0.098 |\n",
       "| deepseek-r1:32b  |   633 |               0 |             326 |             307 |      0.474 |               |       0.46  |       0.171 |   0     |   0.101 |   0.917 |   0.342 |   0.463 |   0.071 |\n",
       "| o3-mini          |   474 |               0 |             259 |             215 |      0.44  |               |       0.433 |       0.203 |   0     |   0.078 |   0.919 |   0.47  |   0.381 |   0.062 |\n",
       "| gpt-4-turbo      |   186 |               0 |              99 |              87 |      0.437 |               |       0.428 |       0.213 |   0     |   0.07  |   0.848 |   0.437 |   0.437 |   0.131 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### XGBoost — Per Agent\n",
       "\n",
       "| group            |     n |   count_label_0 |   count_label_1 |   count_label_2 |   F1_macro | AUROC_macro   |   TPR_macro |   FPR_macro |   TPR_0 |   FPR_0 |   TPR_1 |   FPR_1 |   TPR_2 |   FPR_2 |\n",
       "|:-----------------|------:|----------------:|----------------:|----------------:|-----------:|:--------------|------------:|------------:|--------:|--------:|--------:|--------:|--------:|--------:|\n",
       "| gemma2:9b        | 40289 |               0 |           21645 |           18644 |      0.523 |               |       0.49  |       0.126 |   0     |   0.134 |   0.892 |   0.161 |   0.577 |   0.084 |\n",
       "| gpt-4o-mini      | 33489 |               0 |           18627 |           14862 |      0.543 |               |       0.516 |       0.112 |   0     |   0.098 |   0.892 |   0.151 |   0.656 |   0.086 |\n",
       "| human            | 29801 |           29801 |               0 |               0 |      0.244 |               |       0.192 |       0.141 |   0.576 |   0     |   0     |   0.09  |   0     |   0.334 |\n",
       "| phi3:3.8b        |  2601 |               0 |            1402 |            1199 |      0.476 |               |       0.454 |       0.169 |   0     |   0.115 |   0.884 |   0.299 |   0.479 |   0.093 |\n",
       "| nemotron         |   920 |               0 |             560 |             360 |      0.476 |               |       0.431 |       0.164 |   0     |   0.179 |   0.78  |   0.214 |   0.514 |   0.1   |\n",
       "| deepseek-r1:1.5b |   899 |               0 |             500 |             399 |      0.528 |               |       0.484 |       0.116 |   0     |   0.168 |   0.894 |   0.12  |   0.559 |   0.06  |\n",
       "| deepseek-r1:32b  |   633 |               0 |             326 |             307 |      0.525 |               |       0.503 |       0.13  |   0     |   0.098 |   0.905 |   0.215 |   0.603 |   0.077 |\n",
       "| o3-mini          |   474 |               0 |             259 |             215 |      0.505 |               |       0.482 |       0.149 |   0     |   0.091 |   0.861 |   0.228 |   0.586 |   0.127 |\n",
       "| gpt-4-turbo      |   186 |               0 |              99 |              87 |      0.487 |               |       0.463 |       0.163 |   0     |   0.108 |   0.838 |   0.241 |   0.552 |   0.141 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### LightGBM — Per Agent\n",
       "\n",
       "| group            |     n |   count_label_0 |   count_label_1 |   count_label_2 |   F1_macro | AUROC_macro   |   TPR_macro |   FPR_macro |   TPR_0 |   FPR_0 |   TPR_1 |   FPR_1 |   TPR_2 |   FPR_2 |\n",
       "|:-----------------|------:|----------------:|----------------:|----------------:|-----------:|:--------------|------------:|------------:|--------:|--------:|--------:|--------:|--------:|--------:|\n",
       "| gemma2:9b        | 40289 |               0 |           21645 |           18644 |      0.524 |               |       0.49  |       0.124 |   0     |   0.139 |   0.889 |   0.147 |   0.581 |   0.087 |\n",
       "| gpt-4o-mini      | 33489 |               0 |           18627 |           14862 |      0.557 |               |       0.53  |       0.1   |   0     |   0.091 |   0.907 |   0.134 |   0.685 |   0.074 |\n",
       "| human            | 29801 |           29801 |               0 |               0 |      0.25  |               |       0.2   |       0.133 |   0.601 |   0     |   0     |   0.082 |   0     |   0.317 |\n",
       "| phi3:3.8b        |  2601 |               0 |            1402 |            1199 |      0.481 |               |       0.457 |       0.164 |   0     |   0.123 |   0.889 |   0.287 |   0.482 |   0.081 |\n",
       "| nemotron         |   920 |               0 |             560 |             360 |      0.499 |               |       0.453 |       0.145 |   0     |   0.172 |   0.798 |   0.175 |   0.561 |   0.089 |\n",
       "| deepseek-r1:1.5b |   899 |               0 |             500 |             399 |      0.528 |               |       0.485 |       0.116 |   0     |   0.166 |   0.892 |   0.115 |   0.564 |   0.066 |\n",
       "| deepseek-r1:32b  |   633 |               0 |             326 |             307 |      0.534 |               |       0.51  |       0.122 |   0     |   0.098 |   0.899 |   0.176 |   0.632 |   0.092 |\n",
       "| o3-mini          |   474 |               0 |             259 |             215 |      0.507 |               |       0.482 |       0.145 |   0     |   0.103 |   0.873 |   0.223 |   0.572 |   0.108 |\n",
       "| gpt-4-turbo      |   186 |               0 |              99 |              87 |      0.5   |               |       0.477 |       0.152 |   0     |   0.102 |   0.879 |   0.253 |   0.552 |   0.101 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"## Overall Model Results\"))\n",
    "display(Markdown(\"----\"))\n",
    "overall_df = pd.DataFrame([\n",
    "    {\"Model\": model, **metrics} for model, metrics in results.items()\n",
    "])\n",
    "df_to_markdown(overall_df, title=\"Overall Results\")\n",
    "\n",
    "display(Markdown(\"## Per-Domain Results\"))\n",
    "display(Markdown(\"----\"))\n",
    "df_to_markdown(logreg_by_domain, title=\"Logistic Regression — Per Domain\")\n",
    "df_to_markdown(xgb_by_domain,  title=\"XGBoost — Per Domain\")\n",
    "df_to_markdown(lgbm_by_domain, title=\"LightGBM — Per Domain\")\n",
    "\n",
    "display(Markdown(\"## Per-Agent Results\"))\n",
    "display(Markdown(\"----\"))\n",
    "df_to_markdown(logreg_by_agent, title=\"Logistic Regression — Per Agent\")\n",
    "df_to_markdown(xgb_by_agent,  title=\"XGBoost — Per Agent\")\n",
    "df_to_markdown(lgbm_by_agent, title=\"LightGBM — Per Agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2b2efe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
