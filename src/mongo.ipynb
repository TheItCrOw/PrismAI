{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pymongo import MongoClient\n",
    "\n",
    "load_dotenv(\"../env\")\n",
    "client = MongoClient(os.environ.get(\"MONGO_DB_CONNECTION\"))\n",
    "collection = client.get_database(\"prismai\").get_collection(\"collected_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import batched\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "datasets.disable_progress_bars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2025-01-22 18:57:48.099021612 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 24 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "\u001b[0;93m2025-01-22 18:57:48.103104602 [W:onnxruntime:, session_state.cc:1168 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\u001b[m\n",
      "\u001b[0;93m2025-01-22 18:57:48.103111104 [W:onnxruntime:, session_state.cc:1170 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\u001b[m\n"
     ]
    }
   ],
   "source": [
    "from transition_scores.scorer import OnnxTransitionScorer\n",
    "from transition_scores.data import CustomTokenizer, RollingWindowChunkTokenizer\n",
    "\n",
    "scorer = OnnxTransitionScorer(\n",
    "    \"/hot_storage/models/onnx/gpt2_onnx_o4/\",\n",
    "    tokenizer=RollingWindowChunkTokenizer.from_pretrained(\"gpt2\"),\n",
    "    batch_size=4,\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1616615c0b54cbdb1f777184db73800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/802852 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m dataset \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_list([dd \u001b[38;5;241m|\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(dd[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_id\u001b[39m\u001b[38;5;124m\"\u001b[39m])} \u001b[38;5;28;01mfor\u001b[39;00m dd \u001b[38;5;129;01min\u001b[39;00m batch])\n\u001b[1;32m     15\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunks\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 16\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mpass\u001b[39;49;00m\n",
      "File \u001b[0;32m/nvme/projects/PrismAI/PrismAI/src/transition_scores/scorer/abc.py:152\u001b[0m, in \u001b[0;36mTransitionScorerABC.process\u001b[0;34m(self, sequences, dataset, top_k)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    147\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mforward(\n\u001b[1;32m    148\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice),\n\u001b[1;32m    149\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice),\n\u001b[1;32m    150\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice),\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 152\u001b[0m     logits: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m outputs\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seq_probs, target_ids, other_fields \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m    156\u001b[0m     logits,\n\u001b[1;32m    157\u001b[0m     input_ids,\n\u001b[1;32m    158\u001b[0m     transpose_dict_of_lists(batch, \u001b[38;5;28miter\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m    159\u001b[0m ):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total = collection.count_documents({})\n",
    "\n",
    "tq = tqdm(\n",
    "    collection.find(\n",
    "        projection=[\n",
    "            \"text\",\n",
    "            \"chunks\",\n",
    "        ],\n",
    "        batch_size=128,\n",
    "    ),\n",
    "    total=total,\n",
    ")\n",
    "for batch in batched(tq, 512):\n",
    "    dataset = Dataset.from_list([dd | {\"_id\": str(dd[\"_id\"])} for dd in batch])\n",
    "    dataset = dataset.filter(lambda x: x[\"text\"] and x[\"chunks\"])\n",
    "    for scores in scorer.process(dataset=dataset, top_k=100):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = collection.find_one({\"_id\": \"22c34302-0ec6-4781-8d96-1d6a4fda049e\"})\n",
    "print(one[\"text\"])\n",
    "print(\"\".join(one[\"chunks\"]))\n",
    "one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson.dbref import DBRef\n",
    "\n",
    "from transition_scores.data import LogProbs\n",
    "from transition_scores.mongo import TextTransitionScore, TransitionScoreItem\n",
    "\n",
    "dict(\n",
    "    TransitionScoreItem(\n",
    "        DBRef(\"a\", \"b\"),\n",
    "        \"gpt2\",\n",
    "        \"onnx\",\n",
    "        TextTransitionScore([LogProbs(0, 1.0, [0], [1.0])]),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1174fe8a75cd49cd9e362f28b9533551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32de1f2874a4a71b2613590e878c448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['_id', 'text_sha256', 'input_ids', 'attention_mask', 'length'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "from transition_scores.data import CustomTokenizer\n",
    "\n",
    "tokenizer = CustomTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"_id\": [\"abc-def-123\"],\n",
    "        \"text\": [\n",
    "            \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\"\n",
    "        ],\n",
    "        \"chunks\": [\n",
    "            [\n",
    "                \"Lorem ipsum dolor sit amet,\",\n",
    "                \"consectetur adipiscing elit.\",\n",
    "                \"Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\",\n",
    "                \"Ut enim ad minim veniam,\",\n",
    "                \"quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\",\n",
    "            ]\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "dataset = tokenizer.tokenize_dataset(dataset)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6651b4649574feabfb2f0268d4d9e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd19c1483404cc2ae34e25ba7534c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc5266bf6914b25a9b830ea1ce5f3f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['_id', 'text_sha256', 'length', 'start_idx', 'attention_mask', 'start_token_idx', 'end_idx', 'text', 'prefix_idx', 'input_ids'],\n",
       "    num_rows: 5\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "from transition_scores.data import CustomTokenizer, RollingWindowChunkTokenizer\n",
    "\n",
    "tokenizer = RollingWindowChunkTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"_id\": [\"abc-def-123\"],\n",
    "        \"text\": [\n",
    "            \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\"\n",
    "        ],\n",
    "        \"chunks\": [\n",
    "            [\n",
    "                \"Lorem ipsum dolor sit amet,\",\n",
    "                \"consectetur adipiscing elit.\",\n",
    "                \"Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\",\n",
    "                \"Ut enim ad minim veniam,\",\n",
    "                \"quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\",\n",
    "            ]\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "dataset = tokenizer.tokenize_dataset(dataset)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 1], [2, 3]], [[4, 5], [6, 7]], [[8, 9], [10, 11]], [[12, 13], [14, 15]]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.arange(16).view(4, 2, 2).tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
