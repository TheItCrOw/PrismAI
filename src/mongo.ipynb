{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pymongo\n",
    "from dotenv import load_dotenv\n",
    "from pymongo import MongoClient\n",
    "from pymongo.collection import Collection\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "load_dotenv(\"../env\")\n",
    "client = MongoClient(os.environ.get(\"MONGO_DB_CONNECTION\"))\n",
    "db = client.get_database(\"prismai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCHEAT Ghostbuster HC3 MAGE OpenLLMText SeqXGPT\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "CHEAT Ghostbuster HC3 MAGE OpenLLMText SeqXGPT\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_items = db.get_collection(\"collected_items\")\n",
    "synthesized_texts = db.get_collection(\"synthesized_texts\")\n",
    "features_prismai = db.get_collection(\"features_prismai\")\n",
    "test_swt = db.get_collection(\"test_swt\")\n",
    "test_new = db.get_collection(\"test_new\")\n",
    "dataset_CHEAT = db.get_collection(\"dataset_CHEAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 126.87it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 134.39it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 131.70it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 134.54it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 135.93it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 142.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# for ds in \"CHEAT Ghostbuster HC3 MAGE OpenLLMText SeqXGPT\".split():\n",
    "#     for index in tqdm(list(features_prismai.list_indexes())):\n",
    "#         db.get_collection(f\"features_{ds}\").create_index(index.get(\"key\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "def normalize_text(text: str):\n",
    "    return \" \".join(text.strip().split())\n",
    "\n",
    "\n",
    "def get_synth_chunk_range(\n",
    "    tokenizer: AutoTokenizer,\n",
    "    doc: dict,\n",
    "    synth: dict,\n",
    "):\n",
    "    full_text = normalize_text(synth[\"text\"])\n",
    "    encoding = tokenizer(\n",
    "        full_text,\n",
    "        return_offsets_mapping=True,\n",
    "        return_special_tokens_mask=True,\n",
    "        add_special_tokens=True,\n",
    "        truncation=False,\n",
    "    )\n",
    "    synth_text: str = normalize_text(synth[\"synth_metadata\"][\"synth_text\"])\n",
    "\n",
    "    if not synth_text:\n",
    "        return None\n",
    "\n",
    "    chunk_start_idx = synth[\"synth_metadata\"][\"start_idx\"]\n",
    "    prefix = \" \".join(synth[\"chunks\"][:chunk_start_idx])\n",
    "    prefix = normalize_text(prefix)\n",
    "\n",
    "    char_start_index = full_text.index(synth_text, len(prefix))\n",
    "    token_start_idx = encoding.char_to_token(char_start_index)\n",
    "\n",
    "    # synth_text_is_first_text = chunk_start_idx == 0 or not prefix\n",
    "\n",
    "    if token_start_idx is None:\n",
    "        raise ValueError(f\"Token start index is None: {synth['_id']}\")\n",
    "\n",
    "    synth_encoding = tokenizer(\n",
    "        \" \" + synth_text\n",
    "        if \"gpt\" in tokenizer.name_or_path and char_start_index > 0\n",
    "        else synth_text,\n",
    "        add_special_tokens=False,\n",
    "        return_length=True,\n",
    "        truncation=False,\n",
    "    )\n",
    "    (synth_length,) = synth_encoding[\"length\"]\n",
    "    token_end_idx = token_start_idx + synth_length\n",
    "\n",
    "    # sanity check\n",
    "    decoded_synth_text = tokenizer.decode(\n",
    "        encoding.input_ids[token_start_idx:token_end_idx],\n",
    "        clean_up_tokenization_spaces=False,\n",
    "    )\n",
    "    if synth_text.strip() != decoded_synth_text.strip():\n",
    "        raise ValueError(\n",
    "            f\"Decoding mismatch: {synth['_id']}!\\n  '{synth_text}'\\n!='{decoded_synth_text}'\\n\"\n",
    "        )\n",
    "\n",
    "    return doc[\"_id\"], token_start_idx, token_end_idx\n",
    "    # else:\n",
    "    #     synth_chunks_char_idx = full_text.index(first_synth_chunk)\n",
    "    #     token_start_idx = encoding.char_to_token(synth_chunks_char_idx)\n",
    "    #     if first_synth_chunk in full_text[: synth_chunks_char_idx + 1]:\n",
    "    #         raise ValueError(\"Chunk not unique in text!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 801/22635 [00:02<01:17, 280.03it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1619 > 1024). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 35/35 [00:00<00:00, 230.60it/s]it/s] \n",
      "100%|██████████| 22635/22635 [11:15<00:00, 33.49it/s]\n"
     ]
    }
   ],
   "source": [
    "model = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=model, use_fast=True\n",
    ")\n",
    "num_docs = features_prismai.count_documents(\n",
    "    {\"document.type\": \"chunk\", \"model.name\": model},\n",
    ")\n",
    "failures = []\n",
    "batch_size = 1000\n",
    "with (\n",
    "    tqdm(total=num_docs, position=0, leave=True) as tq_find,\n",
    "    tqdm(total=batch_size, position=1, leave=True) as tq_update,\n",
    "):\n",
    "    for skip in range(0, num_docs, batch_size):\n",
    "        results = []\n",
    "        for doc in features_prismai.find(\n",
    "            {\"document.type\": \"chunk\", \"model.name\": model},\n",
    "            projection=[\"document._synth_id.$id\"],\n",
    "            skip=skip,\n",
    "            limit=batch_size,\n",
    "        ):\n",
    "            synth = synthesized_texts.find_one(\n",
    "                {\"_id\": doc[\"document\"][\"_synth_id\"][\"$id\"]}\n",
    "            )\n",
    "            try:\n",
    "                result = get_synth_chunk_range(tokenizer, doc, synth)\n",
    "                if result is not None:\n",
    "                    results.append(result)\n",
    "            except ValueError:\n",
    "                failures.append(doc[\"_id\"])\n",
    "                tq_find.set_postfix_str(f\"failures: {len(failures)}\")\n",
    "            tq_find.update(1)\n",
    "\n",
    "        tq_update.reset(len(results))\n",
    "        for _id, start, end in results:\n",
    "            features_prismai.update_one(\n",
    "                {\"_id\": _id},\n",
    "                {\n",
    "                    \"$set\": {\n",
    "                        \"document.synth_token_start\": start,\n",
    "                        \"document.synth_token_end\": end,\n",
    "                    }\n",
    "                },\n",
    "            )\n",
    "            tq_update.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('6797bddabb95bc200c6ad37a'),\n",
       " 'ref_id': DBRef('collected_items', 'bd314092-bcff-4adc-b372-8a3d1d9b23c9'),\n",
       " '_ref_id': DBRef('collected_items', 'ec3f8da5-6dab-4488-af89-3815f5fa6d0d'),\n",
       " 'domain': 'student_essays',\n",
       " 'date': '-',\n",
       " 'source': 'https://www.kaggle.com/datasets/thedrcat/daigt-proper-train-dataset',\n",
       " 'lang': 'en-EN',\n",
       " 'agent': 'gemma2:9b',\n",
       " 'text': 'In the passage \"Driverless Cars Are Coming,\" the author gives reasons why the car would be nice to have, but they also give reasons why it would not be good to have. Even though having a car drive you around would be nice, to me the benefits of driving yourself around are so much more than thoughs of having a car drive you around. Having a car driving you around all the time can create many dangers to the people around you, possible malfunctions can occur to the car, and the joy of driving your own car around would be lost.  The dangers of having a car drive you around would be that the human brain is marter than a computer. We can determain situations better in person than a computer can however many miles away from it you are. While computers are more logistically smarter than humans, we have experiance in everyday life to help us determain how to drive more efficantly.  Havong a self driving car is a great advancment in the technilogical field, but what is saying that there would not be malfunctions. If you are driving approxamently 70 miles on the interstate and the car malfunctions, there can be major risks to your safety and the safety of those around you.  Lastily, when you were little you would always dream about driving your own car one day, but if you have a car driving you around you would lose that freedom feeling. Also, today a lot of people like to drive around when they are streesed because it helps them get there mind off of things, but if you have a car driving you around places you lose the stress free driving time because you are not controling the car.   ',\n",
       " 'chunks': ['In the passage \"Driverless Cars Are Coming,\" the author gives reasons why the car would be nice to have, but they also give reasons why it would not be good to have. Even though having a car drive you around would be nice, to me the benefits of driving yourself around are so much more than thoughs of having a car drive you around. Having a car driving you around all the time can create many dangers to the people around you, possible malfunctions can occur to the car, and the joy of driving your own car around would be lost.',\n",
       "  '',\n",
       "  'The dangers of having a car drive you around would be that the human brain is marter than a computer. We can determain situations better in person than a computer can however many miles away from it you are. While computers are more logistically smarter than humans, we have experiance in everyday life to help us determain how to drive more efficantly.',\n",
       "  '',\n",
       "  'Havong a self driving car is a great advancment in the technilogical field, but what is saying that there would not be malfunctions. If you are driving approxamently 70 miles on the interstate and the car malfunctions, there can be major risks to your safety and the safety of those around you.',\n",
       "  '',\n",
       "  'Lastily, when you were little you would always dream about driving your own car one day, but if you have a car driving you around you would lose that freedom feeling. Also, today a lot of people like to drive around when they are streesed because it helps them get there mind off of things, but if you have a car driving you around places you lose the stress free driving time because you are not controling the car.',\n",
       "  '  '],\n",
       " 'type': 'chunk',\n",
       " 'synth_metadata': {'created': '2025-01-21 21:52:47.685554',\n",
       "  'type': 'chunk',\n",
       "  'model': 'gemma2:9b',\n",
       "  'seed': 1645285259,\n",
       "  'total_chunks': 9,\n",
       "  'amount_chunks_to_replace': 1,\n",
       "  'chunks_replaced_percentage': 11.11,\n",
       "  'start_idx': 7,\n",
       "  'end_idx': 8,\n",
       "  'og_chunk_text_length': 1,\n",
       "  'synth_chunk_text_length': 0,\n",
       "  'synth_text': '  ',\n",
       "  'synth_text_truncated': False}}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise RuntimeError(\"STOP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Averager:\n",
    "    def __init__(self):\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, value):\n",
    "        self.sum += value\n",
    "        self.count += 1\n",
    "\n",
    "    def average(self):\n",
    "        return self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "gpt_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", use_fast=True)\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B\", use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "prismai_gpt2 = defaultdict(list)\n",
    "prismai_llama = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc19105d5904813af2fbf6a6bcd7159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28dd24367df141e08f69e7dc703cc956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d36a538297405499dab29336985827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "524abe78c32a4b849a065f62b445baa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe64418372574238aa4f97b5f5b03731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a5611bcdf645f59e6461a331c0491f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836c8754879d47218f6c01b437b5035c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bce1b00e71c4f98bd82b8b9bd9002f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba38f9a84fd84d348d078219b6a39b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5995b9601edd496b9ac04bb5e9332dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for domain in tqdm(db.get_collection(\"collected_items\").distinct(\"domain\"), position=0):\n",
    "    for item in tqdm(\n",
    "        db.get_collection(\"synthesized_texts\").find(\n",
    "            {\"domain\": domain},\n",
    "            projection={\"text\": 1},\n",
    "        ),\n",
    "        position=1,\n",
    "    ):\n",
    "        text = \" \".join(item.get(\"text\").strip().split())\n",
    "        encoding = gpt_tokenizer(text, return_length=True)\n",
    "        (length,) = encoding[\"length\"]\n",
    "        prismai_gpt2[domain].append(length)\n",
    "\n",
    "        encoding = llama_tokenizer(text, return_length=True)\n",
    "        (length,) = encoding[\"length\"]\n",
    "        prismai_llama[domain].append(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c1c70516634bf9a5f53fc730551a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b38cca8feba4541a9e0a90fad6d6932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "arxiv_papers: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a9e76e3c90c4803be3d8bf6d35c1c38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "blog_authorship_corpus: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e43f31c0504fba9036c1047d3d7f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "bundestag: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7edfbe0cf4a34b20bbe666150850f151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cnn_news: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f64fda82ea14391afc228340d91114e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "euro_court_cases: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c083a8f19b542e7b6694bffd91e3c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gutenberg: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8cc9a732c342f0ae47c2fa5133c993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "house_of_commons: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fbc66a62dd04c1486fdda2924250cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiegel_articles: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26eaae8a49f04fcb83191f32d5f79700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "student_essays: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for domain in tqdm(db.get_collection(\"collected_items\").distinct(\"domain\"), position=0):\n",
    "    for item in tqdm(\n",
    "        db.get_collection(\"features_prismai\").aggregate(\n",
    "            [\n",
    "                {\"$match\": {\"document.domain\": domain}},\n",
    "                {\"$project\": {\"_id\": 1, \"document._id.$id\": 1}},\n",
    "                {\n",
    "                    \"$lookup\": {\n",
    "                        \"from\": \"collected_items\",\n",
    "                        \"localField\": \"document._id.$id\",\n",
    "                        \"foreignField\": \"_id\",\n",
    "                        \"as\": \"text\",\n",
    "                        \"pipeline\": [\n",
    "                            {\"$project\": {\"text\": 1}},\n",
    "                        ],\n",
    "                    }\n",
    "                },\n",
    "                {\"$unwind\": \"$text\"},\n",
    "                {\"$project\": {\"text\": \"$text.text\"}},\n",
    "            ]\n",
    "        ),\n",
    "        desc=domain,\n",
    "        position=1,\n",
    "    ):\n",
    "        text = \" \".join(item.get(\"text\").strip().split())\n",
    "        encoding = gpt_tokenizer(text, return_length=True)\n",
    "        (length,) = encoding[\"length\"]\n",
    "        prismai_gpt2[domain].append(length)\n",
    "\n",
    "        encoding = llama_tokenizer(text, return_length=True)\n",
    "        (length,) = encoding[\"length\"]\n",
    "        prismai_llama[domain].append(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      " & gpt2_05p & gpt2_median & gpt2_95p & llama_05p & llama_median & llama_95p \\\\\n",
      "\\midrule\n",
      "arxiv_papers & \\np{1009} & \\np{11338} & \\np{34941} & \\np{966} & \\np{11158} & \\np{34433} \\\\\n",
      "blog_authorship_corpus & \\np{15} & \\np{65} & \\np{600} & \\np{16} & \\np{66} & \\np{593} \\\\\n",
      "bundestag & \\np{234} & \\np{1342} & \\np{2483} & \\np{170} & \\np{946} & \\np{1747} \\\\\n",
      "cnn_news & \\np{309} & \\np{749} & \\np{1597} & \\np{309} & \\np{748} & \\np{1588} \\\\\n",
      "euro_court_cases & \\np{258} & \\np{984} & \\np{5046} & \\np{280} & \\np{1019} & \\np{5140} \\\\\n",
      "gutenberg & \\np{784} & \\np{39006} & \\np{222774} & \\np{778} & \\np{37531} & \\np{202753} \\\\\n",
      "house_of_commons & \\np{89} & \\np{818} & \\np{18497} & \\np{91} & \\np{822} & \\np{18700} \\\\\n",
      "spiegel_articles & \\np{334} & \\np{912} & \\np{2603} & \\np{250} & \\np{682} & \\np{1934} \\\\\n",
      "student_essays & \\np{213} & \\np{439} & \\np{890} & \\np{212} & \\np{436} & \\np{884} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gpt2_05p",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gpt2_median",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gpt2_95p",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llama_05p",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llama_median",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llama_95p",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "a10d792f-83f7-46b4-9594-0661c40ad92f",
       "rows": [
        [
         "arxiv_papers",
         "1009.0",
         "11338.0",
         "34941.5",
         "966.5",
         "11158.0",
         "34433.0"
        ],
        [
         "blog_authorship_corpus",
         "15.0",
         "65.0",
         "600.0",
         "16.0",
         "66.0",
         "593.0"
        ],
        [
         "bundestag",
         "234.0",
         "1342.0",
         "2483.899999999998",
         "170.0",
         "946.0",
         "1747.0"
        ],
        [
         "cnn_news",
         "309.0",
         "749.0",
         "1597.0",
         "309.55000000000007",
         "748.0",
         "1588.0"
        ],
        [
         "euro_court_cases",
         "258.25",
         "984.0",
         "5046.0",
         "280.25",
         "1019.0",
         "5140.0"
        ],
        [
         "gutenberg",
         "784.9000000000001",
         "39006.0",
         "222774.0",
         "778.9000000000001",
         "37531.0",
         "202753.0"
        ],
        [
         "house_of_commons",
         "89.0",
         "818.0",
         "18497.399999999965",
         "91.0",
         "822.0",
         "18700.5499999999"
        ],
        [
         "spiegel_articles",
         "334.0",
         "912.0",
         "2603.0",
         "250.0",
         "682.0",
         "1934.0"
        ],
        [
         "student_essays",
         "213.0",
         "439.0",
         "890.0",
         "212.0",
         "436.0",
         "884.0"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 9
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt2_05p</th>\n",
       "      <th>gpt2_median</th>\n",
       "      <th>gpt2_95p</th>\n",
       "      <th>llama_05p</th>\n",
       "      <th>llama_median</th>\n",
       "      <th>llama_95p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>arxiv_papers</th>\n",
       "      <td>1009.00</td>\n",
       "      <td>11338.0</td>\n",
       "      <td>34941.5</td>\n",
       "      <td>966.50</td>\n",
       "      <td>11158.0</td>\n",
       "      <td>34433.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blog_authorship_corpus</th>\n",
       "      <td>15.00</td>\n",
       "      <td>65.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>66.0</td>\n",
       "      <td>593.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bundestag</th>\n",
       "      <td>234.00</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>2483.9</td>\n",
       "      <td>170.00</td>\n",
       "      <td>946.0</td>\n",
       "      <td>1747.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_news</th>\n",
       "      <td>309.00</td>\n",
       "      <td>749.0</td>\n",
       "      <td>1597.0</td>\n",
       "      <td>309.55</td>\n",
       "      <td>748.0</td>\n",
       "      <td>1588.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>euro_court_cases</th>\n",
       "      <td>258.25</td>\n",
       "      <td>984.0</td>\n",
       "      <td>5046.0</td>\n",
       "      <td>280.25</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>5140.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gutenberg</th>\n",
       "      <td>784.90</td>\n",
       "      <td>39006.0</td>\n",
       "      <td>222774.0</td>\n",
       "      <td>778.90</td>\n",
       "      <td>37531.0</td>\n",
       "      <td>202753.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house_of_commons</th>\n",
       "      <td>89.00</td>\n",
       "      <td>818.0</td>\n",
       "      <td>18497.4</td>\n",
       "      <td>91.00</td>\n",
       "      <td>822.0</td>\n",
       "      <td>18700.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spiegel_articles</th>\n",
       "      <td>334.00</td>\n",
       "      <td>912.0</td>\n",
       "      <td>2603.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>682.0</td>\n",
       "      <td>1934.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student_essays</th>\n",
       "      <td>213.00</td>\n",
       "      <td>439.0</td>\n",
       "      <td>890.0</td>\n",
       "      <td>212.00</td>\n",
       "      <td>436.0</td>\n",
       "      <td>884.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        gpt2_05p  gpt2_median  gpt2_95p  llama_05p  \\\n",
       "arxiv_papers             1009.00      11338.0   34941.5     966.50   \n",
       "blog_authorship_corpus     15.00         65.0     600.0      16.00   \n",
       "bundestag                 234.00       1342.0    2483.9     170.00   \n",
       "cnn_news                  309.00        749.0    1597.0     309.55   \n",
       "euro_court_cases          258.25        984.0    5046.0     280.25   \n",
       "gutenberg                 784.90      39006.0  222774.0     778.90   \n",
       "house_of_commons           89.00        818.0   18497.4      91.00   \n",
       "spiegel_articles          334.00        912.0    2603.0     250.00   \n",
       "student_essays            213.00        439.0     890.0     212.00   \n",
       "\n",
       "                        llama_median  llama_95p  \n",
       "arxiv_papers                 11158.0   34433.00  \n",
       "blog_authorship_corpus          66.0     593.00  \n",
       "bundestag                      946.0    1747.00  \n",
       "cnn_news                       748.0    1588.00  \n",
       "euro_court_cases              1019.0    5140.00  \n",
       "gutenberg                    37531.0  202753.00  \n",
       "house_of_commons               822.0   18700.55  \n",
       "spiegel_articles               682.0    1934.00  \n",
       "student_essays                 436.0     884.00  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    [{\"gpt2\": prismai_gpt2[key], \"llama\": prismai_llama[key]} for key in prismai_llama],\n",
    "    columns=[\"gpt2\", \"llama\"],\n",
    "    index=list(prismai_llama.keys()),\n",
    ")\n",
    "df[\"gpt2_05p\"] = df[\"gpt2\"].map(lambda x: np.percentile(x, 5))\n",
    "# df[\"gpt2_mean\"] = df[\"gpt2\"].map(np.mean)\n",
    "df[\"gpt2_median\"] = df[\"gpt2\"].map(np.median)\n",
    "df[\"gpt2_95p\"] = df[\"gpt2\"].map(lambda x: np.percentile(x, 95))\n",
    "del df[\"gpt2\"]\n",
    "df[\"llama_05p\"] = df[\"llama\"].map(lambda x: np.percentile(x, 5))\n",
    "# df[\"llama_mean\"] = df[\"llama\"].map(np.mean)\n",
    "df[\"llama_median\"] = df[\"llama\"].map(np.median)\n",
    "df[\"llama_95p\"] = df[\"llama\"].map(lambda x: np.percentile(x, 95))\n",
    "del df[\"llama\"]\n",
    "print(df.to_latex(float_format=\"\\\\np{%d}\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145134ef47fa4a9ea901617bfe33232b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CHEAT: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "312eb296d8434ff2b817f857ebe89126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ghostbuster: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38f9b5fb5064b85b3c448afc6ba68e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HC3-Plus: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339ff64c76b94ea88bbce5ddb13436d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MAGE: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c7268d4747a434cadeefdbac0eca35d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "OpenLLMText: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9948219ffe8f4c60a813161fe39c1e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SeqXGPT: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "values_gpt2 = defaultdict(list)\n",
    "values_llama = defaultdict(list)\n",
    "\n",
    "for ds in \"CHEAT Ghostbuster HC3-Plus MAGE OpenLLMText SeqXGPT\".split():\n",
    "    for item in tqdm(db.get_collection(f\"dataset_{ds}\").find(), position=0, desc=ds):\n",
    "        text = \" \".join(item.get(\"text\").strip().split())\n",
    "        encoding = gpt_tokenizer(text, return_length=True)\n",
    "        (length,) = encoding[\"length\"]\n",
    "        values_gpt2[ds].append(length)\n",
    "\n",
    "        encoding = llama_tokenizer(text, return_length=True)\n",
    "        (length,) = encoding[\"length\"]\n",
    "        values_llama[ds].append(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      " & gpt2_05p & gpt2_median & gpt2_95p & llama_05p & llama_median & llama_95p \\\\\n",
      "\\midrule\n",
      "CHEAT & \\np{106} & \\np{176} & \\np{298} & \\np{105} & \\np{173} & \\np{291} \\\\\n",
      "Ghostbuster & \\np{280} & \\np{632} & \\np{997} & \\np{281} & \\np{631} & \\np{998} \\\\\n",
      "HC3-Plus & \\np{12} & \\np{52} & \\np{383} & \\np{11} & \\np{41} & \\np{257} \\\\\n",
      "MAGE & \\np{36} & \\np{141} & \\np{951} & \\np{37} & \\np{142} & \\np{952} \\\\\n",
      "OpenLLMText & \\np{120} & \\np{392} & \\np{1024} & \\np{120} & \\np{390} & \\np{1031} \\\\\n",
      "SeqXGPT & \\np{72} & \\np{270} & \\np{504} & \\np{73} & \\np{270} & \\np{499} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gpt2_05p",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gpt2_median",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gpt2_95p",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llama_05p",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llama_median",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llama_95p",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "9078274e-458c-49a7-8801-00b0f9697713",
       "rows": [
        [
         "CHEAT",
         "106.0",
         "176.0",
         "298.0",
         "105.0",
         "173.0",
         "291.0"
        ],
        [
         "Ghostbuster",
         "280.0",
         "632.0",
         "997.0",
         "281.0",
         "631.0",
         "998.0499999999993"
        ],
        [
         "HC3-Plus",
         "12.0",
         "52.0",
         "383.0",
         "11.0",
         "41.0",
         "257.0"
        ],
        [
         "MAGE",
         "36.0",
         "141.0",
         "951.0",
         "37.0",
         "142.0",
         "952.0"
        ],
        [
         "OpenLLMText",
         "120.0",
         "392.0",
         "1024.0",
         "120.0",
         "390.0",
         "1031.0"
        ],
        [
         "SeqXGPT",
         "72.0",
         "270.0",
         "504.0",
         "73.0",
         "270.0",
         "499.0"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt2_05p</th>\n",
       "      <th>gpt2_median</th>\n",
       "      <th>gpt2_95p</th>\n",
       "      <th>llama_05p</th>\n",
       "      <th>llama_median</th>\n",
       "      <th>llama_95p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CHEAT</th>\n",
       "      <td>106.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>291.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ghostbuster</th>\n",
       "      <td>280.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>997.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>631.0</td>\n",
       "      <td>998.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HC3-Plus</th>\n",
       "      <td>12.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>257.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAGE</th>\n",
       "      <td>36.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>951.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>952.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenLLMText</th>\n",
       "      <td>120.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>1031.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SeqXGPT</th>\n",
       "      <td>72.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>499.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             gpt2_05p  gpt2_median  gpt2_95p  llama_05p  llama_median  \\\n",
       "CHEAT           106.0        176.0     298.0      105.0         173.0   \n",
       "Ghostbuster     280.0        632.0     997.0      281.0         631.0   \n",
       "HC3-Plus         12.0         52.0     383.0       11.0          41.0   \n",
       "MAGE             36.0        141.0     951.0       37.0         142.0   \n",
       "OpenLLMText     120.0        392.0    1024.0      120.0         390.0   \n",
       "SeqXGPT          72.0        270.0     504.0       73.0         270.0   \n",
       "\n",
       "             llama_95p  \n",
       "CHEAT           291.00  \n",
       "Ghostbuster     998.05  \n",
       "HC3-Plus        257.00  \n",
       "MAGE            952.00  \n",
       "OpenLLMText    1031.00  \n",
       "SeqXGPT         499.00  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    [{\"gpt2\": values_gpt2[key], \"llama\": values_llama[key]} for key in values_llama],\n",
    "    columns=[\"gpt2\", \"llama\"],\n",
    "    index=list(values_llama.keys()),\n",
    ")\n",
    "df[\"gpt2_05p\"] = df[\"gpt2\"].map(lambda x: np.percentile(x, 5))\n",
    "# df[\"gpt2_mean\"] = df[\"gpt2\"].map(np.mean)\n",
    "df[\"gpt2_median\"] = df[\"gpt2\"].map(np.median)\n",
    "df[\"gpt2_95p\"] = df[\"gpt2\"].map(lambda x: np.percentile(x, 95))\n",
    "del df[\"gpt2\"]\n",
    "df[\"llama_05p\"] = df[\"llama\"].map(lambda x: np.percentile(x, 5))\n",
    "# df[\"llama_mean\"] = df[\"llama\"].map(np.mean)\n",
    "df[\"llama_median\"] = df[\"llama\"].map(np.median)\n",
    "df[\"llama_95p\"] = df[\"llama\"].map(lambda x: np.percentile(x, 95))\n",
    "del df[\"llama\"]\n",
    "print(df.to_latex(float_format=\"\\\\np{%d}\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(\n",
    "    features_prismai.aggregate(\n",
    "        [\n",
    "            {\n",
    "                \"$project\": {\n",
    "                    \"domain\": \"$document.domain\",\n",
    "                    \"size\": {\"$size\": \"$transition_scores.intermediate_logits\"},\n",
    "                },\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": \"$domain\",\n",
    "                    \"size\": {\"$max\": \"$size\"},\n",
    "                },\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_collection = collected_items\n",
    "source_collection_limit = 1500\n",
    "\n",
    "synth_collection = \"synthesized_texts\"\n",
    "score_collection = \"features_prismai\"\n",
    "\n",
    "domain = \"cnn_news\"\n",
    "lang = \"en-EN\"\n",
    "\n",
    "synth_type = \"fulltext\"\n",
    "synth_agent = \"gpt-4o-mini\"\n",
    "\n",
    "feature_model = \"gpt2\"\n",
    "\n",
    "pre_processor_type = \"truncated\"\n",
    "\n",
    "next(\n",
    "    db.get_collection(score_collection).aggregate(\n",
    "        [\n",
    "            {\n",
    "                \"$match\": {\n",
    "                    \"document.agent\": {\"$in\": [None, synth_agent]},\n",
    "                    \"document.domain\": domain,\n",
    "                    \"document.lang\": lang,\n",
    "                    \"document.type\": {\"$in\": [\"source\", synth_type]},\n",
    "                    \"model.name\": feature_model,\n",
    "                    # \"pre_processor.type\": pre_processor_type,\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": \"$document._id.$id\",\n",
    "                    \"count\": {\"$count\": {}},\n",
    "                    \"features\": {\n",
    "                        \"$push\": {\n",
    "                            \"type\": \"$document.type\",\n",
    "                            \"split\": \"$split\",\n",
    "                            \"transition_scores\": \"$transition_scores\",\n",
    "                        }\n",
    "                    },\n",
    "                }\n",
    "            },\n",
    "        ],\n",
    "        allowDiskUse=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_prismai.count_documents({\"model.name\": {\"$ne\": \"gpt2\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_prismai.delete_many({\"model.name\": {\"$ne\": \"gpt2\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(\n",
    "    features_prismai.aggregate(\n",
    "        [\n",
    "            {\"$match\": {\"model.name\": \"meta-llama/Llama-3.2-1B\"}},\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": [\"$document.agent\", \"$document.type\", \"$document.domain\"],\n",
    "                    \"count\": {\"$count\": {}},\n",
    "                }\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise RuntimeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesized_texts.count_documents(\n",
    "    {\n",
    "        \"domain\": \"blog_authorship_corpus\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_ = list(\n",
    "    synthesized_texts.aggregate(\n",
    "        [\n",
    "            {\"$match\": {\"agent\": {\"$ne\": \"nemotron\"}}},\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": [\"$domain\", \"$type\", \"$agent\"],\n",
    "                    \"agent\": {\"$first\": \"$agent\"},\n",
    "                    \"domain\": {\"$first\": \"$domain\"},\n",
    "                    \"type\": {\"$first\": \"$type\"},\n",
    "                    \"count\": {\"$count\": {}},\n",
    "                }\n",
    "            },\n",
    "            {\"$group\": {\"_id\": [\"$domain\"], \"count\": {\"$min\": \"$count\"}}},\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(\n",
    "    collected_items.aggregate(\n",
    "        [\n",
    "            {\n",
    "                \"$lookup\": {\n",
    "                    \"from\": \"synthesized_texts\",\n",
    "                    \"as\": \"synthesized_texts\",\n",
    "                    \"localField\": \"_id\",\n",
    "                    \"foreignField\": \"_ref_id.$id\",\n",
    "                    \"pipeline\": [\n",
    "                        {\n",
    "                            \"$project\": {\n",
    "                                \"_id\": 1,\n",
    "                                \"type\": 1,\n",
    "                                \"agent\": 1,\n",
    "                                # \"_doc_id\": \"$_ref_id.$id\",\n",
    "                                # \"domain\": 1,\n",
    "                            }\n",
    "                        },\n",
    "                        {\"$match\": {\"type\": \"fulltext\", \"agent\": \"gemma2:9b\"}},\n",
    "                    ],\n",
    "                }\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "# len(items)\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db.drop_collection(transition_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoc_ids = [\n",
    "    doc[\"_id\"]\n",
    "    for doc in collected_items.find(\n",
    "        {\"domain\": \"house_of_commons\"}, projection={\"_id\": 1}, limit=1500\n",
    "    )\n",
    "]\n",
    "len(hoc_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_ids_hoc = [\n",
    "    doc[\"document\"][\"_id\"].id\n",
    "    for doc in transition_scores.find(\n",
    "        {\n",
    "            \"document.domain\": \"house_of_commons\",\n",
    "            \"document.type\": \"source\",\n",
    "            # \"model.name\": \"gpt2\",\n",
    "            \"model.name\": \"meta-llama/Llama-3.2-1B\",\n",
    "        },\n",
    "        projection={\"document._id\": 1},\n",
    "    )\n",
    "]\n",
    "len(llama_ids_hoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(llama_ids_hoc).intersection(hoc_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(llama_ids_hoc).intersection(hoc_ids[: len(llama_ids_hoc)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1500 - len(llama_ids_hoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoc_ids_synth = [\n",
    "    doc[\"_id\"]\n",
    "    for doc in synthesized_texts.find(\n",
    "        # {\"domain\": \"euro_court_cases\"},\n",
    "        {\"domain\": \"house_of_commons\"},\n",
    "        projection={\"_id\": 1},\n",
    "    )\n",
    "]\n",
    "len(hoc_ids_synth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_ids_hoc_synth = [\n",
    "    doc[\"document\"][\"_synth_id\"].id\n",
    "    for doc in transition_scores.find(\n",
    "        {\n",
    "            \"document.domain\": \"house_of_commons\",\n",
    "            \"document.type\": {\"$ne\": \"source\"},\n",
    "            \"model.name\": \"meta-llama/Llama-3.2-1B\",\n",
    "        },\n",
    "        projection={\"document._synth_id\": 1},\n",
    "    )\n",
    "]\n",
    "len(llama_ids_hoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(llama_ids_hoc_synth).intersection(hoc_ids_synth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(llama_ids_hoc_synth).intersection(hoc_ids_synth[: len(llama_ids_hoc_synth)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(doc[\"agent\"] for doc in synthesized_texts.find(projection=[\"agent\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(\n",
    "    synthesized_texts.aggregate(\n",
    "        [\n",
    "            {\"$match\": {\"type\": \"chunk\", \"agent\": \"gemma2:9b\"}},\n",
    "            # {\"$limit\": 1},\n",
    "            {\n",
    "                \"$project\": {\n",
    "                    \"_id\": 1,\n",
    "                    \"chunks\": 1,\n",
    "                    \"start_idx\": \"$synth_metadata.start_idx\",\n",
    "                    \"end_idx\": \"$synth_metadata.end_idx\",\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$lookup\": {\n",
    "                    \"from\": \"transition_scores\",\n",
    "                    \"as\": \"transition_scores\",\n",
    "                    \"localField\": \"_id\",\n",
    "                    \"foreignField\": \"document._synth_id.$id\",\n",
    "                    \"pipeline\": [\n",
    "                        {\"$match\": {\"document.type\": \"chunk\", \"model.name\": \"gpt2\"}},\n",
    "                        {\n",
    "                            \"$project\": {\n",
    "                                \"_id\": 1,\n",
    "                                \"document\": 1,\n",
    "                                \"model\": 1,\n",
    "                                # \"transition_scores\": 1,\n",
    "                                \"metadata\": 1,\n",
    "                            }\n",
    "                        },\n",
    "                    ],\n",
    "                }\n",
    "            },\n",
    "        ],\n",
    "        # allowDiskUse=True,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(\n",
    "    transition_scores.aggregate(\n",
    "        [\n",
    "            {\n",
    "                \"$lookup\": {\n",
    "                    \"from\": \"collected_items\",\n",
    "                    \"localField\": \"refs._ref_id.$id\",\n",
    "                    \"foreignField\": \"_id\",\n",
    "                    \"as\": \"source\",\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$project\": {\n",
    "                    \"transition_scores\": 0,\n",
    "                    \"source.text\": 0,\n",
    "                    \"source.chunks\": 0,\n",
    "                    \"source.synthetization\": 0,\n",
    "                    # \"_id\": 1,\n",
    "                    # \"domain\": 1,\n",
    "                    # \"features._id\": 1,\n",
    "                    # \"features.model.name\": 1,\n",
    "                    # \"features.pre_processor.type\": 1,\n",
    "                }\n",
    "            },\n",
    "            {\"$unwind\": {\"path\": \"$source\"}},\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": {\n",
    "                        \"$concat\": [\n",
    "                            \"$source.domain\",\n",
    "                            \" - \",\n",
    "                            \"$model.name\",\n",
    "                            \" - \",\n",
    "                            \"$pre_processor.type\",\n",
    "                        ]\n",
    "                    },\n",
    "                    \"total\": {\"$sum\": 1},\n",
    "                }\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(\n",
    "    transition_scores.aggregate(\n",
    "        [\n",
    "            {\n",
    "                \"$lookup\": {\n",
    "                    \"from\": \"synthesized_texts\",\n",
    "                    \"localField\": \"refs._ref_id.$id\",\n",
    "                    \"foreignField\": \"_id\",\n",
    "                    \"as\": \"source\",\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$project\": {\n",
    "                    \"transition_scores\": 0,\n",
    "                    \"source.text\": 0,\n",
    "                    \"source.chunks\": 0,\n",
    "                    \"source.synthetization\": 0,\n",
    "                    # \"_id\": 1,\n",
    "                    # \"domain\": 1,\n",
    "                    # \"features._id\": 1,\n",
    "                    # \"features.model.name\": 1,\n",
    "                    # \"features.pre_processor.type\": 1,\n",
    "                }\n",
    "            },\n",
    "            {\"$unwind\": {\"path\": \"$source\"}},\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": {\n",
    "                        \"$concat\": [\n",
    "                            \"$source.domain\",\n",
    "                            \" - \",\n",
    "                            \"$model.name\",\n",
    "                            \" - \",\n",
    "                            \"$pre_processor.type\",\n",
    "                        ]\n",
    "                    },\n",
    "                    \"total\": {\"$sum\": 1},\n",
    "                }\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(\n",
    "    1\n",
    "    for _ in test_swt.aggregate(\n",
    "        [\n",
    "            {\n",
    "                \"$lookup\": {\n",
    "                    \"from\": \"synthesized_texts\",\n",
    "                    \"localField\": \"refs._ref_id.$id\",\n",
    "                    \"foreignField\": \"_id\",\n",
    "                    \"as\": \"features\",\n",
    "                }\n",
    "            },\n",
    "            {\"$match\": {\"features\": {\"$exists\": True, \"$ne\": []}}},\n",
    "            {\n",
    "                \"$project\": {\n",
    "                    \"_id\": 1,\n",
    "                    \"refs._ref_id.$id\": 1,\n",
    "                    \"features._id\": 1,\n",
    "                    \"features.id\": 1,\n",
    "                }\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "    # if doc[\"features\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(1 for _ in test_swt.find(projection={\"_id\": 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "re.findall(\"\\d\", \"abc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
