{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pymongo import MongoClient\n",
    "\n",
    "load_dotenv(\"../env\")\n",
    "client = MongoClient(os.environ.get(\"MONGO_DB_CONNECTION\"))\n",
    "collection = client.get_database(\"prismai\").get_collection(\"collected_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import batched\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "datasets.disable_progress_bars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2025-01-23 16:55:10.333259473 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 24 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "\u001b[0;93m2025-01-23 16:55:10.337907913 [W:onnxruntime:, session_state.cc:1168 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\u001b[m\n",
      "\u001b[0;93m2025-01-23 16:55:10.337916633 [W:onnxruntime:, session_state.cc:1170 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\u001b[m\n"
     ]
    }
   ],
   "source": [
    "from transition_scores.pre_processor.text import TextPreProcessor\n",
    "from transition_scores.pre_processor.chunks import RollingWindowChunkPreProcessor\n",
    "from transition_scores.scorer import OnnxTransitionScorer\n",
    "\n",
    "scorer = OnnxTransitionScorer(\n",
    "    \"/hot_storage/models/onnx/gpt2_onnx_o4/\",\n",
    "    pre_processor=RollingWindowChunkPreProcessor.from_pretrained(\n",
    "        \"/hot_storage/models/onnx/gpt2_onnx_o4/\"\n",
    "    ),\n",
    "    batch_size=1,\n",
    "    device=\"cuda\",\n",
    "    top_k=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ff6be487154f9f8c0041239bc835af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/802852 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Parameter 'function'=<bound method TransitionScorerABC._process_batch of <transition_scores.scorer.OnnxTransitionScorer object at 0x721cad472c90>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ref': {'$id': '678fb3abdbe3ac531644d662', '$ref': 'collected_items'}, 'text_sha256': '00de2227c91236bb19430f6780cc26df7e06e098370e9068af6877140db3939f', 'text': 'Herr PrÃ¤sident! Meine sehr geehrten Damen und Herren!', 'start_idx': 0, 'end_idx': 1, 'start_token_idx': 0, 'prefix_idx': 0, 'transition_scores': [{'target_id': 39, 'target_prob': 0.0, 'top_k_ids': [], 'top_k_scores': []}, {'target_id': 8056, 'target_prob': 5.699131725123152e-05, 'top_k_ids': [13, 11, 198, 12], 'top_k_scores': [0.0634\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m scores \u001b[38;5;129;01min\u001b[39;00m scorer\u001b[38;5;241m.\u001b[39mprocess(dataset):\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(scores)[:\u001b[38;5;241m500\u001b[39m])\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from bson import DBRef\n",
    "\n",
    "\n",
    "total = collection.count_documents({})\n",
    "\n",
    "tq = tqdm(\n",
    "    collection.find(\n",
    "        projection=[\n",
    "            \"text\",\n",
    "            \"chunks\",\n",
    "        ],\n",
    "        batch_size=128,\n",
    "    ),\n",
    "    total=total,\n",
    ")\n",
    "for batch in batched(tq, 16):\n",
    "    batch = [\n",
    "        {\n",
    "            \"ref\": {\n",
    "                \"$ref\": \"collected_items\",\n",
    "                \"$id\": str(row.pop(\"_id\")),\n",
    "            }\n",
    "        }\n",
    "        | row\n",
    "        for row in batch\n",
    "    ]\n",
    "    dataset = Dataset.from_list(batch)\n",
    "    dataset = dataset.filter(lambda x: x[\"text\"] and x[\"chunks\"])\n",
    "    for scores in scorer.process(dataset):\n",
    "        print(str(scores)[:500])\n",
    "        raise RuntimeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_scores = scores.copy()\n",
    "\n",
    "transposed = {\"feature_metadata\": dict()}\n",
    "for key in scorer.pre_processor.additional_fields:\n",
    "    transposed[\"feature_metadata\"][key] = _scores.pop(key)\n",
    "transposed = _scores | transposed\n",
    "transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = collection.find_one({\"_id\": \"22c34302-0ec6-4781-8d96-1d6a4fda049e\"})\n",
    "print(one[\"text\"])\n",
    "print(\"\".join(one[\"chunks\"]))\n",
    "one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson.dbref import DBRef\n",
    "\n",
    "from transition_scores.data import LogProbs\n",
    "from transition_scores.mongo import TextTransitionScore, TransitionScoreItem\n",
    "\n",
    "dict(\n",
    "    TransitionScoreItem(\n",
    "        DBRef(\"a\", \"b\"),\n",
    "        \"gpt2\",\n",
    "        \"onnx\",\n",
    "        TextTransitionScore([LogProbs(0, 1.0, [0], [1.0])]),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "from transition_scores.pre_processor.text import TextPreProcessor\n",
    "\n",
    "tokenizer = TextPreProcessor.from_pretrained(\"gpt2\")\n",
    "\n",
    "dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"_id\": [\"abc-def-123\"],\n",
    "        \"text\": [\n",
    "            \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\"\n",
    "        ],\n",
    "        \"chunks\": [\n",
    "            [\n",
    "                \"Lorem ipsum dolor sit amet,\",\n",
    "                \"consectetur adipiscing elit.\",\n",
    "                \"Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\",\n",
    "                \"Ut enim ad minim veniam,\",\n",
    "                \"quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\",\n",
    "            ]\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "dataset = tokenizer.prepare_dataset(dataset)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "from transition_scores.pre_processor.text import TextPreProcessor\n",
    "from transition_scores.pre_processor.chunks import RollingWindowChunkPreProcessor\n",
    "\n",
    "tokenizer = RollingWindowChunkPreProcessor.from_pretrained(\"gpt2\")\n",
    "\n",
    "dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"_id\": [\"abc-def-123\"],\n",
    "        \"text\": [\n",
    "            \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\"\n",
    "        ],\n",
    "        \"chunks\": [\n",
    "            [\n",
    "                \"Lorem ipsum dolor sit amet,\",\n",
    "                \"consectetur adipiscing elit.\",\n",
    "                \"Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\",\n",
    "                \"Ut enim ad minim veniam,\",\n",
    "                \"quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\",\n",
    "            ]\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "dataset = tokenizer.prepare_dataset(dataset)\n",
    "dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
